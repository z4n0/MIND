{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "337553da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Environment settings: {'kaggle': False, 'gdrive': False, 'linux': True}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import platform\n",
    "import os\n",
    "\n",
    "gdrive = False\n",
    "linux = True \n",
    "# Detect if we're running on a Linux system\n",
    "linux = platform.system() == \"Linux\"\n",
    "\n",
    "# Detect if we're in a Google Colab environment by attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "# Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "    gdrive=True\n",
    "except ImportError:\n",
    "    gdrive = False\n",
    "\n",
    "# Detect if we're in a Kaggle environment by checking for a Kaggle-specific environment variable\n",
    "kaggle = \"KAGGLE_URL_BASE\" in os.environ\n",
    "environment_flags = {'kaggle': kaggle, 'gdrive': gdrive, 'linux': linux}\n",
    "print(\"Environment settings:\", environment_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34aeaa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zano/Documents/TESI/FOLDER_CINECA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/zano/Documents/TESI/FOLDER_CINECA/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf9f0a",
   "metadata": {},
   "source": [
    "## install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6358950",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63fd0c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python --version   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9fda59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9adf7f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretrained_microscopy_models@ git+https://github.com/nasa/pretrained-microscopy-models@f50b5689a71cf6f86016fb4a5c5a2bb31e0397f3 (from -r requirementsaaaa.txt (line 183))\n",
      "  Using cached pretrained_microscopy_models-0.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: absl-py==2.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: accelerate==1.5.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 2)) (1.5.2)\n",
      "Requirement already satisfied: aenum==3.1.15 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 3)) (3.1.15)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.11.14 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 5)) (3.11.14)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: albucore==0.0.23 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 7)) (0.0.23)\n",
      "Requirement already satisfied: albumentations==2.0.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: alembic==1.14.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 9)) (1.14.1)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 11)) (4.9.3)\n",
      "Requirement already satisfied: anyio==4.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: anywidget==0.9.13 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 13)) (0.9.13)\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 14)) (23.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 15)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 16)) (1.3.0)\n",
      "Requirement already satisfied: astor==0.8.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 17)) (0.8.1)\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 18)) (3.0.0)\n",
      "Requirement already satisfied: async-lru==2.0.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 19)) (2.0.4)\n",
      "Requirement already satisfied: attrs==25.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 20)) (25.1.0)\n",
      "Requirement already satisfied: babel==2.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 21)) (2.17.0)\n",
      "Requirement already satisfied: beartype==0.20.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 22)) (0.20.2)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 23)) (4.13.3)\n",
      "Requirement already satisfied: bleach==6.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 24)) (6.2.0)\n",
      "Requirement already satisfied: blinker==1.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 25)) (1.9.0)\n",
      "Requirement already satisfied: byol-pytorch==0.8.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 26)) (0.8.2)\n",
      "Requirement already satisfied: cachetools==5.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 27)) (5.5.1)\n",
      "Requirement already satisfied: certifi==2025.1.31 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 28)) (2025.1.31)\n",
      "Requirement already satisfied: cffi==1.17.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 29)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 30)) (3.4.1)\n",
      "Requirement already satisfied: clearml==1.17.2rc0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 31)) (1.17.2rc0)\n",
      "Requirement already satisfied: click==8.1.8 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 32)) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle==3.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 33)) (3.1.1)\n",
      "Requirement already satisfied: colorama==0.4.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 34)) (0.4.6)\n",
      "Requirement already satisfied: colorlog==6.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 35)) (6.9.0)\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 36)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 37)) (1.3.1)\n",
      "Requirement already satisfied: crc32c==2.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 38)) (2.7.1)\n",
      "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 39)) (0.12.1)\n",
      "Requirement already satisfied: databricks-sdk==0.43.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 40)) (0.43.0)\n",
      "Requirement already satisfied: debugpy==1.8.12 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 41)) (1.8.12)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 42)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 43)) (0.7.1)\n",
      "Requirement already satisfied: Deprecated==1.2.18 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 44)) (1.2.18)\n",
      "Requirement already satisfied: docker==7.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 45)) (7.1.0)\n",
      "Requirement already satisfied: donfig==0.8.1.post1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 46)) (0.8.1.post1)\n",
      "Requirement already satisfied: efficientnet_pytorch==0.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 47)) (0.6.3)\n",
      "Requirement already satisfied: einops==0.8.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 48)) (0.8.1)\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 49)) (2.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 50)) (2.21.1)\n",
      "Requirement already satisfied: filelock==3.11.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 51)) (3.11.0)\n",
      "Requirement already satisfied: fire==0.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 52)) (0.7.0)\n",
      "Requirement already satisfied: Flask==3.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 53)) (3.1.0)\n",
      "Requirement already satisfied: fonttools==4.56.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 54)) (4.56.0)\n",
      "Requirement already satisfied: fqdn==1.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 55)) (1.5.1)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 56)) (1.5.0)\n",
      "Requirement already satisfied: fsspec==2025.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 57)) (2025.2.0)\n",
      "Requirement already satisfied: furl==2.1.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 58)) (2.1.3)\n",
      "Requirement already satisfied: gdown==5.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 59)) (5.2.0)\n",
      "Requirement already satisfied: gitdb==4.0.12 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 60)) (4.0.12)\n",
      "Requirement already satisfied: GitPython==3.1.44 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 61)) (3.1.44)\n",
      "Requirement already satisfied: google-auth==2.38.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 62)) (2.38.0)\n",
      "Requirement already satisfied: graphene==3.4.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 63)) (3.4.3)\n",
      "Requirement already satisfied: graphql-core==3.2.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 64)) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay==3.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 65)) (3.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 66)) (0.20.3)\n",
      "Requirement already satisfied: greenlet==3.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 67)) (3.1.1)\n",
      "Requirement already satisfied: grpcio==1.70.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 68)) (1.70.0)\n",
      "Requirement already satisfied: gunicorn==23.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 69)) (23.0.0)\n",
      "Requirement already satisfied: h11==0.14.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 70)) (0.14.0)\n",
      "Requirement already satisfied: h5py==3.12.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 71)) (3.12.1)\n",
      "Requirement already satisfied: httpcore==1.0.7 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 72)) (1.0.7)\n",
      "Requirement already satisfied: httpx==0.28.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 73)) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 74)) (0.30.2)\n",
      "Requirement already satisfied: hydra-core==1.3.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 75)) (1.3.2)\n",
      "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 76)) (3.10)\n",
      "Requirement already satisfied: imagecodecs==2024.12.30 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 77)) (2024.12.30)\n",
      "Requirement already satisfied: imageio==2.37.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 78)) (2.37.0)\n",
      "Requirement already satisfied: imglyb==2.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 79)) (2.1.0)\n",
      "Requirement already satisfied: importlib_metadata==8.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 80)) (8.5.0)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 81)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.32.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 82)) (8.32.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 83)) (8.1.5)\n",
      "Requirement already satisfied: isoduration==20.11.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 84)) (20.11.0)\n",
      "Requirement already satisfied: itk==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 85)) (5.4.0)\n",
      "Requirement already satisfied: itk-core==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 86)) (5.4.0)\n",
      "Requirement already satisfied: itk-filtering==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 87)) (5.4.0)\n",
      "Requirement already satisfied: itk-io==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 88)) (5.4.0)\n",
      "Requirement already satisfied: itk-numerics==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 89)) (5.4.0)\n",
      "Requirement already satisfied: itk-registration==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 90)) (5.4.0)\n",
      "Requirement already satisfied: itk-segmentation==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 91)) (5.4.0)\n",
      "Requirement already satisfied: itsdangerous==2.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 92)) (2.2.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 93)) (0.19.2)\n",
      "Requirement already satisfied: jgo==1.0.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 94)) (1.0.6)\n",
      "Requirement already satisfied: Jinja2==3.1.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 95)) (3.1.5)\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 96)) (1.4.2)\n",
      "Requirement already satisfied: jpype1==1.5.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 97)) (1.5.2)\n",
      "Requirement already satisfied: json-tricks==3.17.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 98)) (3.17.3)\n",
      "Requirement already satisfied: json5==0.10.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 99)) (0.10.0)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 100)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 101)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2024.10.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 102)) (2024.10.1)\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 103)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 104)) (2.2.5)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 105)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 106)) (5.7.2)\n",
      "Requirement already satisfied: jupyter_server==2.15.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 107)) (2.15.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 108)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab==4.3.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 109)) (4.3.5)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 110)) (0.3.0)\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 111)) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 112)) (3.0.13)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 113)) (1.4.8)\n",
      "Requirement already satisfied: kornia==0.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 114)) (0.8.0)\n",
      "Requirement already satisfied: kornia_rs==0.1.8 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 115)) (0.1.8)\n",
      "Requirement already satisfied: labeling==0.1.14 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 116)) (0.1.14)\n",
      "Requirement already satisfied: lazy_loader==0.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 117)) (0.4)\n",
      "Requirement already satisfied: lightly==1.5.19 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 118)) (1.5.19)\n",
      "Requirement already satisfied: lightly-utils==0.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 119)) (0.0.2)\n",
      "Requirement already satisfied: lightning-utilities==0.14.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 120)) (0.14.2)\n",
      "Requirement already satisfied: lmdb==1.6.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 121)) (1.6.2)\n",
      "Requirement already satisfied: lpips==0.1.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 122)) (0.1.4)\n",
      "Requirement already satisfied: Mako==1.3.9 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 123)) (1.3.9)\n",
      "Requirement already satisfied: Markdown==3.7 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 124)) (3.7)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 125)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 126)) (3.10.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 127)) (0.1.7)\n",
      "Requirement already satisfied: mistune==3.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 128)) (3.1.1)\n",
      "Requirement already satisfied: mlflow==2.20.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 129)) (2.20.1)\n",
      "Requirement already satisfied: mlflow-skinny==2.20.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 130)) (2.20.1)\n",
      "Requirement already satisfied: monai==1.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 131)) (1.4.0)\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 132)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 133)) (6.2.0)\n",
      "Requirement already satisfied: munch==4.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 134)) (4.0.0)\n",
      "Requirement already satisfied: narwhals==1.26.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 135)) (1.26.0)\n",
      "Requirement already satisfied: nbclient==0.10.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 136)) (0.10.2)\n",
      "Requirement already satisfied: nbconvert==7.16.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 137)) (7.16.6)\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 138)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 139)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 140)) (3.4.2)\n",
      "Requirement already satisfied: nibabel==5.3.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 141)) (5.3.2)\n",
      "Requirement already satisfied: ninja==1.11.1.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 142)) (1.11.1.3)\n",
      "Requirement already satisfied: nni==3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 143)) (3.0)\n",
      "Requirement already satisfied: notebook==7.3.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 144)) (7.3.2)\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 145)) (0.2.4)\n",
      "Requirement already satisfied: numcodecs==0.15.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 146)) (0.15.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 147)) (1.26.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 148)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 149)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 150)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 151)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 152)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 153)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 154)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 155)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 156)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 157)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-ml-py==12.570.86 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 158)) (12.570.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 159)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 160)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 161)) (12.4.127)\n",
      "Requirement already satisfied: ome-types==0.6.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 162)) (0.6.1)\n",
      "Requirement already satisfied: omegaconf==2.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 163)) (2.3.0)\n",
      "Requirement already satisfied: onnx==1.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 164)) (1.17.0)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 165)) (4.11.0.86)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 166)) (4.11.0.86)\n",
      "Requirement already satisfied: openslide-python==1.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 167)) (1.4.1)\n",
      "Requirement already satisfied: opentelemetry-api==1.30.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 168)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.30.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 169)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 170)) (0.51b0)\n",
      "Requirement already satisfied: optuna==4.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 171)) (4.2.0)\n",
      "Requirement already satisfied: orderedmultidict==1.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 172)) (1.0.1)\n",
      "Requirement already satisfied: overrides==7.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 173)) (7.7.0)\n",
      "Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 174)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 175)) (2.2.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 176)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 177)) (0.8.4)\n",
      "Requirement already satisfied: pathlib2==2.3.7.post1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 178)) (2.3.7.post1)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 179)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 180)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 181)) (4.3.6)\n",
      "Requirement already satisfied: plotly==6.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 182)) (6.0.0)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 184)) (0.7.4)\n",
      "Requirement already satisfied: prettytable==3.14.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 185)) (3.14.0)\n",
      "Requirement already satisfied: prometheus_client==0.21.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 186)) (0.21.1)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 187)) (3.0.50)\n",
      "Requirement already satisfied: propcache==0.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 188)) (0.3.0)\n",
      "Requirement already satisfied: protobuf==5.29.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 189)) (5.29.3)\n",
      "Requirement already satisfied: psutil==6.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 190)) (6.1.1)\n",
      "Requirement already satisfied: psygnal==0.12.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 191)) (0.12.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 192)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 193)) (0.2.3)\n",
      "Requirement already satisfied: pyamg==5.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 194)) (5.2.1)\n",
      "Requirement already satisfied: pyarrow==18.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 195)) (18.1.0)\n",
      "Requirement already satisfied: pyasn1==0.6.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 196)) (0.6.1)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 197)) (0.4.1)\n",
      "Requirement already satisfied: pycparser==2.22 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 198)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.10.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 199)) (2.10.6)\n",
      "Requirement already satisfied: pydantic-extra-types==2.10.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 200)) (2.10.3)\n",
      "Requirement already satisfied: pydantic_core==2.27.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 201)) (2.27.2)\n",
      "Requirement already satisfied: pydicom==3.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 202)) (3.0.1)\n",
      "Requirement already satisfied: Pygments==2.19.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 203)) (2.19.1)\n",
      "Requirement already satisfied: pyimagej==1.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 204)) (1.6.0)\n",
      "Requirement already satisfied: PyJWT==2.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 205)) (2.9.0)\n",
      "Requirement already satisfied: pynrrd==1.1.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 206)) (1.1.3)\n",
      "Requirement already satisfied: pyparsing==3.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 207)) (3.2.1)\n",
      "Requirement already satisfied: PySocks==1.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 208)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 209)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==3.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 210)) (3.2.1)\n",
      "Requirement already satisfied: PythonWebHDFS==0.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 211)) (0.2.3)\n",
      "Requirement already satisfied: pytorch-ignite==0.4.11 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 212)) (0.4.11)\n",
      "Requirement already satisfied: pytorch-lightning==2.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 213)) (2.5.1)\n",
      "Requirement already satisfied: pytz==2025.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 214)) (2025.1)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 215)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 216)) (26.2.1)\n",
      "Requirement already satisfied: readlif==0.6.5 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 217)) (0.6.5)\n",
      "Requirement already satisfied: referencing==0.36.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 218)) (0.36.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 219)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 220)) (2.32.3)\n",
      "Requirement already satisfied: responses==0.25.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 221)) (0.25.6)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 222)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 223)) (0.1.1)\n",
      "Requirement already satisfied: rpds-py==0.22.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 224)) (0.22.3)\n",
      "Requirement already satisfied: rsa==4.9 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 225)) (4.9)\n",
      "Requirement already satisfied: safetensors==0.5.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 226)) (0.5.3)\n",
      "Requirement already satisfied: schema==0.7.7 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 227)) (0.7.7)\n",
      "Requirement already satisfied: scikit-image==0.25.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 228)) (0.25.1)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 229)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 230)) (1.15.1)\n",
      "Requirement already satisfied: scyjava==1.10.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 231)) (1.10.2)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 232)) (0.13.2)\n",
      "Requirement already satisfied: segmentation-models-pytorch==0.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 233)) (0.2.1)\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 234)) (1.8.3)\n",
      "Requirement already satisfied: setuptools==75.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 235)) (75.8.0)\n",
      "Requirement already satisfied: simplejson==3.19.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 236)) (3.19.3)\n",
      "Requirement already satisfied: simsimd==6.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 237)) (6.2.1)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 238)) (1.17.0)\n",
      "Requirement already satisfied: smmap==5.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 239)) (5.0.2)\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 240)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 241)) (2.6)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.38 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 242)) (2.0.38)\n",
      "Requirement already satisfied: sqlparse==0.5.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 243)) (0.5.3)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 244)) (0.6.3)\n",
      "Requirement already satisfied: stringzilla==3.12.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 245)) (3.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 246)) (1.13.1)\n",
      "Requirement already satisfied: tensorboard==2.18.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 247)) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 248)) (0.7.2)\n",
      "Requirement already satisfied: tensorboardX==2.6.2.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 249)) (2.6.2.2)\n",
      "Requirement already satisfied: termcolor==2.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 250)) (2.5.0)\n",
      "Requirement already satisfied: terminado==0.18.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 251)) (0.18.1)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 252)) (3.5.0)\n",
      "Requirement already satisfied: tifffile==2025.1.10 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 253)) (2025.1.10)\n",
      "Requirement already satisfied: tinycss2==1.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 255)) (1.4.0)\n",
      "Requirement already satisfied: tokenizers==0.21.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 256)) (0.21.1)\n",
      "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 257)) (2.6.0)\n",
      "Requirement already satisfied: torchmetrics==1.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 258)) (1.7.0)\n",
      "Requirement already satisfied: torchview==0.2.6 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 259)) (0.2.6)\n",
      "Requirement already satisfied: torchvision==0.21.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 260)) (0.21.0)\n",
      "Requirement already satisfied: torchviz==0.0.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 261)) (0.0.3)\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 262)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 263)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 264)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.51.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 265)) (4.51.3)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 266)) (3.2.0)\n",
      "Requirement already satisfied: typeguard==4.1.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 267)) (4.1.2)\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241206 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 268)) (2.9.0.20241206)\n",
      "Requirement already satisfied: types-PyYAML==6.0.12.20241230 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 269)) (6.0.12.20241230)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 270)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2025.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 271)) (2025.1)\n",
      "Requirement already satisfied: uri-template==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 272)) (1.3.0)\n",
      "Requirement already satisfied: urllib3==2.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 273)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 274)) (0.2.13)\n",
      "Requirement already satisfied: webcolors==24.11.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 275)) (24.11.1)\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 276)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 277)) (1.8.0)\n",
      "Requirement already satisfied: websockets==14.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 278)) (14.2)\n",
      "Requirement already satisfied: Werkzeug==3.1.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 279)) (3.1.3)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 280)) (4.0.13)\n",
      "Requirement already satisfied: wrapt==1.17.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 281)) (1.17.2)\n",
      "Requirement already satisfied: xarray==2025.1.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 282)) (2025.1.2)\n",
      "Requirement already satisfied: xsdata==24.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 283)) (24.3.1)\n",
      "Requirement already satisfied: yarl==1.18.3 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 284)) (1.18.3)\n",
      "Requirement already satisfied: zarr==3.0.2 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 285)) (3.0.2)\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.venv/lib/python3.12/site-packages (from -r requirementsaaaa.txt (line 286)) (3.21.0)\n",
      "Requirement already satisfied: timm==0.4.12 in ./.venv/lib/python3.12/site-packages (from segmentation-models-pytorch==0.2.1->-r requirementsaaaa.txt (line 233)) (0.4.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirementsaaaa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69bc438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_fold_0.pth                 \u001b[0m\u001b[01;34mnotebooks\u001b[0m/\n",
      "best_model_fold_1.pth                 \u001b[01;34mpretrained_encoders\u001b[0m/\n",
      "best_model_fold_2.pth                 README.txt\n",
      "best_model_fold_3.pth                 requirementsaaaa.txt\n",
      "best_model_fold_4.pth                 requirements.txt\n",
      "best_model_fold_5.pth                 simclr_pretraining.py\n",
      "best_model_fold_6.pth                 simple_image_checker.py\n",
      "best_model_fold_7.pth                 \u001b[01;34mslurm_files\u001b[0m/\n",
      "byol_simsiam_pretraining.py           snelled_requirements.txt\n",
      "\u001b[01;34mclasses\u001b[0m/                              ssl_d121_3c-17253692.out\n",
      "\u001b[01;34mconfigs\u001b[0m/                              \u001b[01;32msubmit_all_3c.sh\u001b[0m*\n",
      "\u001b[01;34mconfusion_matrices\u001b[0m/                   \u001b[01;32msubmit_all_4c.sh\u001b[0m*\n",
      "\u001b[01;34mdata\u001b[0m/                                 \u001b[01;32msubmit_all_pretrained.sh\u001b[0m*\n",
      "downstream_supervised_fine_tuning.py  supervised_learning.py\n",
      "\u001b[01;34mlearning_curves\u001b[0m/                      \u001b[01;34mtmp_gradcam\u001b[0m/\n",
      "\u001b[01;34mlightning_logs\u001b[0m/                       train_3c.py\n",
      "\u001b[01;34mlogs\u001b[0m/                                 train_4c.py\n",
      "mlflow_ui.log                         train_pretrained.py\n",
      "\u001b[01;34mmlruns\u001b[0m/                               \u001b[01;34mutils\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b0584fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate your virtual environment\n",
    "!source ~/Documents/TESI/FOLDER_CINECA/.venv/bin/activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10561d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tifffile\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "# from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "from monai.data import Dataset, DataLoader\n",
    "# from classes.PrintShapeTransform import PrintShapeTransform\n",
    "from monai.utils.misc import set_determinism\n",
    "import monai\n",
    "print(monai.__version__)\n",
    "import cv2\n",
    "#import tifffile\n",
    "#from monai.networks.nets import DenseNet121\n",
    "import torch.nn.functional as F\n",
    "from monai.visualize import GradCAMpp,GradCAM  \n",
    "import pytorch_lightning\n",
    "#kaggle = input(\"Are you on Kaggle? Enter 'T' for True or 'F' for False: \")\n",
    "kaggle = False\n",
    "if gdrive:\n",
    "    import os\n",
    "\n",
    "    # Change to the desired directory:\n",
    "    os.chdir('/content/drive/MyDrive/TESI/TESI/notebooks')\n",
    "\n",
    "    # Verify the current directory:\n",
    "    print(os.getcwd())\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "# Import the set_global_seed function or define it if not available\n",
    "try:\n",
    "    from utils.reproducibility_functions import set_global_seed\n",
    "    set_global_seed(42)\n",
    "except (ImportError, NameError) as e:\n",
    "    # Define the function locally if import fails\n",
    "    def set_global_seed(seed):\n",
    "        \"\"\"Set seed for all sources of randomness to ensure reproducibility.\"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        # Set deterministic behavior for CUDA\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "        # Set monai determinism\n",
    "        set_determinism(seed=seed)\n",
    "        \n",
    "    set_global_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd202463",
   "metadata": {},
   "source": [
    "## PARAMETERS THAT WILL GET LOGGED ON MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d39574ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/4c/base.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.5, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 16, 'num_workers': 2}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 4, 'out_channels': 2, 'dropout_prob': 0.1, 'patch_size': [32, 32], 'library': 'torchvision'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Add the parent directory to Python path to make configs package accessible\n",
    "from configs.ConfigLoader import ConfigLoader\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "yaml_path = \"/home/zano/Documents/TESI/FOLDER_CINECA/configs/4c/base.yaml\"\n",
    "colab_yaml_path = \"/content/drive/MyDrive/TESI/FOLDER_CINECA/configs/base.yaml\"\n",
    "try:\n",
    "    cfg = ConfigLoader(yaml_path)\n",
    "except ValueError as e:\n",
    "    print(f\"Error loading configuration: {e}\")\n",
    "    print(\"Please ensure the YAML file contains all required sections.\")\n",
    "    raise\n",
    "\n",
    "# Set a fixed random seed for reproducibility for all the soruces of randomness\n",
    "# python, numpy, torch, monai\n",
    "SEED = 42\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "set_determinism(seed=SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.deterministic = True   # forces deterministic convolution algorithms\n",
    "cudnn.benchmark     = False  # turn off data-dependent autotune\n",
    "# monai.utils.set_determinism(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f545d",
   "metadata": {},
   "source": [
    "# UNIFIED DATA SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82403307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path for the MLflow tracking directory and its trash folder\n",
    "mlruns_path = \"/home/zano/Documents/TESI/FOLDER_CINECA/mlruns\"\n",
    "trash_path = os.path.join(mlruns_path, \".trash\")\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(trash_path, exist_ok=True)\n",
    "\n",
    "os.environ[\"DATA_ROOT\"] = \"/home/zano/Documents/TESI/FOLDER_CINECA/data\"\n",
    "os.environ[\"PROJ_ROOT\"] = \"/home/zano/Documents/TESI/FOLDER_CINECA\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"file:{mlruns_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66e58c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dir: /home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP\n",
      "base_dir: /home/zano/Documents/TESI/FOLDER_CINECA\n",
      "Linux detected, setting tracking URI\n",
      "Final Tracking URI: file:/home/zano/Documents/TESI/FOLDER_CINECA/mlruns\n",
      "Does the directory exist? True\n"
     ]
    }
   ],
   "source": [
    "from utils.directory_functions import get_data_and_base_directory\n",
    "num_input_channels = int(input(\"Enter the number of input channels (3 or 4): \"))\n",
    "data_dir, base_dir = get_data_and_base_directory(num_input_channels)\n",
    "print(\"data dir:\",data_dir)\n",
    "print(\"base_dir:\",base_dir)\n",
    "\n",
    "# start mlflow ui\n",
    "from utils.mlflow_functions import *\n",
    "from utils.directory_functions import *\n",
    "\n",
    "tracking_uri = get_tracking_uri()\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "start_mlflow_ui_locally(tracking_uri) # start mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d095c9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0842a9a00ff844bea8b869b46c1c631a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Class Set:', index=1, options=('MSA vs Control', 'MSA vs PD', 'MSA-P vs MSA-C', 'MSA-P v"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "CLASS_NAME_SETS = {\n",
    "    \"MSA vs Control\": [\"MSA\", \"control\"],\n",
    "    \"MSA vs PD\": [\"MSA\", \"PD\"],\n",
    "    \"MSA-P vs MSA-C\": [\"MSA-P\", \"MSA-C\"],\n",
    "    \"MSA-P vs PD\": [\"MSA-P\", \"PD\"],\n",
    "    \"PD vs MSA-P vs MSA-C\": [\"PD\", \"MSA-P\", \"MSA-C\"]\n",
    "}\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=list(CLASS_NAME_SETS.keys()),\n",
    "    value=\"MSA vs PD\",\n",
    "    description='Class Set:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def on_dropdown_change(change):\n",
    "    \"\"\"\n",
    "    Update the class_names variable when the dropdown selection changes.\n",
    "    \"\"\"\n",
    "    global class_names\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        class_names = CLASS_NAME_SETS[change['new']]\n",
    "        print(f\"class_names set to: {class_names}\")\n",
    "\n",
    "\n",
    "class_names = CLASS_NAME_SETS[dropdown.value]\n",
    "\n",
    "dropdown.observe(on_dropdown_change)\n",
    "\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7f7a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names set to: ['MSA', 'PD']\n"
     ]
    }
   ],
   "source": [
    "print(f\"class_names set to: {class_names}\") #chekc if the class names are set correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5be877",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34f85a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSA': '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA', 'PD': '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD'}\n",
      "Class directories:\n",
      "{'MSA': '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA', 'PD': '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD'}\n",
      "MSA images (before filtering): 'gh' count: 104, 'vaso' count: 0\n",
      "After removing 'vaso', MSA images: 'gh' count: 104, 'vaso' count: 0\n",
      "PD images (before filtering): 'gh' count: 60, 'vaso' count: 0\n",
      "After removing 'vaso', PD images: 'gh' count: 60, 'vaso' count: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking image shapes:\n",
      "MSA image: MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5435 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5435 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5463 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh 2 pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5745 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5745 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5753 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5753 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5753 gh3.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5776 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5776 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPIgrey 63x z2 gh pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5881 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5881 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5904 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5904 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5954 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5954 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5969 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5969 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5978 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5992 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5992 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5996 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5996 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6046 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6046 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6053 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6053 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6060 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6085 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6085 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6179 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6179 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6237.lif - 6237 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6237.lif - 6237 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6258.lif - 6258 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6258.lif - 6258 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6431.lif - 6431 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6431.lif - 6431 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6485.lif - 6485 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6485.lif - 6485 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6593.lif - 6593 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6593.lif - 6593 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7037.lif - 7037 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7037.lif - 7037 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7056.lif - 7056 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7056.lif - 7056 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7105.lif - 7105 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7105.lif - 7105 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7114.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7114.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7185.lif - 7185 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7185.lif - 7185 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7191.lif - 7191 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7191.lif - 7191 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7210.lif - 7210 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7210.lif - 7210 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7239.lif - 7239 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7239.lif - 7239 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7284.lif - 7284 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7284.lif - 7284 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7343.lif - 7343 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7343.lif - 7343 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7397.lif - 7397 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7407.lif - 7407 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7407.lif - 7407 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7579.lif - 7599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7597.lif - 7597 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7597.lif - 7597 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7689.lif - 7689 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7689.lif - 7689 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7857.lif - 7857 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7857.lif - 7857 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7893.lif - 7893 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7893.lif - 7893 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6323.lif - 6323 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6323.lif - 6323 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6340.lif - 6340 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6340.lif - 6340 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6366.lif - 6366 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6366.lif - 6366 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6651.lif - 6651 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6651.lif - 6651 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6696.lif - 6696 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6696.lif - 6696 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6749.lif - 6749 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6749.lif - 6749 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6773.lif - 6773 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6773.lif - 6773 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7132.lif - 7132 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7132.lif - 7132 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7155.lif - 7155 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7155.lif - 7155 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7229.lif - 7229 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7229.lif - 7229 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7318.lif - 7318 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7318.lif - 7318 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7544.lif - 7544 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7544.lif - 7544 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7781.lif - 7781 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7781.lif - 7781 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7787.lif - 7787 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7787.lif - 7787 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7811.lif - 7811 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7811.lif - 7811 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "\n",
      "Minority label for resampling purposes: 1\n",
      "\n",
      "Sample of image paths: ('/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif', '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif', '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif', '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6179 gh.tif.tif', '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif')\n",
      "Total images found: 164\n",
      "\n",
      "Sample of image paths (NumPy): ['/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6179 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif']\n",
      "[0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping each class to its directory\n",
    "class_dirs = {}\n",
    "three_classes = (len(class_names) == 3)\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dirs[class_name] = os.path.join(data_dir, class_name)\n",
    "    \n",
    "print(class_dirs)\n",
    "if three_classes:\n",
    "    class2_name, class1_name, class0_name = class_names\n",
    "    class2_dir, class1_dir, class0_dir = class_dirs.values()\n",
    "else:\n",
    "    class1_name, class0_name = class_names\n",
    "    class1_dir, class0_dir = class_dirs.values()\n",
    "\n",
    "print(\"Class directories:\")\n",
    "print(class_dirs)\n",
    "\n",
    "# Dictionaries to store image paths and counts for each class\n",
    "images_paths_dict = {}\n",
    "counts_dict = {}\n",
    "\n",
    "# Loop over classes to process each folder\n",
    "for class_name in class_names:\n",
    "    class_dir = class_dirs[class_name]\n",
    "    image_paths = sorted(glob.glob(os.path.join(class_dir, \"*.tif\")))\n",
    "    \n",
    "    # Check if images were found; otherwise raise an error\n",
    "    if not image_paths:\n",
    "        raise FileNotFoundError(f\"No TIFF image file found in {class_dir}\")\n",
    "    \n",
    "    # Count occurrences of 'gh' and 'vaso' in the filenames (using .lower() for case insensitivity)\n",
    "    gh_count = sum('gh' in os.path.basename(path).lower() for path in image_paths)\n",
    "    vaso_count = sum('vaso' in os.path.basename(path).lower() for path in image_paths)\n",
    "    print(f\"{class_name} images (before filtering): 'gh' count: {gh_count}, 'vaso' count: {vaso_count}\")\n",
    "    \n",
    "    # Filter out images that contain 'vaso' (if needed)\n",
    "    image_paths = [path for path in image_paths if 'vaso' not in os.path.basename(path).lower()]\n",
    "    gh_count_after = sum('gh' in os.path.basename(path).lower() for path in image_paths)\n",
    "    vaso_count_after = sum('vaso' in os.path.basename(path).lower() for path in image_paths)\n",
    "    print(f\"After removing 'vaso', {class_name} images: 'gh' count: {gh_count_after}, 'vaso' count: {vaso_count_after}\")\n",
    "    \n",
    "    # Store the filtered image paths and counts for later use\n",
    "    images_paths_dict[class_name] = image_paths\n",
    "    counts_dict[class_name] = {\"gh_count\": gh_count_after, \"vaso_count\": vaso_count_after}\n",
    "\n",
    "# Visualize the number of 'gh' counts per class in a bar chart\n",
    "plt.figure()\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of 'gh' occurrences\")\n",
    "plt.title(\"Number of 'gh' occurrences per class\")\n",
    "bar_heights = [counts_dict[cn][\"gh_count\"] for cn in class_names]\n",
    "bar_colors = ['red', 'blue', 'lightblue']\n",
    "plt.bar(class_names, bar_heights, color=bar_colors)\n",
    "plt.show()\n",
    "\n",
    "# --- Debug: Check image shapes after initial loading ---\n",
    "print(\"\\nChecking image shapes:\")\n",
    "for class_name, image_paths in images_paths_dict.items():\n",
    "    for path in image_paths:\n",
    "        img = tifffile.imread(path)  # Read image as a numpy array\n",
    "        print(f\"{class_name} image: {os.path.basename(path)}  dtype: {img.dtype}, shape: {img.shape}\")\n",
    "\n",
    "# Combine image paths and labels for the three classes; \n",
    "# the label here is simply the index of the class in class_names (0, 1, 2)\n",
    "combined = [] # List to store tuples of (image_path, label)\n",
    "for label, class_name in enumerate(class_names):\n",
    "    for path in images_paths_dict[class_name]:\n",
    "        combined.append((path, label))\n",
    "# print(\"\\nSample of combined image paths and labels:\", combined[:5])\n",
    "random.shuffle(combined)  # Shuffle the combined list to mix classes\n",
    "\n",
    "# Optionally, determine the minority label for resampling purposes\n",
    "counts = {label: len(images_paths_dict[class_name]) for label, class_name in enumerate(class_names)}\n",
    "minority_label = min(counts, key=lambda k: counts[k])\n",
    "print(f\"\\nMinority label for resampling purposes: {minority_label}\")\n",
    "\n",
    "# Unzip the combined list back into separate tuples (if needed)\n",
    "images_paths, labels = zip(*combined)\n",
    "print(\"\\nSample of image paths:\", images_paths[:5])\n",
    "print(\"Total images found:\", len(combined))\n",
    "\n",
    "# Optionally, convert to NumPy arrays (helpful for further processing or k-fold splitting)\n",
    "images_paths_np = np.array(images_paths)\n",
    "labels_np = np.array(labels)\n",
    "print(\"\\nSample of image paths (NumPy):\", images_paths_np[:5])\n",
    "print((labels_np))\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecece1",
   "metadata": {},
   "source": [
    "## TEST SET SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65f43807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images paths: ['/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5954 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7105.lif - 7105 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7689.lif - 7689 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5996 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7185.lif - 7185 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6258.lif - 6258 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7284.lif - 7284 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5745 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7105.lif - 7105 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6046 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6053 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5753 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5463 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7787.lif - 7787 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6485.lif - 6485 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7544.lif - 7544 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5881 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5996 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7407.lif - 7407 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7239.lif - 7239 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7191.lif - 7191 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5954 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5881 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6696.lif - 6696 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6053 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7210.lif - 7210 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5978 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6085 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6696.lif - 6696 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7132.lif - 7132 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7056.lif - 7056 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6485.lif - 6485 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6593.lif - 6593 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7037.lif - 7037 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7284.lif - 7284 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5753 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6431.lif - 6431 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7597.lif - 7597 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5745 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7544.lif - 7544 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6340.lif - 6340 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7343.lif - 7343 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5904 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7397.lif - 7397 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5969 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7781.lif - 7781 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6046 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7239.lif - 7239 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7318.lif - 7318 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6237.lif - 6237 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7857.lif - 7857 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7689.lif - 7689 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7155.lif - 7155 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7037.lif - 7037 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7893.lif - 7893 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7343.lif - 7343 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6237.lif - 6237 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6323.lif - 6323 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7229.lif - 7229 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPIgrey 63x z2 gh pinhole 1 z 05.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7857.lif - 7857 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6323.lif - 6323 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7781.lif - 7781 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6593.lif - 6593 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7811.lif - 7811 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7579.lif - 7599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6366.lif - 6366 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5992 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6749.lif - 6749 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6773.lif - 6773 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7056.lif - 7056 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6179 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7155.lif - 7155 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6651.lif - 6651 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6258.lif - 6258 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7210.lif - 7210 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7229.lif - 7229 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6340.lif - 6340 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6179 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7132.lif - 7132 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7114.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7191.lif - 7191 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7893.lif - 7893 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6060 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5776 gh.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7787.lif - 7787 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7114.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6749.lif - 6749 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6651.lif - 6651 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7811.lif - 7811 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5904 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7185.lif - 7185 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7318.lif - 7318 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6773.lif - 6773 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif']\n",
      "true test labels: [0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1]\n",
      "147 training images\n",
      "17 test images\n",
      "['/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5776 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7597.lif - 7597 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5992 gh2.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5435 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7407.lif - 7407 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6431.lif - 6431 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh 2 pinhole 1 z 05.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6366.lif - 6366 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5753 gh3.tif.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5969 gh2.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6085 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5435 gh.tif'\n",
      " '/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# NB the test set must be splitted BEFORE oversampling to avoid data leakage!\n",
    "# -------------------------------------------------------------------------\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#returns numpy arrays containing the paths to images and the labels\n",
    "# print(cfg.data_splitting[\"random_seed\"])\n",
    "train_images_paths, test_images_paths, train_true_labels, test_true_labels = train_test_split(\n",
    "    images_paths_np,\n",
    "    labels_np,\n",
    "    test_size = cfg.data_splitting[\"test_set_size\"],\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "test_images_paths_np = np.array(test_images_paths)\n",
    "test_true_labels_np = np.array(test_true_labels)\n",
    "print(\"train images paths:\", train_images_paths)\n",
    "print(\"true test labels:\", test_true_labels)\n",
    "# # For the cross-validation, we'll use train_images_paths and labels_temp\n",
    "train_images_paths_np = np.array(train_images_paths) #contains the images paths\n",
    "train_labels_np = np.array(train_true_labels) #contains the labels\n",
    "print(f\"{train_images_paths_np.shape[0]} training images\")\n",
    "print(f\"{len(test_images_paths)} test images\")\n",
    "#test_images_paths = [os.path.basename(path) for path in test_images_paths]\n",
    "print(test_images_paths)\n",
    "print(type(train_images_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1aac0",
   "metadata": {},
   "source": [
    "# SUPERVISED LEARNING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb61a7",
   "metadata": {},
   "source": [
    "## training augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59a83100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from /home/zano/Documents/TESI/TESI/configs/3c/base.yaml\n",
      "Configuration: {'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 7}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n",
      "Configuration loaded from /home/zano/Documents/TESI/TESI/configs/3c/densenet121.yaml\n",
      "Configuration: {'dataset': None, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.15, 'test_set_size': 0.1, 'num_folds': 7}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 32, 'num_workers': 2}, 'model': {'model_name': 'Densenet121', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1}, 'training': {'num_epochs': 125, 'early_stopping_patience': 40, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': None, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '1e-4', 'patience': 25}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}\n",
      "Using pretrained model: False\n",
      "Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is not supported by torchvision or is not pretrained\n",
      "Model Densenet121 not supported using custom transforms\n",
      "No fold-specific stats provided or incomplete; proceeding without specific normalization step (only ScaleIntensityd).\n",
      "Using MONAI for model instantiation.\n",
      "Building MONAI DenseNet121 with 3-channel input...\n",
      "DenseNet121(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (layers): Sequential(\n",
      "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu1): ReLU(inplace=True)\n",
      "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu2): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (class_layers): Sequential(\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (out): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from configs import ConfigLoader\n",
    "import utils.transformations_functions as tf\n",
    "import utils.monai_transformation_functions as mtf\n",
    "from configs.ConfigLoader import ConfigLoader\n",
    "\n",
    "from classes.ModelManager import ModelManager\n",
    "available_models = [\"densenet121\", \"resnet18\", \"resnet18\", \"resnet50\"]\n",
    "\n",
    "yaml_path = f\"/home/zano/Documents/TESI/TESI/configs/{num_input_channels}c/densenet121.yaml\"\n",
    "cfg = ConfigLoader(yaml_path) \n",
    "cfg.set_freezed_layer_index(None)\n",
    "transfer_learning = cfg.get_transfer_learning()\n",
    "pretrained_weights = \"imagenet\" if transfer_learning else None # 'microscopynet' or \"imagenet\" or 'imagenet-microscopynet' \n",
    "assert pretrained_weights in [None,\"microscopynet\", \"imagenet\", \"imagenet-microscopynet\"], \"pretrained_weights must be one of [None, 'microscopynet', 'imagenet', 'imagenet-microscopynet']\"\n",
    "            # indicates that the encoder was first pretrained on imagenet and then finetuned on microscopynet\n",
    "model_library = \"monai\" # or \"torchvision\" or \"monai\" pretraining dataset, either 'microscopynet' or \n",
    "assert model_library in [\"torchvision\", \"monai\"], \"model_library must be one of ['torchvision', 'monai']\"\n",
    "color_transforms = False\n",
    "train_transforms, val_transforms, test_transforms = tf.get_transforms(cfg, color_transforms=color_transforms)\n",
    "# train_transforms, val_transforms, test_transforms = mtf.get_transforms(cfg, color_transforms=color_transforms)\n",
    "model_manager = ModelManager(cfg, library=model_library)\n",
    "# Verify the number of unique labels in the dataset\n",
    "num_classes = len(np.unique(train_labels_np))\n",
    "# print(f\"Number of classes in the dataset: {num_classes}\")\n",
    "using_cosine_scheduler = False\n",
    "# Ensure the model's output matches the number of classes\n",
    "model, device = model_manager.setup_model(num_classes=num_classes, pretrained_weights=pretrained_weights)\n",
    "# model = model.to(device)  # First, move to the target device\n",
    "# model = model.float() \n",
    "print(model)\n",
    "# print(cfg.get_model_input_channels())\n",
    "\n",
    "# if model.__class__.__name__ == \"ViT\":\n",
    "#     print(\"Using ViT hence it requires custom training and validation functions\")\n",
    "#     train_epoch = train_epoch_vit\n",
    "#     val_epoch = val_epoch_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e13fa8",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624ec7",
   "metadata": {},
   "source": [
    "## NESTED K FOLD WITH HYP(LR) TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa19017",
   "metadata": {},
   "source": [
    "This code trains an image classifier using nested cross-validation.\n",
    "The outer loop evaluates the model's performance, while the inner loop (using Optuna) tunes the learning rate.\n",
    "For each outer fold, Optuna finds the best learning rate by minimizing validation loss on inner folds.\n",
    "The model is then retrained on the entire outer training set with this optimal learning rate and evaluated on the outer set. The final results are the average performance metrics across all outer folds. Techniques like oversampling, undersampling, and early stopping are used to improve the model's robustness and generalization.\n",
    "\n",
    "NB: total number of epoch: n_outer_folds  n_trials  n_inner_folds  inner_num_epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460ff5c",
   "metadata": {},
   "source": [
    "### outer test as test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55840646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "patient_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5edd2bfa-9143-414c-bcad-778c06cf7cb8",
       "rows": [
        [
         "0",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6599"
        ],
        [
         "1",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif",
         "1",
         "6008"
        ],
        [
         "2",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6008"
        ],
        [
         "3",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6179 gh.tif.tif",
         "0",
         "6179"
        ],
        [
         "4",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6791"
        ],
        [
         "5",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif",
         "1",
         "6577"
        ],
        [
         "6",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "7293"
        ],
        [
         "7",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5745 gh.tif.tif",
         "0",
         "5745"
        ],
        [
         "8",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6690"
        ],
        [
         "9",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7037.lif - 7037 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "7037"
        ],
        [
         "10",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5978 gh.tif.tif",
         "0",
         "5978"
        ],
        [
         "11",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "1",
         "6427"
        ],
        [
         "12",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "7461"
        ],
        [
         "13",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5776 gh.tif.tif",
         "0",
         "5776"
        ],
        [
         "14",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6459"
        ],
        [
         "15",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6383"
        ],
        [
         "16",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "4092"
        ],
        [
         "17",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif",
         "0",
         "5767"
        ],
        [
         "18",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "6326"
        ],
        [
         "19",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6424"
        ],
        [
         "20",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6053 gh2.tif",
         "0",
         "6053"
        ],
        [
         "21",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7114.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "7114"
        ],
        [
         "22",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif",
         "1",
         "6616"
        ],
        [
         "23",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7579.lif - 7599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "7579"
        ],
        [
         "24",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "4121"
        ],
        [
         "25",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5776 gh2.tif.tif",
         "0",
         "5776"
        ],
        [
         "26",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif",
         "0",
         "7179"
        ],
        [
         "27",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6337"
        ],
        [
         "28",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7037.lif - 7037 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif",
         "0",
         "7037"
        ],
        [
         "29",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7781.lif - 7781 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif",
         "1",
         "7781"
        ],
        [
         "30",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_7781.lif - 7781 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "7781"
        ],
        [
         "31",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "1",
         "6791"
        ],
        [
         "32",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif",
         "1",
         "6351"
        ],
        [
         "33",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "4121"
        ],
        [
         "34",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7893.lif - 7893 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "7893"
        ],
        [
         "35",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6431.lif - 6431 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6431"
        ],
        [
         "36",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5992 gh2.tif.tif",
         "0",
         "5992"
        ],
        [
         "37",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "7120"
        ],
        [
         "38",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5753 gh2.tif.tif",
         "0",
         "5753"
        ],
        [
         "39",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "1",
         "6571"
        ],
        [
         "40",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6326"
        ],
        [
         "41",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6179 gh2.tif.tif",
         "0",
         "6179"
        ],
        [
         "42",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6657"
        ],
        [
         "43",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_7689.lif - 7689 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif",
         "0",
         "7689"
        ],
        [
         "44",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6308"
        ],
        [
         "45",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6663"
        ],
        [
         "46",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "1",
         "6375"
        ],
        [
         "47",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/PD/MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "1",
         "6363"
        ],
        [
         "48",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "6663"
        ],
        [
         "49",
         "/home/zano/Documents/TESI/FOLDER_CINECA/data/3c_MIP/MSA/MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif",
         "0",
         "5767"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 164
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>1</td>\n",
       "      <td>6008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>1</td>\n",
       "      <td>6008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>6179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>1</td>\n",
       "      <td>6791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>6657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>7105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>5435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>/home/zano/Documents/TESI/FOLDER_CINECA/data/3...</td>\n",
       "      <td>1</td>\n",
       "      <td>7811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  label patient_id\n",
       "0    /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      0       6599\n",
       "1    /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      1       6008\n",
       "2    /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      1       6008\n",
       "3    /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      0       6179\n",
       "4    /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      1       6791\n",
       "..                                                 ...    ...        ...\n",
       "159  /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      0       6657\n",
       "160  /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      0       7105\n",
       "161  /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      0       5435\n",
       "162  /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      0       5969\n",
       "163  /home/zano/Documents/TESI/FOLDER_CINECA/data/3...      1       7811\n",
       "\n",
       "[164 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "patient_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d24cf3b9-fdb4-4065-bfc8-67d867b288f2",
       "rows": [
        [
         "0",
         "4092",
         "0"
        ],
        [
         "1",
         "4121",
         "0"
        ],
        [
         "2",
         "5358",
         "0"
        ],
        [
         "3",
         "5435",
         "0"
        ],
        [
         "4",
         "5463",
         "0"
        ],
        [
         "5",
         "5717",
         "0"
        ],
        [
         "6",
         "5745",
         "0"
        ],
        [
         "7",
         "5753",
         "0"
        ],
        [
         "8",
         "5767",
         "0"
        ],
        [
         "9",
         "5776",
         "0"
        ],
        [
         "10",
         "5878",
         "0"
        ],
        [
         "11",
         "5881",
         "0"
        ],
        [
         "12",
         "5904",
         "0"
        ],
        [
         "13",
         "5954",
         "0"
        ],
        [
         "14",
         "5969",
         "0"
        ],
        [
         "15",
         "5978",
         "0"
        ],
        [
         "16",
         "5992",
         "0"
        ],
        [
         "17",
         "5996",
         "0"
        ],
        [
         "18",
         "6008",
         "1"
        ],
        [
         "19",
         "6046",
         "0"
        ],
        [
         "20",
         "6053",
         "0"
        ],
        [
         "21",
         "6060",
         "0"
        ],
        [
         "22",
         "6085",
         "0"
        ],
        [
         "23",
         "6179",
         "0"
        ],
        [
         "24",
         "6237",
         "0"
        ],
        [
         "25",
         "6258",
         "0"
        ],
        [
         "26",
         "6308",
         "0"
        ],
        [
         "27",
         "6311",
         "0"
        ],
        [
         "28",
         "6323",
         "1"
        ],
        [
         "29",
         "6326",
         "0"
        ],
        [
         "30",
         "6337",
         "1"
        ],
        [
         "31",
         "6340",
         "1"
        ],
        [
         "32",
         "6351",
         "1"
        ],
        [
         "33",
         "6363",
         "1"
        ],
        [
         "34",
         "6366",
         "1"
        ],
        [
         "35",
         "6375",
         "1"
        ],
        [
         "36",
         "6383",
         "1"
        ],
        [
         "37",
         "6424",
         "1"
        ],
        [
         "38",
         "6427",
         "1"
        ],
        [
         "39",
         "6431",
         "0"
        ],
        [
         "40",
         "6459",
         "1"
        ],
        [
         "41",
         "6485",
         "0"
        ],
        [
         "42",
         "6571",
         "1"
        ],
        [
         "43",
         "6577",
         "1"
        ],
        [
         "44",
         "6593",
         "0"
        ],
        [
         "45",
         "6599",
         "0"
        ],
        [
         "46",
         "6616",
         "1"
        ],
        [
         "47",
         "6651",
         "1"
        ],
        [
         "48",
         "6657",
         "0"
        ],
        [
         "49",
         "6663",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 84
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>7787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>7811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>7893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  label\n",
       "0        4092      0\n",
       "1        4121      0\n",
       "2        5358      0\n",
       "3        5435      0\n",
       "4        5463      0\n",
       "..        ...    ...\n",
       "79       7781      1\n",
       "80       7787      1\n",
       "81       7811      1\n",
       "82       7857      0\n",
       "83       7893      0\n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patient IDs: ['4092' '4121' '5358' '5435' '5463' '5717' '5745' '5753' '5767' '5776'\n",
      " '5878' '5881' '5904' '5954' '5969' '5978' '5992' '5996' '6008' '6046'\n",
      " '6053' '6060' '6085' '6179' '6237' '6258' '6308' '6311' '6323' '6326'\n",
      " '6337' '6340' '6351' '6363' '6366' '6375' '6383' '6424' '6427' '6431'\n",
      " '6459' '6485' '6571' '6577' '6593' '6599' '6616' '6651' '6657' '6663'\n",
      " '6690' '6696' '6749' '6773' '6791' '7037' '7056' '7105' '7114' '7120'\n",
      " '7132' '7155' '7179' '7185' '7191' '7210' '7229' '7239' '7284' '7293'\n",
      " '7318' '7343' '7397' '7407' '7461' '7544' '7579' '7597' '7689' '7781'\n",
      " '7787' '7811' '7857' '7893']\n",
      "Number of unique patients: 84\n",
      "Unique patient labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 1 0 0 0 1 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "patient_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3fb32303-e255-4e37-948d-caba1b0a0ea6",
       "rows": [
        [
         "0",
         "4092",
         "0"
        ],
        [
         "1",
         "4121",
         "0"
        ],
        [
         "2",
         "5358",
         "0"
        ],
        [
         "3",
         "5435",
         "0"
        ],
        [
         "4",
         "5463",
         "0"
        ],
        [
         "5",
         "5717",
         "0"
        ],
        [
         "6",
         "5745",
         "0"
        ],
        [
         "7",
         "5753",
         "0"
        ],
        [
         "8",
         "5767",
         "0"
        ],
        [
         "9",
         "5776",
         "0"
        ],
        [
         "10",
         "5878",
         "0"
        ],
        [
         "11",
         "5881",
         "0"
        ],
        [
         "12",
         "5904",
         "0"
        ],
        [
         "13",
         "5954",
         "0"
        ],
        [
         "14",
         "5969",
         "0"
        ],
        [
         "15",
         "5978",
         "0"
        ],
        [
         "16",
         "5992",
         "0"
        ],
        [
         "17",
         "5996",
         "0"
        ],
        [
         "18",
         "6008",
         "1"
        ],
        [
         "19",
         "6046",
         "0"
        ],
        [
         "20",
         "6053",
         "0"
        ],
        [
         "21",
         "6060",
         "0"
        ],
        [
         "22",
         "6085",
         "0"
        ],
        [
         "23",
         "6179",
         "0"
        ],
        [
         "24",
         "6237",
         "0"
        ],
        [
         "25",
         "6258",
         "0"
        ],
        [
         "26",
         "6308",
         "0"
        ],
        [
         "27",
         "6311",
         "0"
        ],
        [
         "28",
         "6323",
         "1"
        ],
        [
         "29",
         "6326",
         "0"
        ],
        [
         "30",
         "6337",
         "1"
        ],
        [
         "31",
         "6340",
         "1"
        ],
        [
         "32",
         "6351",
         "1"
        ],
        [
         "33",
         "6363",
         "1"
        ],
        [
         "34",
         "6366",
         "1"
        ],
        [
         "35",
         "6375",
         "1"
        ],
        [
         "36",
         "6383",
         "1"
        ],
        [
         "37",
         "6424",
         "1"
        ],
        [
         "38",
         "6427",
         "1"
        ],
        [
         "39",
         "6431",
         "0"
        ],
        [
         "40",
         "6459",
         "1"
        ],
        [
         "41",
         "6485",
         "0"
        ],
        [
         "42",
         "6571",
         "1"
        ],
        [
         "43",
         "6577",
         "1"
        ],
        [
         "44",
         "6593",
         "0"
        ],
        [
         "45",
         "6599",
         "0"
        ],
        [
         "46",
         "6616",
         "1"
        ],
        [
         "47",
         "6651",
         "1"
        ],
        [
         "48",
         "6657",
         "0"
        ],
        [
         "49",
         "6663",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 84
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>7787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>7811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>7893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  label\n",
       "0        4092      0\n",
       "1        4121      0\n",
       "2        5358      0\n",
       "3        5435      0\n",
       "4        5463      0\n",
       "..        ...    ...\n",
       "79       7781      1\n",
       "80       7787      1\n",
       "81       7811      1\n",
       "82       7857      0\n",
       "83       7893      0\n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2 unique classes: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "def extract_patient_id(image_path):\n",
    "    # Example: parse from the file name\n",
    "    # In real code, you might have a different pattern\n",
    "    match = re.search(r'(\\d{4})', image_path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "# Build a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"image_path\": images_paths_np,\n",
    "    \"label\": labels_np\n",
    "})\n",
    "\n",
    "df[\"patient_id\"] = df[\"image_path\"].apply(extract_patient_id) # extract the patient id from the image path and create a new column\n",
    "display(df)\n",
    "\n",
    "# Ensure everything is string or int\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str) # convert the patient id to a string\n",
    "\n",
    "# Now group by patient to get a single label per patient.\n",
    "# If every patient truly has exactly one label, we can just take .first()\n",
    "# create a patient_label_df by filtering df patient_label_df( \"patient_id\",\"label\")\n",
    "patient_label_df = df.groupby(\"patient_id\", as_index=False)[\"label\"].first() # group by patient id and take the first label for each patient\n",
    "display(patient_label_df)\n",
    "\n",
    "unique_pat_ids = patient_label_df[\"patient_id\"].values  # we need these to stratify for patient\n",
    "print(f\"Unique patient IDs: {unique_pat_ids}\")\n",
    "print(f\"Number of unique patients: {len(unique_pat_ids)}\")\n",
    "pat_labels     = patient_label_df[\"label\"].values\n",
    "print(f\"Unique patient labels: {pat_labels}\")\n",
    "\n",
    "display(patient_label_df)\n",
    "\n",
    "# Determine the number of classes automatically from the dataset labels\n",
    "unique_overall_labels = np.unique(labels_np) # Or df['label'].unique()\n",
    "num_classes = len(unique_overall_labels)\n",
    "print(f\"Detected {num_classes} unique classes: {sorted(unique_overall_labels)}\")\n",
    "\n",
    "# Crucial Check: Ensure labels are 0, 1, ..., N-1 for nn.CrossEntropyLoss\n",
    "expected_labels = set(range(num_classes)) # set of all possible labels (0...N-1)\n",
    "actual_labels = set(unique_overall_labels) # set of all actual labels found in labels_np\n",
    "if expected_labels != actual_labels:\n",
    "    # Depending on your data, you might raise an error or attempt re-encoding.\n",
    "    # If labels are e.g., [1, 2, 3], they MUST be mapped to [0, 1, 2].\n",
    "    raise ValueError(f\"Labels must be contiguous integers starting from 0 (i.e., 0 to N-1). Found: {sorted(actual_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739102de",
   "metadata": {},
   "source": [
    "## TRAINING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63848e0c",
   "metadata": {},
   "source": [
    "### PRETRAINED IMAGENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58afa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT  = get_data_directory(num_input_channels)\n",
    "images, labels = [], []\n",
    "# get the images and labels from the data directory\n",
    "for lab, cname in enumerate(class_names):\n",
    "    for p in (DATA_ROOT / cname).glob(\"*.tif\"):\n",
    "        if \"vaso\" in p.name.lower():\n",
    "            continue\n",
    "        images.append(str(p)); labels.append(lab)\n",
    "if len(images) == 0:\n",
    "    raise FileNotFoundError(f\"No images found in {DATA_ROOT}. Check your dataset.\")\n",
    "\n",
    "images, labels = np.array(images), np.array(labels)\n",
    "\n",
    "tr_imgs, te_imgs, tr_y, te_y = train_test_split(\n",
    "    images, labels,\n",
    "    test_size=cfg.get_test_ratio(),\n",
    "    stratify=labels, random_state=42)\n",
    "\n",
    "df = pd.DataFrame({\"image_path\": images,\n",
    "                    \"label\": labels,\n",
    "                    \"patient_id\": [extract_patient_id(p) for p in images]})\n",
    "pat_df      = df.groupby(\"patient_id\").first().reset_index()\n",
    "unique_pats = pat_df[\"patient_id\"].values\n",
    "pat_labels  = pat_df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb861232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fold_idx(results, metric=\"test_balanced_acc\") -> int:\n",
    "    return int(np.argmax([r[metric] for r in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "728a93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 14:49:45,128] A new study created in memory with name: no-name-8cd4d96c-2476-4969-8492-f599baf53e8b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/base.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/densenet121.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.15, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 32, 'num_workers': 2}, 'model': {'model_name': 'Densenet121', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai', 'pretrained_weights': 'imagenet'}, 'training': {'num_epochs': 125, 'early_stopping_patience': 40, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': 263, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '1e-4', 'patience': 25}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}\n",
      "Number of classes in the dataset: 2\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Detected 2 unique classes.\n",
      "\n",
      "===== OUTER FOLD 1 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 1 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 1.\n",
      "--- Starting Hyperparameter Tuning for Fold 1 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 14:50:08,012] Trial 0 finished with value: 0.7106368839740753 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7106368839740753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 14:50:30,175] Trial 1 finished with value: 0.9496607879797618 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7106368839740753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 14:50:52,362] Trial 2 finished with value: 0.7174361646175385 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7106368839740753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 1 with LR=0.000047 ---\n",
      "X_train_es: (121,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 121, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 0 Epoch 1/125: Tr L: 0.7596, Tr Acc: 0.4740, Val L: 0.7869, Val Acc: 0.4091, Val Bal Acc: 0.5357, Val Roc AUC: 0.6161, Val_mcc: 0.1650, Val F1: 0.5517 lr: 0.000047\n",
      " Fold 0 Epoch 2/125: Tr L: 0.6794, Tr Acc: 0.5649, Val L: 0.7073, Val Acc: 0.5000, Val Bal Acc: 0.6071, Val Roc AUC: 0.6607, Val_mcc: 0.3004, Val F1: 0.5926 lr: 0.000047\n",
      " Fold 0 Epoch 3/125: Tr L: 0.6455, Tr Acc: 0.5844, Val L: 0.6697, Val Acc: 0.5000, Val Bal Acc: 0.5536, Val Roc AUC: 0.6696, Val_mcc: 0.1107, Val F1: 0.5217 lr: 0.000047\n",
      " Fold 0 Epoch 4/125: Tr L: 0.5695, Tr Acc: 0.7792, Val L: 0.6381, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7411, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 0 Epoch 5/125: Tr L: 0.5702, Tr Acc: 0.7338, Val L: 0.6068, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7768, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 6/125: Tr L: 0.5153, Tr Acc: 0.8052, Val L: 0.5879, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8125, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 7/125: Tr L: 0.4969, Tr Acc: 0.8247, Val L: 0.5836, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8036, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 8/125: Tr L: 0.4488, Tr Acc: 0.8766, Val L: 0.5798, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8125, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 9/125: Tr L: 0.4334, Tr Acc: 0.8571, Val L: 0.5764, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 10/125: Tr L: 0.4115, Tr Acc: 0.8701, Val L: 0.5648, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 11/125: Tr L: 0.3952, Tr Acc: 0.8766, Val L: 0.5528, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 12/125: Tr L: 0.3739, Tr Acc: 0.8961, Val L: 0.5386, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8214, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 13/125: Tr L: 0.3483, Tr Acc: 0.9156, Val L: 0.5243, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8393, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 14/125: Tr L: 0.3325, Tr Acc: 0.9026, Val L: 0.5166, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8929, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 15/125: Tr L: 0.3100, Tr Acc: 0.9156, Val L: 0.5169, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8839, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 0 Epoch 16/125: Tr L: 0.2963, Tr Acc: 0.9351, Val L: 0.5114, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8929, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 0 Epoch 17/125: Tr L: 0.2935, Tr Acc: 0.9091, Val L: 0.4997, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.9018, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 0 Epoch 18/125: Tr L: 0.3238, Tr Acc: 0.8831, Val L: 0.4782, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9018, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 19/125: Tr L: 0.2589, Tr Acc: 0.9221, Val L: 0.4677, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9018, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 20/125: Tr L: 0.2663, Tr Acc: 0.8961, Val L: 0.4517, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8929, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 21/125: Tr L: 0.2610, Tr Acc: 0.9351, Val L: 0.4499, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8929, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 22/125: Tr L: 0.2307, Tr Acc: 0.9481, Val L: 0.4509, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8929, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 23/125: Tr L: 0.2388, Tr Acc: 0.9156, Val L: 0.4515, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8929, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 24/125: Tr L: 0.2237, Tr Acc: 0.9416, Val L: 0.4393, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9018, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 25/125: Tr L: 0.2018, Tr Acc: 0.9675, Val L: 0.4420, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9018, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 0 Epoch 26/125: Tr L: 0.1980, Tr Acc: 0.9351, Val L: 0.4266, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9107, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 27/125: Tr L: 0.1983, Tr Acc: 0.9221, Val L: 0.4169, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 28/125: Tr L: 0.1819, Tr Acc: 0.9481, Val L: 0.4067, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 29/125: Tr L: 0.1659, Tr Acc: 0.9545, Val L: 0.3974, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9107, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 30/125: Tr L: 0.1789, Tr Acc: 0.9481, Val L: 0.3917, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 31/125: Tr L: 0.1489, Tr Acc: 0.9545, Val L: 0.3925, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 32/125: Tr L: 0.1494, Tr Acc: 0.9545, Val L: 0.4045, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 33/125: Tr L: 0.1343, Tr Acc: 0.9740, Val L: 0.4132, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 34/125: Tr L: 0.1311, Tr Acc: 0.9545, Val L: 0.3936, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9107, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 35/125: Tr L: 0.1354, Tr Acc: 0.9675, Val L: 0.3770, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9196, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 36/125: Tr L: 0.1186, Tr Acc: 0.9675, Val L: 0.3660, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9286, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 37/125: Tr L: 0.1141, Tr Acc: 0.9740, Val L: 0.3619, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9286, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 38/125: Tr L: 0.0999, Tr Acc: 0.9675, Val L: 0.3729, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9286, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 39/125: Tr L: 0.1231, Tr Acc: 0.9675, Val L: 0.3548, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9196, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 40/125: Tr L: 0.0989, Tr Acc: 0.9545, Val L: 0.3369, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.9375, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000047\n",
      " Fold 0 Epoch 41/125: Tr L: 0.1019, Tr Acc: 0.9675, Val L: 0.3311, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.9464, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000047\n",
      " Fold 0 Epoch 42/125: Tr L: 0.0792, Tr Acc: 0.9740, Val L: 0.3357, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 43/125: Tr L: 0.0874, Tr Acc: 0.9740, Val L: 0.3606, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 44/125: Tr L: 0.0881, Tr Acc: 0.9610, Val L: 0.4069, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 45/125: Tr L: 0.0994, Tr Acc: 0.9481, Val L: 0.4372, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 46/125: Tr L: 0.0674, Tr Acc: 0.9805, Val L: 0.3851, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 47/125: Tr L: 0.1045, Tr Acc: 0.9610, Val L: 0.3299, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 48/125: Tr L: 0.1016, Tr Acc: 0.9610, Val L: 0.3343, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 49/125: Tr L: 0.0761, Tr Acc: 0.9740, Val L: 0.3367, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 50/125: Tr L: 0.0743, Tr Acc: 0.9675, Val L: 0.3222, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 51/125: Tr L: 0.0492, Tr Acc: 0.9805, Val L: 0.3342, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 52/125: Tr L: 0.0864, Tr Acc: 0.9740, Val L: 0.3331, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 53/125: Tr L: 0.0673, Tr Acc: 0.9935, Val L: 0.3437, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 54/125: Tr L: 0.0573, Tr Acc: 0.9935, Val L: 0.3263, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9286, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 55/125: Tr L: 0.0637, Tr Acc: 0.9805, Val L: 0.3588, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 56/125: Tr L: 0.1065, Tr Acc: 0.9675, Val L: 0.3807, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 57/125: Tr L: 0.0514, Tr Acc: 0.9805, Val L: 0.3661, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 58/125: Tr L: 0.0812, Tr Acc: 0.9675, Val L: 0.3118, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 59/125: Tr L: 0.0639, Tr Acc: 0.9740, Val L: 0.2507, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 60/125: Tr L: 0.0721, Tr Acc: 0.9805, Val L: 0.2562, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 61/125: Tr L: 0.0508, Tr Acc: 0.9870, Val L: 0.2513, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 62/125: Tr L: 0.0895, Tr Acc: 0.9675, Val L: 0.2483, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 63/125: Tr L: 0.1066, Tr Acc: 0.9610, Val L: 0.2796, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 64/125: Tr L: 0.0774, Tr Acc: 0.9610, Val L: 0.3117, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9732, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 65/125: Tr L: 0.0464, Tr Acc: 0.9805, Val L: 0.3814, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 66/125: Tr L: 0.0526, Tr Acc: 0.9805, Val L: 0.3349, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 67/125: Tr L: 0.0265, Tr Acc: 0.9935, Val L: 0.3187, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 68/125: Tr L: 0.1014, Tr Acc: 0.9675, Val L: 0.3466, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 69/125: Tr L: 0.0329, Tr Acc: 0.9935, Val L: 0.3354, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 70/125: Tr L: 0.0415, Tr Acc: 0.9805, Val L: 0.3514, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 71/125: Tr L: 0.0704, Tr Acc: 0.9805, Val L: 0.3840, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 72/125: Tr L: 0.1160, Tr Acc: 0.9481, Val L: 0.3560, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 73/125: Tr L: 0.0406, Tr Acc: 0.9870, Val L: 0.3126, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 74/125: Tr L: 0.0557, Tr Acc: 0.9805, Val L: 0.2699, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 75/125: Tr L: 0.0452, Tr Acc: 0.9870, Val L: 0.2653, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9554, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 76/125: Tr L: 0.0557, Tr Acc: 0.9805, Val L: 0.2729, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9554, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 77/125: Tr L: 0.0776, Tr Acc: 0.9545, Val L: 0.3160, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 78/125: Tr L: 0.0436, Tr Acc: 0.9870, Val L: 0.3437, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 79/125: Tr L: 0.0633, Tr Acc: 0.9740, Val L: 0.3182, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 80/125: Tr L: 0.0436, Tr Acc: 0.9805, Val L: 0.2880, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 81/125: Tr L: 0.0501, Tr Acc: 0.9805, Val L: 0.2789, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9643, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 82/125: Tr L: 0.0147, Tr Acc: 1.0000, Val L: 0.2673, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9554, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 83/125: Tr L: 0.0506, Tr Acc: 0.9740, Val L: 0.2475, Val Acc: 0.9545, Val Bal Acc: 0.9643, Val Roc AUC: 0.9464, Val_mcc: 0.9085, Val F1: 0.9412 lr: 0.000047\n",
      " Fold 0 Epoch 84/125: Tr L: 0.0383, Tr Acc: 0.9935, Val L: 0.2450, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9643, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 85/125: Tr L: 0.0747, Tr Acc: 0.9740, Val L: 0.2544, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 86/125: Tr L: 0.0637, Tr Acc: 0.9610, Val L: 0.2983, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 87/125: Tr L: 0.0738, Tr Acc: 0.9740, Val L: 0.3668, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 88/125: Tr L: 0.0664, Tr Acc: 0.9870, Val L: 0.4038, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 89/125: Tr L: 0.0317, Tr Acc: 0.9870, Val L: 0.4077, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 90/125: Tr L: 0.0863, Tr Acc: 0.9740, Val L: 0.3729, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 91/125: Tr L: 0.0295, Tr Acc: 0.9935, Val L: 0.3652, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 92/125: Tr L: 0.0510, Tr Acc: 0.9870, Val L: 0.3835, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 93/125: Tr L: 0.0473, Tr Acc: 0.9870, Val L: 0.3312, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 94/125: Tr L: 0.0483, Tr Acc: 0.9870, Val L: 0.2861, Val Acc: 0.9545, Val Bal Acc: 0.9643, Val Roc AUC: 0.9554, Val_mcc: 0.9085, Val F1: 0.9412 lr: 0.000047\n",
      " Fold 0 Epoch 95/125: Tr L: 0.0112, Tr Acc: 1.0000, Val L: 0.2981, Val Acc: 0.9545, Val Bal Acc: 0.9643, Val Roc AUC: 0.9554, Val_mcc: 0.9085, Val F1: 0.9412 lr: 0.000047\n",
      " Fold 0 Epoch 96/125: Tr L: 0.0767, Tr Acc: 0.9675, Val L: 0.3248, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 97/125: Tr L: 0.0233, Tr Acc: 1.0000, Val L: 0.3536, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 98/125: Tr L: 0.0266, Tr Acc: 0.9870, Val L: 0.3530, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 99/125: Tr L: 0.0545, Tr Acc: 0.9740, Val L: 0.3312, Val Acc: 0.9545, Val Bal Acc: 0.9643, Val Roc AUC: 0.9375, Val_mcc: 0.9085, Val F1: 0.9412 lr: 0.000047\n",
      " Fold 0 Epoch 100/125: Tr L: 0.0547, Tr Acc: 0.9740, Val L: 0.3488, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 101/125: Tr L: 0.0516, Tr Acc: 0.9870, Val L: 0.3451, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 102/125: Tr L: 0.0342, Tr Acc: 0.9870, Val L: 0.3377, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 103/125: Tr L: 0.0507, Tr Acc: 0.9740, Val L: 0.3238, Val Acc: 0.9545, Val Bal Acc: 0.9643, Val Roc AUC: 0.9375, Val_mcc: 0.9085, Val F1: 0.9412 lr: 0.000047\n",
      " Fold 0 Epoch 104/125: Tr L: 0.0419, Tr Acc: 0.9805, Val L: 0.3121, Val Acc: 0.9545, Val Bal Acc: 0.9643, Val Roc AUC: 0.9375, Val_mcc: 0.9085, Val F1: 0.9412 lr: 0.000047\n",
      " Fold 0 Epoch 105/125: Tr L: 0.0959, Tr Acc: 0.9740, Val L: 0.3475, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 106/125: Tr L: 0.0599, Tr Acc: 0.9740, Val L: 0.3849, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9375, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 107/125: Tr L: 0.0260, Tr Acc: 0.9935, Val L: 0.4484, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 108/125: Tr L: 0.0120, Tr Acc: 1.0000, Val L: 0.3732, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 109/125: Tr L: 0.0240, Tr Acc: 0.9935, Val L: 0.3442, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 110/125: Tr L: 0.0450, Tr Acc: 0.9740, Val L: 0.3305, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000047\n",
      " Fold 0 Epoch 111/125: Tr L: 0.0275, Tr Acc: 0.9870, Val L: 0.3280, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 112/125: Tr L: 0.0642, Tr Acc: 0.9805, Val L: 0.3211, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9375, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 113/125: Tr L: 0.0149, Tr Acc: 1.0000, Val L: 0.3160, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 114/125: Tr L: 0.0252, Tr Acc: 0.9870, Val L: 0.3044, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 115/125: Tr L: 0.0616, Tr Acc: 0.9740, Val L: 0.2963, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 116/125: Tr L: 0.0377, Tr Acc: 0.9935, Val L: 0.3117, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 117/125: Tr L: 0.0260, Tr Acc: 0.9805, Val L: 0.3062, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 118/125: Tr L: 0.0407, Tr Acc: 0.9675, Val L: 0.3119, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 119/125: Tr L: 0.0070, Tr Acc: 1.0000, Val L: 0.3005, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 120/125: Tr L: 0.0150, Tr Acc: 0.9935, Val L: 0.3060, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 121/125: Tr L: 0.0144, Tr Acc: 1.0000, Val L: 0.3102, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9464, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 122/125: Tr L: 0.0111, Tr Acc: 0.9935, Val L: 0.3250, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      " Fold 0 Epoch 123/125: Tr L: 0.0235, Tr Acc: 0.9935, Val L: 0.2930, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      " Fold 0 Epoch 124/125: Tr L: 0.0152, Tr Acc: 1.0000, Val L: 0.3052, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9554, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      "Early stopping triggered at epoch 124 for fold 0\n",
      "--- Evaluating Fold 1 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 0: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 0 FINAL] Test Loss: 1.0792 | Test Acc: 0.5714 | test Balanced Acc: 0.5577 | test F1: 0.4706 | Test AUC: 0.6731 | Test MCC: 0.1132\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:01:44,048] A new study created in memory with name: no-name-2d5daf0d-c415-4f7c-a4f8-0165c8d5a7f8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 2 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 2 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 2.\n",
      "--- Starting Hyperparameter Tuning for Fold 2 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:02:06,036] Trial 0 finished with value: 0.6967304646968842 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6967304646968842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:02:27,752] Trial 1 finished with value: 1.1526218752066295 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6967304646968842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:02:49,499] Trial 2 finished with value: 0.7351290384928385 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6967304646968842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 2 with LR=0.000047 ---\n",
      "X_train_es: (120,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 120, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 1 Epoch 1/125: Tr L: 0.7307, Tr Acc: 0.4934, Val L: 0.8579, Val Acc: 0.3636, Val Bal Acc: 0.5000, Val Roc AUC: 0.5536, Val_mcc: 0.0000, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 1 Epoch 2/125: Tr L: 0.6595, Tr Acc: 0.5987, Val L: 0.7610, Val Acc: 0.4545, Val Bal Acc: 0.5714, Val Roc AUC: 0.6607, Val_mcc: 0.2390, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 1 Epoch 3/125: Tr L: 0.6087, Tr Acc: 0.6842, Val L: 0.6981, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.7054, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 1 Epoch 4/125: Tr L: 0.5542, Tr Acc: 0.7434, Val L: 0.6409, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.6875, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 5/125: Tr L: 0.5423, Tr Acc: 0.7829, Val L: 0.6018, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.7321, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 1 Epoch 6/125: Tr L: 0.4904, Tr Acc: 0.8684, Val L: 0.5753, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.7411, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 1 Epoch 7/125: Tr L: 0.4923, Tr Acc: 0.8158, Val L: 0.5608, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.7679, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 1 Epoch 8/125: Tr L: 0.4459, Tr Acc: 0.8487, Val L: 0.5552, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7679, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 1 Epoch 9/125: Tr L: 0.4321, Tr Acc: 0.8882, Val L: 0.5531, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7857, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 1 Epoch 10/125: Tr L: 0.4054, Tr Acc: 0.8947, Val L: 0.5517, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 1 Epoch 11/125: Tr L: 0.3742, Tr Acc: 0.8882, Val L: 0.5501, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 1 Epoch 12/125: Tr L: 0.3660, Tr Acc: 0.9013, Val L: 0.5580, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7946, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 1 Epoch 13/125: Tr L: 0.3744, Tr Acc: 0.8750, Val L: 0.5606, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7946, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 1 Epoch 14/125: Tr L: 0.3225, Tr Acc: 0.9013, Val L: 0.5550, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8036, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 1 Epoch 15/125: Tr L: 0.3487, Tr Acc: 0.8947, Val L: 0.5442, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7946, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 1 Epoch 16/125: Tr L: 0.3029, Tr Acc: 0.9276, Val L: 0.5460, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8036, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 1 Epoch 17/125: Tr L: 0.2780, Tr Acc: 0.9408, Val L: 0.5417, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8214, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 1 Epoch 18/125: Tr L: 0.3083, Tr Acc: 0.9013, Val L: 0.5318, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8214, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 19/125: Tr L: 0.2734, Tr Acc: 0.9079, Val L: 0.5276, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8214, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 20/125: Tr L: 0.2222, Tr Acc: 0.9539, Val L: 0.5189, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8125, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 21/125: Tr L: 0.2521, Tr Acc: 0.9211, Val L: 0.5249, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8214, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 22/125: Tr L: 0.2156, Tr Acc: 0.9342, Val L: 0.5068, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8304, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 23/125: Tr L: 0.2508, Tr Acc: 0.9342, Val L: 0.5045, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8214, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 24/125: Tr L: 0.2192, Tr Acc: 0.9342, Val L: 0.4987, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8304, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 25/125: Tr L: 0.2033, Tr Acc: 0.9145, Val L: 0.5161, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8393, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 26/125: Tr L: 0.1970, Tr Acc: 0.9408, Val L: 0.5130, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8393, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 27/125: Tr L: 0.2070, Tr Acc: 0.9342, Val L: 0.5099, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8393, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 28/125: Tr L: 0.1984, Tr Acc: 0.9474, Val L: 0.5231, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8393, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 29/125: Tr L: 0.1590, Tr Acc: 0.9474, Val L: 0.5330, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8393, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 30/125: Tr L: 0.1533, Tr Acc: 0.9408, Val L: 0.5367, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8482, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 31/125: Tr L: 0.1732, Tr Acc: 0.9474, Val L: 0.5530, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8482, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 32/125: Tr L: 0.1557, Tr Acc: 0.9408, Val L: 0.5443, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8214, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 33/125: Tr L: 0.1356, Tr Acc: 0.9408, Val L: 0.5203, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8393, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 34/125: Tr L: 0.1450, Tr Acc: 0.9408, Val L: 0.5253, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8304, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 35/125: Tr L: 0.1327, Tr Acc: 0.9474, Val L: 0.5201, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8482, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 36/125: Tr L: 0.1312, Tr Acc: 0.9276, Val L: 0.5173, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8482, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 37/125: Tr L: 0.1156, Tr Acc: 0.9737, Val L: 0.5525, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8482, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 38/125: Tr L: 0.1093, Tr Acc: 0.9803, Val L: 0.5727, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8482, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 39/125: Tr L: 0.0854, Tr Acc: 0.9934, Val L: 0.5706, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 40/125: Tr L: 0.1127, Tr Acc: 0.9605, Val L: 0.5559, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 41/125: Tr L: 0.0741, Tr Acc: 0.9934, Val L: 0.5604, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8571, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 42/125: Tr L: 0.0879, Tr Acc: 0.9737, Val L: 0.5733, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 43/125: Tr L: 0.1160, Tr Acc: 0.9671, Val L: 0.6186, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 44/125: Tr L: 0.0955, Tr Acc: 0.9605, Val L: 0.6305, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 45/125: Tr L: 0.1044, Tr Acc: 0.9474, Val L: 0.6474, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 46/125: Tr L: 0.0837, Tr Acc: 0.9737, Val L: 0.6457, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 47/125: Tr L: 0.0697, Tr Acc: 0.9803, Val L: 0.6008, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8482, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 48/125: Tr L: 0.0831, Tr Acc: 0.9737, Val L: 0.5810, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 1 Epoch 49/125: Tr L: 0.0783, Tr Acc: 0.9803, Val L: 0.5548, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8571, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 50/125: Tr L: 0.0761, Tr Acc: 0.9868, Val L: 0.5471, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8304, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 1 Epoch 51/125: Tr L: 0.0871, Tr Acc: 0.9671, Val L: 0.5829, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8304, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 1 Epoch 52/125: Tr L: 0.0679, Tr Acc: 0.9671, Val L: 0.6286, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8304, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 1 Epoch 53/125: Tr L: 0.1091, Tr Acc: 0.9474, Val L: 0.6847, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8482, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 54/125: Tr L: 0.0674, Tr Acc: 0.9671, Val L: 0.7524, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 55/125: Tr L: 0.1050, Tr Acc: 0.9408, Val L: 0.7944, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8571, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 1 Epoch 56/125: Tr L: 0.0812, Tr Acc: 0.9605, Val L: 0.7832, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8571, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 1 Epoch 57/125: Tr L: 0.0748, Tr Acc: 0.9803, Val L: 0.8011, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 58/125: Tr L: 0.0683, Tr Acc: 0.9803, Val L: 0.7459, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 59/125: Tr L: 0.0764, Tr Acc: 0.9737, Val L: 0.7023, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 60/125: Tr L: 0.0691, Tr Acc: 0.9671, Val L: 0.6547, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 61/125: Tr L: 0.0773, Tr Acc: 0.9671, Val L: 0.6231, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 62/125: Tr L: 0.0617, Tr Acc: 0.9803, Val L: 0.6564, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8661, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 63/125: Tr L: 0.1070, Tr Acc: 0.9605, Val L: 0.6849, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 1 Epoch 64/125: Tr L: 0.0491, Tr Acc: 0.9934, Val L: 0.6972, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      "Early stopping triggered at epoch 64 for fold 1\n",
      "--- Evaluating Fold 2 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 1: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 1 FINAL] Test Loss: 0.6459 | Test Acc: 0.7273 | test Balanced Acc: 0.7054 | test F1: 0.6250 | Test AUC: 0.7321 | Test MCC: 0.4107\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:08:20,801] A new study created in memory with name: no-name-e189f18d-414f-4ce8-a2a2-f3065aced266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 3 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 3 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 3.\n",
      "--- Starting Hyperparameter Tuning for Fold 3 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:08:42,997] Trial 0 finished with value: 0.6964853405952454 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6964853405952454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:09:05,030] Trial 1 finished with value: 0.9333692267537117 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6964853405952454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:09:27,091] Trial 2 finished with value: 0.7115181287129719 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6964853405952454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 3 with LR=0.000047 ---\n",
      "X_train_es: (121,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 121, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 2 Epoch 1/125: Tr L: 0.7196, Tr Acc: 0.5455, Val L: 0.7727, Val Acc: 0.4545, Val Bal Acc: 0.5714, Val Roc AUC: 0.6161, Val_mcc: 0.2390, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 2 Epoch 2/125: Tr L: 0.6422, Tr Acc: 0.6558, Val L: 0.7043, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.6875, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 2 Epoch 3/125: Tr L: 0.5867, Tr Acc: 0.6818, Val L: 0.6699, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.6429, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 2 Epoch 4/125: Tr L: 0.5192, Tr Acc: 0.7987, Val L: 0.6406, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6786, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 2 Epoch 5/125: Tr L: 0.5310, Tr Acc: 0.7857, Val L: 0.6264, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.6964, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 6/125: Tr L: 0.4845, Tr Acc: 0.8312, Val L: 0.6172, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7054, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 7/125: Tr L: 0.4649, Tr Acc: 0.8182, Val L: 0.6143, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7232, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 8/125: Tr L: 0.4331, Tr Acc: 0.8182, Val L: 0.6165, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 9/125: Tr L: 0.3964, Tr Acc: 0.8377, Val L: 0.6164, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7232, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 10/125: Tr L: 0.3857, Tr Acc: 0.8961, Val L: 0.6107, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 11/125: Tr L: 0.3497, Tr Acc: 0.9091, Val L: 0.6095, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 12/125: Tr L: 0.3325, Tr Acc: 0.9286, Val L: 0.6059, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 13/125: Tr L: 0.3073, Tr Acc: 0.9156, Val L: 0.6014, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 14/125: Tr L: 0.3047, Tr Acc: 0.9156, Val L: 0.6066, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7232, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 15/125: Tr L: 0.2723, Tr Acc: 0.9416, Val L: 0.6098, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7232, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 16/125: Tr L: 0.2667, Tr Acc: 0.9351, Val L: 0.6093, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 17/125: Tr L: 0.2485, Tr Acc: 0.9416, Val L: 0.6053, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7321, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 2 Epoch 18/125: Tr L: 0.2698, Tr Acc: 0.9156, Val L: 0.6092, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7321, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 2 Epoch 19/125: Tr L: 0.2434, Tr Acc: 0.9481, Val L: 0.6005, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7321, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 2 Epoch 20/125: Tr L: 0.2061, Tr Acc: 0.9610, Val L: 0.6059, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7321, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 2 Epoch 21/125: Tr L: 0.2031, Tr Acc: 0.9481, Val L: 0.6088, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 22/125: Tr L: 0.1986, Tr Acc: 0.9481, Val L: 0.6253, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 23/125: Tr L: 0.1895, Tr Acc: 0.9675, Val L: 0.6395, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 24/125: Tr L: 0.1728, Tr Acc: 0.9545, Val L: 0.6390, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 25/125: Tr L: 0.1918, Tr Acc: 0.9286, Val L: 0.6560, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 26/125: Tr L: 0.1702, Tr Acc: 0.9481, Val L: 0.6557, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 27/125: Tr L: 0.1648, Tr Acc: 0.9481, Val L: 0.6483, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 28/125: Tr L: 0.1553, Tr Acc: 0.9675, Val L: 0.6569, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 29/125: Tr L: 0.1285, Tr Acc: 0.9610, Val L: 0.6600, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 30/125: Tr L: 0.1450, Tr Acc: 0.9610, Val L: 0.6541, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 31/125: Tr L: 0.1073, Tr Acc: 0.9740, Val L: 0.6591, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 32/125: Tr L: 0.1207, Tr Acc: 0.9805, Val L: 0.6748, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7321, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 33/125: Tr L: 0.1252, Tr Acc: 0.9675, Val L: 0.6893, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 34/125: Tr L: 0.0970, Tr Acc: 0.9740, Val L: 0.6945, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 35/125: Tr L: 0.1165, Tr Acc: 0.9610, Val L: 0.7013, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7589, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 36/125: Tr L: 0.0869, Tr Acc: 0.9870, Val L: 0.7152, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7589, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 37/125: Tr L: 0.1062, Tr Acc: 0.9545, Val L: 0.7256, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 38/125: Tr L: 0.0716, Tr Acc: 0.9870, Val L: 0.7499, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 39/125: Tr L: 0.0804, Tr Acc: 0.9870, Val L: 0.7557, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 40/125: Tr L: 0.0659, Tr Acc: 0.9740, Val L: 0.7713, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 41/125: Tr L: 0.0932, Tr Acc: 0.9675, Val L: 0.7687, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 42/125: Tr L: 0.0657, Tr Acc: 0.9805, Val L: 0.7998, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 43/125: Tr L: 0.1053, Tr Acc: 0.9481, Val L: 0.8254, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 44/125: Tr L: 0.0666, Tr Acc: 0.9740, Val L: 0.8858, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7411, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 2 Epoch 45/125: Tr L: 0.0698, Tr Acc: 0.9805, Val L: 0.9066, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7500, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 2 Epoch 46/125: Tr L: 0.0491, Tr Acc: 0.9935, Val L: 0.8765, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 47/125: Tr L: 0.0699, Tr Acc: 0.9740, Val L: 0.8703, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 48/125: Tr L: 0.0796, Tr Acc: 0.9805, Val L: 0.8729, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 49/125: Tr L: 0.0894, Tr Acc: 0.9610, Val L: 0.8620, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 50/125: Tr L: 0.0621, Tr Acc: 0.9740, Val L: 0.8663, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 51/125: Tr L: 0.0752, Tr Acc: 0.9610, Val L: 0.8629, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 52/125: Tr L: 0.0390, Tr Acc: 1.0000, Val L: 0.8636, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 53/125: Tr L: 0.0612, Tr Acc: 0.9935, Val L: 0.8904, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 54/125: Tr L: 0.0739, Tr Acc: 0.9675, Val L: 0.8758, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 55/125: Tr L: 0.0771, Tr Acc: 0.9740, Val L: 0.8722, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 56/125: Tr L: 0.0721, Tr Acc: 0.9805, Val L: 0.8652, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 57/125: Tr L: 0.0415, Tr Acc: 0.9935, Val L: 0.8708, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7500, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 58/125: Tr L: 0.0572, Tr Acc: 0.9870, Val L: 0.8726, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7589, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      " Fold 2 Epoch 59/125: Tr L: 0.0631, Tr Acc: 0.9805, Val L: 0.8627, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.7589, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000024\n",
      "Early stopping triggered at epoch 59 for fold 2\n",
      "--- Evaluating Fold 3 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 2: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 2 FINAL] Test Loss: 0.9384 | Test Acc: 0.4762 | test Balanced Acc: 0.4567 | test F1: 0.3529 | Test AUC: 0.4135 | Test MCC: -0.0849\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:14:38,654] A new study created in memory with name: no-name-236c70a2-2654-483c-a21b-dd677b5397b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 4 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 4 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 4.\n",
      "--- Starting Hyperparameter Tuning for Fold 4 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:15:01,006] Trial 0 finished with value: 0.69625390569369 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.69625390569369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:15:23,169] Trial 1 finished with value: 0.8081077386935551 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.69625390569369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:15:45,289] Trial 2 finished with value: 0.6729472974936167 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6729472974936167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 4 with LR=0.000401 ---\n",
      "X_train_es: (120,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 120, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 3 Epoch 1/125: Tr L: 0.6341, Tr Acc: 0.6316, Val L: 0.6568, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6071, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000401\n",
      " Fold 3 Epoch 2/125: Tr L: 0.5245, Tr Acc: 0.7632, Val L: 0.5973, Val Acc: 0.6364, Val Bal Acc: 0.5804, Val Roc AUC: 0.7232, Val_mcc: 0.1736, Val F1: 0.4286 lr: 0.000401\n",
      " Fold 3 Epoch 3/125: Tr L: 0.3057, Tr Acc: 0.9079, Val L: 0.8379, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.7143, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 3 Epoch 4/125: Tr L: 0.2374, Tr Acc: 0.9013, Val L: 0.7824, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 5/125: Tr L: 0.1674, Tr Acc: 0.9408, Val L: 0.8920, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7321, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 6/125: Tr L: 0.1633, Tr Acc: 0.9342, Val L: 0.9386, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.7232, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 3 Epoch 7/125: Tr L: 0.1233, Tr Acc: 0.9408, Val L: 0.8403, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 8/125: Tr L: 0.1147, Tr Acc: 0.9605, Val L: 1.1090, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7411, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 9/125: Tr L: 0.0884, Tr Acc: 0.9539, Val L: 1.5858, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.7232, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 3 Epoch 10/125: Tr L: 0.1031, Tr Acc: 0.9605, Val L: 1.7113, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.7232, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 3 Epoch 11/125: Tr L: 0.1115, Tr Acc: 0.9539, Val L: 1.0091, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7768, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 12/125: Tr L: 0.1055, Tr Acc: 0.9474, Val L: 0.9900, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7500, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 3 Epoch 13/125: Tr L: 0.1222, Tr Acc: 0.9408, Val L: 1.0262, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 3 Epoch 14/125: Tr L: 0.0533, Tr Acc: 0.9803, Val L: 1.1562, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.8036, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 15/125: Tr L: 0.0996, Tr Acc: 0.9868, Val L: 1.3830, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.8125, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 16/125: Tr L: 0.0762, Tr Acc: 0.9803, Val L: 1.5137, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7946, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 17/125: Tr L: 0.0709, Tr Acc: 0.9671, Val L: 1.3368, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.8036, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 18/125: Tr L: 0.1023, Tr Acc: 0.9671, Val L: 1.0608, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 19/125: Tr L: 0.0653, Tr Acc: 0.9803, Val L: 1.0821, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.8036, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 3 Epoch 20/125: Tr L: 0.0895, Tr Acc: 0.9539, Val L: 1.6912, Val Acc: 0.6364, Val Bal Acc: 0.7143, Val Roc AUC: 0.7768, Val_mcc: 0.4629, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 21/125: Tr L: 0.1525, Tr Acc: 0.9276, Val L: 1.7683, Val Acc: 0.6364, Val Bal Acc: 0.7143, Val Roc AUC: 0.7589, Val_mcc: 0.4629, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 22/125: Tr L: 0.0483, Tr Acc: 0.9868, Val L: 1.2958, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7768, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 3 Epoch 23/125: Tr L: 0.0957, Tr Acc: 0.9605, Val L: 1.0837, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 24/125: Tr L: 0.0685, Tr Acc: 0.9539, Val L: 1.1630, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 3 Epoch 25/125: Tr L: 0.0833, Tr Acc: 0.9605, Val L: 1.1039, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 3 Epoch 26/125: Tr L: 0.0438, Tr Acc: 0.9803, Val L: 1.3774, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7768, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 27/125: Tr L: 0.0841, Tr Acc: 0.9671, Val L: 1.3959, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7679, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 28/125: Tr L: 0.1119, Tr Acc: 0.9671, Val L: 1.5449, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7500, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 29/125: Tr L: 0.0627, Tr Acc: 0.9803, Val L: 1.5567, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7321, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 3 Epoch 30/125: Tr L: 0.0408, Tr Acc: 0.9868, Val L: 1.5301, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7321, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 3 Epoch 31/125: Tr L: 0.0635, Tr Acc: 0.9868, Val L: 1.4721, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.7411, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 3 Epoch 32/125: Tr L: 0.0921, Tr Acc: 0.9671, Val L: 1.4149, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7411, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 3 Epoch 33/125: Tr L: 0.0619, Tr Acc: 0.9803, Val L: 1.3699, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7500, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 3 Epoch 34/125: Tr L: 0.0389, Tr Acc: 0.9803, Val L: 1.3782, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7500, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 3 Epoch 35/125: Tr L: 0.0383, Tr Acc: 0.9737, Val L: 1.4852, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7589, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 3 Epoch 36/125: Tr L: 0.0643, Tr Acc: 0.9605, Val L: 1.4912, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7679, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 3 Epoch 37/125: Tr L: 0.0346, Tr Acc: 0.9803, Val L: 1.4467, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.7768, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 3 Epoch 38/125: Tr L: 0.0313, Tr Acc: 0.9934, Val L: 1.4246, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.7768, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 3 Epoch 39/125: Tr L: 0.0263, Tr Acc: 0.9934, Val L: 1.4102, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 3 Epoch 40/125: Tr L: 0.0708, Tr Acc: 0.9671, Val L: 1.2912, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.7946, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 3 Epoch 41/125: Tr L: 0.0335, Tr Acc: 0.9934, Val L: 1.1400, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7946, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 3 Epoch 42/125: Tr L: 0.0291, Tr Acc: 0.9868, Val L: 1.1260, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.7946, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000201\n",
      "Early stopping triggered at epoch 42 for fold 3\n",
      "--- Evaluating Fold 4 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 3: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 3 FINAL] Test Loss: 0.6553 | Test Acc: 0.5455 | test Balanced Acc: 0.4821 | test F1: 0.2857 | Test AUC: 0.5804 | Test MCC: -0.0386\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:19:24,825] A new study created in memory with name: no-name-8c24d1c7-72e2-4576-945b-bbdfa5e5a8b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 5 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 5 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 5.\n",
      "--- Starting Hyperparameter Tuning for Fold 5 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:19:47,492] Trial 0 finished with value: 0.7004726231098175 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7004726231098175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:20:09,932] Trial 1 finished with value: 0.8757992163300514 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7004726231098175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:20:32,385] Trial 2 finished with value: 0.7487478454907734 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7004726231098175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 5 with LR=0.000047 ---\n",
      "X_train_es: (122,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 122, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 4 Epoch 1/125: Tr L: 0.7161, Tr Acc: 0.5263, Val L: 0.8222, Val Acc: 0.4545, Val Bal Acc: 0.5714, Val Roc AUC: 0.4196, Val_mcc: 0.2390, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 4 Epoch 2/125: Tr L: 0.6554, Tr Acc: 0.5987, Val L: 0.7689, Val Acc: 0.4545, Val Bal Acc: 0.5446, Val Roc AUC: 0.4911, Val_mcc: 0.1114, Val F1: 0.5385 lr: 0.000047\n",
      " Fold 4 Epoch 3/125: Tr L: 0.6147, Tr Acc: 0.6908, Val L: 0.7466, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.5357, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 4 Epoch 4/125: Tr L: 0.5397, Tr Acc: 0.7829, Val L: 0.7155, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.5625, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 5/125: Tr L: 0.5255, Tr Acc: 0.7961, Val L: 0.6851, Val Acc: 0.5000, Val Bal Acc: 0.4732, Val Roc AUC: 0.6071, Val_mcc: -0.0524, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 4 Epoch 6/125: Tr L: 0.4603, Tr Acc: 0.8882, Val L: 0.6666, Val Acc: 0.4545, Val Bal Acc: 0.4107, Val Roc AUC: 0.5982, Val_mcc: -0.1786, Val F1: 0.2500 lr: 0.000047\n",
      " Fold 4 Epoch 7/125: Tr L: 0.4594, Tr Acc: 0.8618, Val L: 0.6570, Val Acc: 0.4545, Val Bal Acc: 0.4107, Val Roc AUC: 0.5893, Val_mcc: -0.1786, Val F1: 0.2500 lr: 0.000047\n",
      " Fold 4 Epoch 8/125: Tr L: 0.4619, Tr Acc: 0.8421, Val L: 0.6655, Val Acc: 0.4545, Val Bal Acc: 0.4107, Val Roc AUC: 0.5893, Val_mcc: -0.1786, Val F1: 0.2500 lr: 0.000047\n",
      " Fold 4 Epoch 9/125: Tr L: 0.4192, Tr Acc: 0.8553, Val L: 0.6663, Val Acc: 0.5000, Val Bal Acc: 0.4732, Val Roc AUC: 0.5982, Val_mcc: -0.0524, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 4 Epoch 10/125: Tr L: 0.3917, Tr Acc: 0.8750, Val L: 0.6691, Val Acc: 0.5455, Val Bal Acc: 0.5357, Val Roc AUC: 0.5982, Val_mcc: 0.0690, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 11/125: Tr L: 0.3859, Tr Acc: 0.8816, Val L: 0.6610, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.5982, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 12/125: Tr L: 0.3667, Tr Acc: 0.8750, Val L: 0.6520, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.6250, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 13/125: Tr L: 0.3250, Tr Acc: 0.8882, Val L: 0.6380, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.6518, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 14/125: Tr L: 0.3383, Tr Acc: 0.9013, Val L: 0.6281, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.6429, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 15/125: Tr L: 0.3226, Tr Acc: 0.9145, Val L: 0.6239, Val Acc: 0.5455, Val Bal Acc: 0.5357, Val Roc AUC: 0.6607, Val_mcc: 0.0690, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 16/125: Tr L: 0.3100, Tr Acc: 0.9013, Val L: 0.6280, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6607, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 17/125: Tr L: 0.2874, Tr Acc: 0.9211, Val L: 0.6292, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6607, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 18/125: Tr L: 0.2997, Tr Acc: 0.9013, Val L: 0.6354, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.6429, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 4 Epoch 19/125: Tr L: 0.2920, Tr Acc: 0.9079, Val L: 0.6401, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6607, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 20/125: Tr L: 0.2392, Tr Acc: 0.9276, Val L: 0.6409, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.6607, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 4 Epoch 21/125: Tr L: 0.2413, Tr Acc: 0.9342, Val L: 0.6385, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6696, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 22/125: Tr L: 0.2205, Tr Acc: 0.9408, Val L: 0.6324, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6964, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 23/125: Tr L: 0.2417, Tr Acc: 0.9539, Val L: 0.6421, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6964, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 24/125: Tr L: 0.2076, Tr Acc: 0.9474, Val L: 0.6507, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6964, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 25/125: Tr L: 0.2141, Tr Acc: 0.9474, Val L: 0.6501, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6964, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 26/125: Tr L: 0.2071, Tr Acc: 0.9211, Val L: 0.6437, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6964, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 27/125: Tr L: 0.2003, Tr Acc: 0.9211, Val L: 0.6338, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6964, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 28/125: Tr L: 0.1990, Tr Acc: 0.9342, Val L: 0.6210, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.7143, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 29/125: Tr L: 0.1878, Tr Acc: 0.9474, Val L: 0.6250, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.7054, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 30/125: Tr L: 0.1600, Tr Acc: 0.9539, Val L: 0.6294, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.7143, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 31/125: Tr L: 0.1547, Tr Acc: 0.9605, Val L: 0.6261, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7321, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 32/125: Tr L: 0.1577, Tr Acc: 0.9408, Val L: 0.6115, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7500, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 33/125: Tr L: 0.1925, Tr Acc: 0.9211, Val L: 0.6108, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7589, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 34/125: Tr L: 0.1377, Tr Acc: 0.9539, Val L: 0.6214, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7589, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 35/125: Tr L: 0.1461, Tr Acc: 0.9539, Val L: 0.6504, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7768, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 36/125: Tr L: 0.1374, Tr Acc: 0.9342, Val L: 0.6492, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7768, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 37/125: Tr L: 0.1135, Tr Acc: 0.9671, Val L: 0.6641, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7857, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 38/125: Tr L: 0.1127, Tr Acc: 0.9605, Val L: 0.6727, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7768, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 39/125: Tr L: 0.0929, Tr Acc: 0.9737, Val L: 0.6576, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7768, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 40/125: Tr L: 0.1152, Tr Acc: 0.9605, Val L: 0.6307, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7768, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 41/125: Tr L: 0.0933, Tr Acc: 0.9803, Val L: 0.6281, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7679, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 42/125: Tr L: 0.1272, Tr Acc: 0.9474, Val L: 0.6101, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7857, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 43/125: Tr L: 0.1061, Tr Acc: 0.9605, Val L: 0.6212, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 44/125: Tr L: 0.0827, Tr Acc: 0.9737, Val L: 0.6309, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8036, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 45/125: Tr L: 0.1037, Tr Acc: 0.9539, Val L: 0.6429, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8036, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 46/125: Tr L: 0.0579, Tr Acc: 0.9934, Val L: 0.6500, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8036, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 47/125: Tr L: 0.0854, Tr Acc: 0.9737, Val L: 0.6044, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 48/125: Tr L: 0.0969, Tr Acc: 0.9605, Val L: 0.5780, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 49/125: Tr L: 0.0655, Tr Acc: 0.9737, Val L: 0.6173, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 50/125: Tr L: 0.0587, Tr Acc: 0.9868, Val L: 0.6102, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 51/125: Tr L: 0.1188, Tr Acc: 0.9474, Val L: 0.5951, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 52/125: Tr L: 0.0697, Tr Acc: 0.9671, Val L: 0.6268, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 53/125: Tr L: 0.0984, Tr Acc: 0.9803, Val L: 0.6730, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 54/125: Tr L: 0.0779, Tr Acc: 0.9671, Val L: 0.7096, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 55/125: Tr L: 0.0916, Tr Acc: 0.9605, Val L: 0.7230, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7857, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 56/125: Tr L: 0.0457, Tr Acc: 0.9803, Val L: 0.7313, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7857, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 57/125: Tr L: 0.0979, Tr Acc: 0.9671, Val L: 0.7313, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 58/125: Tr L: 0.0685, Tr Acc: 0.9671, Val L: 0.6900, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8125, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 59/125: Tr L: 0.0844, Tr Acc: 0.9737, Val L: 0.6220, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8571, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 60/125: Tr L: 0.0387, Tr Acc: 0.9868, Val L: 0.5909, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8571, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 61/125: Tr L: 0.0629, Tr Acc: 0.9737, Val L: 0.5615, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8661, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 4 Epoch 62/125: Tr L: 0.0541, Tr Acc: 0.9868, Val L: 0.5912, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8750, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 63/125: Tr L: 0.0744, Tr Acc: 0.9671, Val L: 0.6775, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8571, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 64/125: Tr L: 0.0651, Tr Acc: 0.9671, Val L: 0.7294, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8304, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 65/125: Tr L: 0.0598, Tr Acc: 0.9737, Val L: 0.7785, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8214, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 66/125: Tr L: 0.0611, Tr Acc: 0.9737, Val L: 0.8142, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 67/125: Tr L: 0.0575, Tr Acc: 0.9803, Val L: 0.7368, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 68/125: Tr L: 0.0586, Tr Acc: 0.9605, Val L: 0.6918, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 69/125: Tr L: 0.0342, Tr Acc: 0.9934, Val L: 0.6824, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 70/125: Tr L: 0.0695, Tr Acc: 0.9737, Val L: 0.7349, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8304, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 71/125: Tr L: 0.0478, Tr Acc: 0.9934, Val L: 0.7797, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8214, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 72/125: Tr L: 0.0484, Tr Acc: 0.9737, Val L: 0.8445, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.8125, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 73/125: Tr L: 0.0702, Tr Acc: 0.9737, Val L: 0.9233, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.8036, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 74/125: Tr L: 0.0454, Tr Acc: 0.9803, Val L: 0.9510, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.8036, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 75/125: Tr L: 0.0455, Tr Acc: 0.9803, Val L: 0.8662, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8125, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 76/125: Tr L: 0.0577, Tr Acc: 0.9803, Val L: 0.7225, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8482, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 77/125: Tr L: 0.0463, Tr Acc: 0.9934, Val L: 0.6360, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8482, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 4 Epoch 78/125: Tr L: 0.0658, Tr Acc: 0.9671, Val L: 0.6522, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8393, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 4 Epoch 79/125: Tr L: 0.0576, Tr Acc: 0.9737, Val L: 0.6419, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8393, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 4 Epoch 80/125: Tr L: 0.0483, Tr Acc: 0.9803, Val L: 0.6694, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8214, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 4 Epoch 81/125: Tr L: 0.0543, Tr Acc: 0.9868, Val L: 0.7292, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 82/125: Tr L: 0.0487, Tr Acc: 0.9803, Val L: 0.7895, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 83/125: Tr L: 0.0549, Tr Acc: 0.9803, Val L: 0.7977, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 84/125: Tr L: 0.0626, Tr Acc: 0.9803, Val L: 0.8312, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8304, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 85/125: Tr L: 0.0471, Tr Acc: 0.9934, Val L: 0.8331, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.8393, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 4 Epoch 86/125: Tr L: 0.0462, Tr Acc: 0.9803, Val L: 0.8246, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8393, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 87/125: Tr L: 0.0258, Tr Acc: 0.9934, Val L: 0.7731, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8393, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 4 Epoch 88/125: Tr L: 0.0575, Tr Acc: 0.9803, Val L: 0.7427, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8393, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 4 Epoch 89/125: Tr L: 0.0398, Tr Acc: 0.9803, Val L: 0.7595, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8393, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 4 Epoch 90/125: Tr L: 0.0233, Tr Acc: 1.0000, Val L: 0.7188, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8482, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 91/125: Tr L: 0.0894, Tr Acc: 0.9605, Val L: 0.7259, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 92/125: Tr L: 0.0321, Tr Acc: 0.9934, Val L: 0.7337, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 93/125: Tr L: 0.0428, Tr Acc: 0.9868, Val L: 0.7512, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 94/125: Tr L: 0.0760, Tr Acc: 0.9737, Val L: 0.7801, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 95/125: Tr L: 0.0230, Tr Acc: 0.9934, Val L: 0.7774, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 96/125: Tr L: 0.0366, Tr Acc: 0.9737, Val L: 0.7944, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 97/125: Tr L: 0.0269, Tr Acc: 0.9868, Val L: 0.8398, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 98/125: Tr L: 0.0652, Tr Acc: 0.9737, Val L: 0.8142, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 99/125: Tr L: 0.0479, Tr Acc: 0.9934, Val L: 0.8173, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 100/125: Tr L: 0.0553, Tr Acc: 0.9737, Val L: 0.7913, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 4 Epoch 101/125: Tr L: 0.0231, Tr Acc: 1.0000, Val L: 0.7476, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      "Early stopping triggered at epoch 101 for fold 4\n",
      "--- Evaluating Fold 5 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 4: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 4 FINAL] Test Loss: 0.6995 | Test Acc: 0.7500 | test Balanced Acc: 0.7262 | test F1: 0.6154 | Test AUC: 0.7619 | Test MCC: 0.4346\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:29:20,928] A new study created in memory with name: no-name-310b25f2-dc3e-4f6f-b876-684da14132b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 6 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 6 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 6.\n",
      "--- Starting Hyperparameter Tuning for Fold 6 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:29:42,802] Trial 0 finished with value: 0.681040088335673 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.681040088335673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:30:04,693] Trial 1 finished with value: 0.9635903810461361 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.681040088335673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:30:26,660] Trial 2 finished with value: 0.7147121727466583 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.681040088335673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 6 with LR=0.000047 ---\n",
      "X_train_es: (122,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 122, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 5 Epoch 1/125: Tr L: 0.7522, Tr Acc: 0.4934, Val L: 0.8160, Val Acc: 0.4545, Val Bal Acc: 0.5714, Val Roc AUC: 0.5446, Val_mcc: 0.2390, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 2/125: Tr L: 0.6791, Tr Acc: 0.5789, Val L: 0.7258, Val Acc: 0.5000, Val Bal Acc: 0.5804, Val Roc AUC: 0.6161, Val_mcc: 0.1845, Val F1: 0.5600 lr: 0.000047\n",
      " Fold 5 Epoch 3/125: Tr L: 0.6486, Tr Acc: 0.6645, Val L: 0.7092, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.5804, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 4/125: Tr L: 0.5505, Tr Acc: 0.7632, Val L: 0.6633, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.6875, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 5/125: Tr L: 0.5437, Tr Acc: 0.7829, Val L: 0.6392, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7054, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 6/125: Tr L: 0.4875, Tr Acc: 0.8487, Val L: 0.6291, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7054, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 7/125: Tr L: 0.4439, Tr Acc: 0.8947, Val L: 0.6299, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6964, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 8/125: Tr L: 0.4634, Tr Acc: 0.8289, Val L: 0.6301, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7143, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 9/125: Tr L: 0.4309, Tr Acc: 0.8487, Val L: 0.6333, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7054, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 10/125: Tr L: 0.4248, Tr Acc: 0.8421, Val L: 0.6423, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6518, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 11/125: Tr L: 0.4040, Tr Acc: 0.8553, Val L: 0.6492, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6429, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 12/125: Tr L: 0.3665, Tr Acc: 0.9013, Val L: 0.6583, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6429, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 13/125: Tr L: 0.3524, Tr Acc: 0.9079, Val L: 0.6667, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6518, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 14/125: Tr L: 0.3425, Tr Acc: 0.8882, Val L: 0.6654, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6518, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 15/125: Tr L: 0.3369, Tr Acc: 0.8882, Val L: 0.6658, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6607, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 16/125: Tr L: 0.3201, Tr Acc: 0.8947, Val L: 0.6725, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6429, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 17/125: Tr L: 0.3243, Tr Acc: 0.8816, Val L: 0.6935, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6429, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 18/125: Tr L: 0.2961, Tr Acc: 0.9079, Val L: 0.7017, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6429, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 19/125: Tr L: 0.2759, Tr Acc: 0.9474, Val L: 0.7096, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6339, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 20/125: Tr L: 0.2535, Tr Acc: 0.9408, Val L: 0.7180, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6250, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 21/125: Tr L: 0.2511, Tr Acc: 0.9276, Val L: 0.7290, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6250, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 22/125: Tr L: 0.2427, Tr Acc: 0.9408, Val L: 0.7450, Val Acc: 0.5455, Val Bal Acc: 0.4821, Val Roc AUC: 0.6250, Val_mcc: -0.0386, Val F1: 0.2857 lr: 0.000047\n",
      " Fold 5 Epoch 23/125: Tr L: 0.2667, Tr Acc: 0.9013, Val L: 0.7636, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6161, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 24/125: Tr L: 0.2354, Tr Acc: 0.9276, Val L: 0.7746, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6161, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 25/125: Tr L: 0.2083, Tr Acc: 0.9605, Val L: 0.7820, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6071, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 26/125: Tr L: 0.2015, Tr Acc: 0.9408, Val L: 0.8007, Val Acc: 0.5455, Val Bal Acc: 0.4821, Val Roc AUC: 0.6071, Val_mcc: -0.0386, Val F1: 0.2857 lr: 0.000047\n",
      " Fold 5 Epoch 27/125: Tr L: 0.2263, Tr Acc: 0.9145, Val L: 0.8181, Val Acc: 0.5455, Val Bal Acc: 0.4821, Val Roc AUC: 0.6071, Val_mcc: -0.0386, Val F1: 0.2857 lr: 0.000047\n",
      " Fold 5 Epoch 28/125: Tr L: 0.2034, Tr Acc: 0.9145, Val L: 0.8423, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6071, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 5 Epoch 29/125: Tr L: 0.1830, Tr Acc: 0.9474, Val L: 0.8478, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6071, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 30/125: Tr L: 0.1770, Tr Acc: 0.9408, Val L: 0.8751, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6071, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 31/125: Tr L: 0.1770, Tr Acc: 0.9474, Val L: 0.8807, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6071, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 32/125: Tr L: 0.1834, Tr Acc: 0.9079, Val L: 0.8910, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6071, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 5 Epoch 33/125: Tr L: 0.1487, Tr Acc: 0.9671, Val L: 0.8997, Val Acc: 0.5455, Val Bal Acc: 0.4821, Val Roc AUC: 0.6071, Val_mcc: -0.0386, Val F1: 0.2857 lr: 0.000024\n",
      " Fold 5 Epoch 34/125: Tr L: 0.1726, Tr Acc: 0.9342, Val L: 0.8939, Val Acc: 0.5455, Val Bal Acc: 0.4821, Val Roc AUC: 0.5982, Val_mcc: -0.0386, Val F1: 0.2857 lr: 0.000024\n",
      " Fold 5 Epoch 35/125: Tr L: 0.1492, Tr Acc: 0.9474, Val L: 0.8899, Val Acc: 0.5455, Val Bal Acc: 0.4821, Val Roc AUC: 0.6071, Val_mcc: -0.0386, Val F1: 0.2857 lr: 0.000024\n",
      " Fold 5 Epoch 36/125: Tr L: 0.1525, Tr Acc: 0.9408, Val L: 0.8991, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6071, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 5 Epoch 37/125: Tr L: 0.1457, Tr Acc: 0.9408, Val L: 0.9057, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6161, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 5 Epoch 38/125: Tr L: 0.1468, Tr Acc: 0.9671, Val L: 0.9214, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.5982, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000024\n",
      " Fold 5 Epoch 39/125: Tr L: 0.1095, Tr Acc: 0.9737, Val L: 0.9151, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.5982, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000024\n",
      " Fold 5 Epoch 40/125: Tr L: 0.1294, Tr Acc: 0.9671, Val L: 0.9204, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.6071, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 5 Epoch 41/125: Tr L: 0.0940, Tr Acc: 0.9803, Val L: 0.9501, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.5893, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000024\n",
      " Fold 5 Epoch 42/125: Tr L: 0.1089, Tr Acc: 0.9737, Val L: 0.9667, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.5893, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000024\n",
      " Fold 5 Epoch 43/125: Tr L: 0.1379, Tr Acc: 0.9539, Val L: 0.9891, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.5982, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000024\n",
      " Fold 5 Epoch 44/125: Tr L: 0.1174, Tr Acc: 0.9539, Val L: 1.0006, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.5804, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 5 Epoch 45/125: Tr L: 0.1086, Tr Acc: 0.9605, Val L: 1.0135, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.5893, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 5 Epoch 46/125: Tr L: 0.0870, Tr Acc: 0.9737, Val L: 1.0153, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.5982, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000024\n",
      "Early stopping triggered at epoch 46 for fold 5\n",
      "--- Evaluating Fold 6 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 5: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 5 FINAL] Test Loss: 0.6382 | Test Acc: 0.6500 | test Balanced Acc: 0.6548 | test F1: 0.5333 | Test AUC: 0.7024 | Test MCC: 0.2851\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:34:22,607] A new study created in memory with name: no-name-70bb9450-d70d-43d2-95f6-76a32511d636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 7 / 8 =====\n",
      "Outer Train images: 146 | Outer Test images: 18\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 7 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 7.\n",
      "--- Starting Hyperparameter Tuning for Fold 7 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:34:46,375] Trial 0 finished with value: 0.696690614024798 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.696690614024798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:35:09,767] Trial 1 finished with value: 0.8107650776704152 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.696690614024798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:35:33,129] Trial 2 finished with value: 0.69070369998614 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.69070369998614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 7 with LR=0.000401 ---\n",
      "X_train_es: (124,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 124, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 6 Epoch 1/125: Tr L: 0.6250, Tr Acc: 0.6125, Val L: 0.7695, Val Acc: 0.4545, Val Bal Acc: 0.5446, Val Roc AUC: 0.7143, Val_mcc: 0.1114, Val F1: 0.5385 lr: 0.000401\n",
      " Fold 6 Epoch 2/125: Tr L: 0.4241, Tr Acc: 0.7875, Val L: 0.7581, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.6875, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 6 Epoch 3/125: Tr L: 0.2883, Tr Acc: 0.8750, Val L: 0.8401, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.7054, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 6 Epoch 4/125: Tr L: 0.2143, Tr Acc: 0.9125, Val L: 0.8126, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7321, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 6 Epoch 5/125: Tr L: 0.1422, Tr Acc: 0.9437, Val L: 0.7434, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7679, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 6 Epoch 6/125: Tr L: 0.1443, Tr Acc: 0.9625, Val L: 0.7945, Val Acc: 0.5909, Val Bal Acc: 0.5179, Val Roc AUC: 0.7143, Val_mcc: 0.0410, Val F1: 0.3077 lr: 0.000401\n",
      " Fold 6 Epoch 7/125: Tr L: 0.1317, Tr Acc: 0.9437, Val L: 0.8492, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.6786, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000401\n",
      " Fold 6 Epoch 8/125: Tr L: 0.0928, Tr Acc: 0.9688, Val L: 0.9926, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.6786, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 6 Epoch 9/125: Tr L: 0.0874, Tr Acc: 0.9750, Val L: 1.2225, Val Acc: 0.5000, Val Bal Acc: 0.4732, Val Roc AUC: 0.6786, Val_mcc: -0.0524, Val F1: 0.3529 lr: 0.000401\n",
      " Fold 6 Epoch 10/125: Tr L: 0.0849, Tr Acc: 0.9625, Val L: 1.1782, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.6786, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 6 Epoch 11/125: Tr L: 0.1076, Tr Acc: 0.9688, Val L: 1.0520, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 6 Epoch 12/125: Tr L: 0.0543, Tr Acc: 0.9812, Val L: 0.9606, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.6964, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 6 Epoch 13/125: Tr L: 0.0267, Tr Acc: 0.9938, Val L: 0.9941, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.6429, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 6 Epoch 14/125: Tr L: 0.1239, Tr Acc: 0.9625, Val L: 1.1000, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.5982, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000401\n",
      " Fold 6 Epoch 15/125: Tr L: 0.0825, Tr Acc: 0.9688, Val L: 1.4261, Val Acc: 0.5000, Val Bal Acc: 0.5268, Val Roc AUC: 0.6696, Val_mcc: 0.0524, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 6 Epoch 16/125: Tr L: 0.1333, Tr Acc: 0.9563, Val L: 1.2013, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7321, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 6 Epoch 17/125: Tr L: 0.0548, Tr Acc: 0.9812, Val L: 1.2066, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.7321, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000401\n",
      " Fold 6 Epoch 18/125: Tr L: 0.1078, Tr Acc: 0.9563, Val L: 1.2383, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.7411, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000401\n",
      " Fold 6 Epoch 19/125: Tr L: 0.0417, Tr Acc: 0.9812, Val L: 1.1774, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7411, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 6 Epoch 20/125: Tr L: 0.0473, Tr Acc: 0.9750, Val L: 1.3049, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7232, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 6 Epoch 21/125: Tr L: 0.0344, Tr Acc: 0.9875, Val L: 1.1488, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7679, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 6 Epoch 22/125: Tr L: 0.0506, Tr Acc: 0.9875, Val L: 1.2597, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.7500, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000401\n",
      " Fold 6 Epoch 23/125: Tr L: 0.0223, Tr Acc: 0.9938, Val L: 1.2532, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.7411, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 6 Epoch 24/125: Tr L: 0.0882, Tr Acc: 0.9625, Val L: 1.3231, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.7500, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 6 Epoch 25/125: Tr L: 0.0245, Tr Acc: 0.9938, Val L: 1.6223, Val Acc: 0.6364, Val Bal Acc: 0.5536, Val Roc AUC: 0.6786, Val_mcc: 0.1336, Val F1: 0.3333 lr: 0.000401\n",
      " Fold 6 Epoch 26/125: Tr L: 0.1240, Tr Acc: 0.9625, Val L: 1.5848, Val Acc: 0.6364, Val Bal Acc: 0.5804, Val Roc AUC: 0.6786, Val_mcc: 0.1736, Val F1: 0.4286 lr: 0.000401\n",
      " Fold 6 Epoch 27/125: Tr L: 0.0178, Tr Acc: 0.9875, Val L: 1.4307, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.7054, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000401\n",
      " Fold 6 Epoch 28/125: Tr L: 0.0549, Tr Acc: 0.9875, Val L: 1.2216, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7500, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 6 Epoch 29/125: Tr L: 0.0483, Tr Acc: 0.9812, Val L: 1.1228, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7946, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 6 Epoch 30/125: Tr L: 0.0483, Tr Acc: 0.9812, Val L: 1.1564, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7768, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 6 Epoch 31/125: Tr L: 0.0513, Tr Acc: 0.9750, Val L: 1.2985, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7768, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 6 Epoch 32/125: Tr L: 0.0471, Tr Acc: 0.9750, Val L: 1.2102, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7589, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 6 Epoch 33/125: Tr L: 0.0724, Tr Acc: 0.9688, Val L: 1.2090, Val Acc: 0.6364, Val Bal Acc: 0.5804, Val Roc AUC: 0.7411, Val_mcc: 0.1736, Val F1: 0.4286 lr: 0.000201\n",
      " Fold 6 Epoch 34/125: Tr L: 0.0407, Tr Acc: 0.9938, Val L: 1.2286, Val Acc: 0.6364, Val Bal Acc: 0.5804, Val Roc AUC: 0.7411, Val_mcc: 0.1736, Val F1: 0.4286 lr: 0.000201\n",
      " Fold 6 Epoch 35/125: Tr L: 0.0441, Tr Acc: 0.9812, Val L: 1.2085, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7321, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 36/125: Tr L: 0.0557, Tr Acc: 0.9688, Val L: 1.2586, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7321, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 37/125: Tr L: 0.0629, Tr Acc: 0.9750, Val L: 1.3503, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7143, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 38/125: Tr L: 0.0499, Tr Acc: 0.9750, Val L: 1.4033, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7143, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 39/125: Tr L: 0.0703, Tr Acc: 0.9750, Val L: 1.3764, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7232, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 40/125: Tr L: 0.0641, Tr Acc: 0.9750, Val L: 1.3381, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7589, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 41/125: Tr L: 0.0553, Tr Acc: 0.9625, Val L: 1.2728, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7768, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 42/125: Tr L: 0.0260, Tr Acc: 1.0000, Val L: 1.1783, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7589, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 6 Epoch 43/125: Tr L: 0.0534, Tr Acc: 0.9625, Val L: 1.1628, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7589, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 6 Epoch 44/125: Tr L: 0.0369, Tr Acc: 0.9875, Val L: 1.1512, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7679, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 6 Epoch 45/125: Tr L: 0.0275, Tr Acc: 0.9812, Val L: 1.1869, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7411, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      "Early stopping triggered at epoch 45 for fold 6\n",
      "--- Evaluating Fold 7 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 6: {0: 10, 1: 8}\n",
      "percentage of classes in test set: 0    0.555556\n",
      "1    0.444444\n",
      "Name: count, dtype: float64\n",
      " [FOLD 6 FINAL] Test Loss: 1.2262 | Test Acc: 0.4444 | test Balanced Acc: 0.4500 | test F1: 0.4444 | Test AUC: 0.5375 | Test MCC: -0.1000\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:39:42,358] A new study created in memory with name: no-name-9ec80295-35a1-4343-a015-598830ef1466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 8 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 8 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 8.\n",
      "--- Starting Hyperparameter Tuning for Fold 8 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:40:05,161] Trial 0 finished with value: 0.6951141854127248 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6951141854127248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:40:27,756] Trial 1 finished with value: 1.4186303205788136 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6951141854127248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:40:50,570] Trial 2 finished with value: 0.7419175753990809 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6951141854127248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 8 with LR=0.000047 ---\n",
      "X_train_es: (122,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 122, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 6,955,906\n",
      "Trainable parameters: 2,162,178\n",
      "Non-trainable parameters: 4,793,728\n",
      "===========================\n",
      " Fold 7 Epoch 1/125: Tr L: 0.7310, Tr Acc: 0.5128, Val L: 0.8261, Val Acc: 0.4545, Val Bal Acc: 0.5714, Val Roc AUC: 0.4821, Val_mcc: 0.2390, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 7 Epoch 2/125: Tr L: 0.6528, Tr Acc: 0.6282, Val L: 0.7190, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.6161, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 7 Epoch 3/125: Tr L: 0.6082, Tr Acc: 0.6667, Val L: 0.6829, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.5804, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 7 Epoch 4/125: Tr L: 0.5621, Tr Acc: 0.7885, Val L: 0.6624, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6250, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 5/125: Tr L: 0.5182, Tr Acc: 0.8141, Val L: 0.6468, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6786, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 6/125: Tr L: 0.4764, Tr Acc: 0.8333, Val L: 0.6458, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 7 Epoch 7/125: Tr L: 0.4637, Tr Acc: 0.8718, Val L: 0.6476, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7321, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 7 Epoch 8/125: Tr L: 0.4653, Tr Acc: 0.8205, Val L: 0.6291, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7411, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 7 Epoch 9/125: Tr L: 0.4282, Tr Acc: 0.8590, Val L: 0.6159, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7500, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 7 Epoch 10/125: Tr L: 0.4088, Tr Acc: 0.8462, Val L: 0.6054, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7679, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 11/125: Tr L: 0.3632, Tr Acc: 0.8974, Val L: 0.5909, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7679, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 12/125: Tr L: 0.3752, Tr Acc: 0.8782, Val L: 0.5865, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 13/125: Tr L: 0.3452, Tr Acc: 0.8718, Val L: 0.5739, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 14/125: Tr L: 0.3520, Tr Acc: 0.8718, Val L: 0.5652, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 15/125: Tr L: 0.2913, Tr Acc: 0.9295, Val L: 0.5636, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 16/125: Tr L: 0.2797, Tr Acc: 0.9167, Val L: 0.5481, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 17/125: Tr L: 0.2809, Tr Acc: 0.9038, Val L: 0.5341, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8571, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 18/125: Tr L: 0.2746, Tr Acc: 0.8910, Val L: 0.5165, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8661, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 19/125: Tr L: 0.2636, Tr Acc: 0.9167, Val L: 0.5223, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8750, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 20/125: Tr L: 0.2280, Tr Acc: 0.9551, Val L: 0.5211, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8661, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 21/125: Tr L: 0.2051, Tr Acc: 0.9551, Val L: 0.4992, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8839, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 22/125: Tr L: 0.2120, Tr Acc: 0.9423, Val L: 0.4927, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8571, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 23/125: Tr L: 0.2556, Tr Acc: 0.8974, Val L: 0.4765, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8929, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 24/125: Tr L: 0.2041, Tr Acc: 0.9167, Val L: 0.4857, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9196, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 25/125: Tr L: 0.1875, Tr Acc: 0.9423, Val L: 0.4775, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9107, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 26/125: Tr L: 0.1697, Tr Acc: 0.9679, Val L: 0.4598, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9196, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 27/125: Tr L: 0.1550, Tr Acc: 0.9615, Val L: 0.4474, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9286, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 28/125: Tr L: 0.1502, Tr Acc: 0.9615, Val L: 0.4320, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.9196, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 29/125: Tr L: 0.1739, Tr Acc: 0.9423, Val L: 0.4758, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.9107, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 7 Epoch 30/125: Tr L: 0.1536, Tr Acc: 0.9487, Val L: 0.5014, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.9018, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 7 Epoch 31/125: Tr L: 0.1275, Tr Acc: 0.9615, Val L: 0.4556, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.9107, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 7 Epoch 32/125: Tr L: 0.1379, Tr Acc: 0.9551, Val L: 0.4340, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9196, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 7 Epoch 33/125: Tr L: 0.1393, Tr Acc: 0.9487, Val L: 0.4419, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9196, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 7 Epoch 34/125: Tr L: 0.1268, Tr Acc: 0.9423, Val L: 0.4693, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9107, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 35/125: Tr L: 0.1249, Tr Acc: 0.9551, Val L: 0.5185, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9107, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 36/125: Tr L: 0.1098, Tr Acc: 0.9615, Val L: 0.5102, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9286, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 37/125: Tr L: 0.1135, Tr Acc: 0.9487, Val L: 0.4764, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9375, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 38/125: Tr L: 0.1043, Tr Acc: 0.9679, Val L: 0.4329, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9286, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 39/125: Tr L: 0.1321, Tr Acc: 0.9423, Val L: 0.4490, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9286, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 40/125: Tr L: 0.1033, Tr Acc: 0.9487, Val L: 0.4628, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9107, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 41/125: Tr L: 0.1081, Tr Acc: 0.9487, Val L: 0.4171, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9286, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 42/125: Tr L: 0.0962, Tr Acc: 0.9679, Val L: 0.4420, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9107, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 43/125: Tr L: 0.0844, Tr Acc: 0.9744, Val L: 0.4076, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9018, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 44/125: Tr L: 0.0730, Tr Acc: 0.9744, Val L: 0.3815, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9196, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 7 Epoch 45/125: Tr L: 0.0859, Tr Acc: 0.9679, Val L: 0.3975, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9375, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 46/125: Tr L: 0.0868, Tr Acc: 0.9744, Val L: 0.4591, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9107, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 47/125: Tr L: 0.0720, Tr Acc: 0.9744, Val L: 0.4615, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9018, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 48/125: Tr L: 0.0822, Tr Acc: 0.9744, Val L: 0.4232, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9375, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 49/125: Tr L: 0.1103, Tr Acc: 0.9744, Val L: 0.3987, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9375, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 50/125: Tr L: 0.1002, Tr Acc: 0.9744, Val L: 0.4058, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9375, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 51/125: Tr L: 0.0779, Tr Acc: 0.9615, Val L: 0.3825, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9554, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 52/125: Tr L: 0.0904, Tr Acc: 0.9744, Val L: 0.3866, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9643, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 53/125: Tr L: 0.0925, Tr Acc: 0.9551, Val L: 0.4267, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9643, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 54/125: Tr L: 0.0480, Tr Acc: 1.0000, Val L: 0.4423, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9464, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 55/125: Tr L: 0.1062, Tr Acc: 0.9615, Val L: 0.4583, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.9464, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 7 Epoch 56/125: Tr L: 0.0592, Tr Acc: 0.9872, Val L: 0.4296, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9286, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 57/125: Tr L: 0.0735, Tr Acc: 0.9679, Val L: 0.4125, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9107, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 58/125: Tr L: 0.0665, Tr Acc: 0.9808, Val L: 0.3793, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9018, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 59/125: Tr L: 0.0503, Tr Acc: 0.9872, Val L: 0.3297, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9286, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 60/125: Tr L: 0.0571, Tr Acc: 0.9808, Val L: 0.3389, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9196, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 61/125: Tr L: 0.0773, Tr Acc: 0.9615, Val L: 0.3749, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9196, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 62/125: Tr L: 0.0629, Tr Acc: 0.9744, Val L: 0.4144, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9286, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 63/125: Tr L: 0.0620, Tr Acc: 0.9744, Val L: 0.4540, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9464, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 64/125: Tr L: 0.0544, Tr Acc: 0.9872, Val L: 0.4271, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 65/125: Tr L: 0.0405, Tr Acc: 0.9872, Val L: 0.4236, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 66/125: Tr L: 0.0667, Tr Acc: 0.9679, Val L: 0.4150, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 67/125: Tr L: 0.0516, Tr Acc: 0.9744, Val L: 0.3702, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 68/125: Tr L: 0.0611, Tr Acc: 0.9808, Val L: 0.4251, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9196, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 69/125: Tr L: 0.0620, Tr Acc: 0.9808, Val L: 0.4270, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9554, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 70/125: Tr L: 0.0439, Tr Acc: 0.9744, Val L: 0.3861, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 71/125: Tr L: 0.0678, Tr Acc: 0.9615, Val L: 0.3716, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9732, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 72/125: Tr L: 0.0583, Tr Acc: 0.9744, Val L: 0.3090, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 73/125: Tr L: 0.0478, Tr Acc: 0.9872, Val L: 0.2844, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 74/125: Tr L: 0.0405, Tr Acc: 0.9872, Val L: 0.2819, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 75/125: Tr L: 0.0496, Tr Acc: 0.9808, Val L: 0.2815, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9732, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 76/125: Tr L: 0.0419, Tr Acc: 0.9808, Val L: 0.3199, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 77/125: Tr L: 0.0428, Tr Acc: 0.9808, Val L: 0.3473, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9732, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 78/125: Tr L: 0.0618, Tr Acc: 0.9744, Val L: 0.3184, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9821, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 79/125: Tr L: 0.0290, Tr Acc: 0.9936, Val L: 0.3180, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9821, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 80/125: Tr L: 0.0267, Tr Acc: 0.9936, Val L: 0.3818, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9643, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 81/125: Tr L: 0.0419, Tr Acc: 0.9936, Val L: 0.4392, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9554, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 82/125: Tr L: 0.0795, Tr Acc: 0.9679, Val L: 0.4106, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 83/125: Tr L: 0.0322, Tr Acc: 0.9936, Val L: 0.3297, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 84/125: Tr L: 0.0484, Tr Acc: 0.9744, Val L: 0.2865, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 85/125: Tr L: 0.0471, Tr Acc: 0.9808, Val L: 0.2590, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9732, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 7 Epoch 86/125: Tr L: 0.0516, Tr Acc: 0.9808, Val L: 0.3026, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9554, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 87/125: Tr L: 0.0527, Tr Acc: 0.9808, Val L: 0.3771, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9643, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 88/125: Tr L: 0.0289, Tr Acc: 0.9936, Val L: 0.5168, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9732, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 89/125: Tr L: 0.0428, Tr Acc: 0.9808, Val L: 0.4994, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9554, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 90/125: Tr L: 0.0642, Tr Acc: 0.9808, Val L: 0.4082, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9643, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 91/125: Tr L: 0.0836, Tr Acc: 0.9679, Val L: 0.3598, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9643, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 92/125: Tr L: 0.0251, Tr Acc: 1.0000, Val L: 0.3288, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9554, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 93/125: Tr L: 0.0164, Tr Acc: 1.0000, Val L: 0.2840, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 7 Epoch 94/125: Tr L: 0.0187, Tr Acc: 1.0000, Val L: 0.3026, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 95/125: Tr L: 0.0251, Tr Acc: 0.9872, Val L: 0.3272, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 96/125: Tr L: 0.0290, Tr Acc: 0.9872, Val L: 0.3449, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 97/125: Tr L: 0.0400, Tr Acc: 0.9744, Val L: 0.3327, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 98/125: Tr L: 0.0392, Tr Acc: 0.9872, Val L: 0.3369, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9286, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 7 Epoch 99/125: Tr L: 0.0571, Tr Acc: 0.9744, Val L: 0.4193, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9286, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 100/125: Tr L: 0.1141, Tr Acc: 0.9615, Val L: 0.3608, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9286, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 101/125: Tr L: 0.0178, Tr Acc: 0.9936, Val L: 0.3008, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.9375, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 7 Epoch 102/125: Tr L: 0.0337, Tr Acc: 0.9872, Val L: 0.3083, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.9375, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 7 Epoch 103/125: Tr L: 0.0914, Tr Acc: 0.9679, Val L: 0.3668, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9375, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 7 Epoch 104/125: Tr L: 0.0676, Tr Acc: 0.9808, Val L: 0.3957, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 105/125: Tr L: 0.0466, Tr Acc: 0.9808, Val L: 0.4334, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9464, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 106/125: Tr L: 0.0193, Tr Acc: 1.0000, Val L: 0.4859, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9464, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 107/125: Tr L: 0.0292, Tr Acc: 0.9808, Val L: 0.4583, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9464, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 7 Epoch 108/125: Tr L: 0.0786, Tr Acc: 0.9615, Val L: 0.4531, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 109/125: Tr L: 0.0271, Tr Acc: 0.9872, Val L: 0.4655, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 110/125: Tr L: 0.0269, Tr Acc: 0.9936, Val L: 0.4216, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9375, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 111/125: Tr L: 0.0599, Tr Acc: 0.9808, Val L: 0.3706, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 7 Epoch 112/125: Tr L: 0.0210, Tr Acc: 0.9936, Val L: 0.3428, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9464, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      " Fold 7 Epoch 113/125: Tr L: 0.0560, Tr Acc: 0.9744, Val L: 0.3782, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 114/125: Tr L: 0.0164, Tr Acc: 0.9936, Val L: 0.4109, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 115/125: Tr L: 0.0251, Tr Acc: 0.9872, Val L: 0.3738, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 116/125: Tr L: 0.0154, Tr Acc: 1.0000, Val L: 0.3806, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 117/125: Tr L: 0.0225, Tr Acc: 0.9936, Val L: 0.3653, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9554, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 118/125: Tr L: 0.0187, Tr Acc: 0.9936, Val L: 0.3533, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 119/125: Tr L: 0.0322, Tr Acc: 0.9808, Val L: 0.3233, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 120/125: Tr L: 0.0523, Tr Acc: 0.9744, Val L: 0.3297, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.9464, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000024\n",
      " Fold 7 Epoch 121/125: Tr L: 0.0226, Tr Acc: 0.9872, Val L: 0.3533, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 122/125: Tr L: 0.0432, Tr Acc: 0.9744, Val L: 0.3254, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9464, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 123/125: Tr L: 0.0464, Tr Acc: 0.9744, Val L: 0.3277, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 124/125: Tr L: 0.0270, Tr Acc: 0.9936, Val L: 0.3179, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9643, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 7 Epoch 125/125: Tr L: 0.0913, Tr Acc: 0.9679, Val L: 0.2857, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9643, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      "Early stopping triggered at epoch 125 for fold 7\n",
      "--- Evaluating Fold 8 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Test set class counts for fold 7: {0: 12, 1: 8}\n",
      "percentage of classes in test set: 0    0.6\n",
      "1    0.4\n",
      "Name: count, dtype: float64\n",
      " [FOLD 7 FINAL] Test Loss: 0.9622 | Test Acc: 0.6500 | test Balanced Acc: 0.6667 | test F1: 0.6316 | Test AUC: 0.7396 | Test MCC: 0.3282\n",
      "model class name: DenseNet\n",
      "\n",
      "-------------------------------------------------\n",
      "Cross-validation results (outer folds):\n",
      "  Fold 0: Test Loss=1.0792, Acc=0.5714, F1=0.4706, Bal Acc=0.5577, AUC=0.6731, MCC=0.1132 (Best LR=0.000047)\n",
      "  Fold 1: Test Loss=0.6459, Acc=0.7273, F1=0.6250, Bal Acc=0.7054, AUC=0.7321, MCC=0.4107 (Best LR=0.000047)\n",
      "  Fold 2: Test Loss=0.9384, Acc=0.4762, F1=0.3529, Bal Acc=0.4567, AUC=0.4135, MCC=-0.0849 (Best LR=0.000047)\n",
      "  Fold 3: Test Loss=0.6553, Acc=0.5455, F1=0.2857, Bal Acc=0.4821, AUC=0.5804, MCC=-0.0386 (Best LR=0.000401)\n",
      "  Fold 4: Test Loss=0.6995, Acc=0.7500, F1=0.6154, Bal Acc=0.7262, AUC=0.7619, MCC=0.4346 (Best LR=0.000047)\n",
      "  Fold 5: Test Loss=0.6382, Acc=0.6500, F1=0.5333, Bal Acc=0.6548, AUC=0.7024, MCC=0.2851 (Best LR=0.000047)\n",
      "  Fold 6: Test Loss=1.2262, Acc=0.4444, F1=0.4444, Bal Acc=0.4500, AUC=0.5375, MCC=-0.1000 (Best LR=0.000401)\n",
      "  Fold 7: Test Loss=0.9622, Acc=0.6500, F1=0.6316, Bal Acc=0.6667, AUC=0.7396, MCC=0.3282 (Best LR=0.000047)\n",
      "\n",
      "--- Aggregate Results ---\n",
      "Avg Test Accuracy: 0.6018 +/- 0.1043\n",
      "Avg Test F1-Score: 0.4949 +/- 0.1218\n",
      "Avg Test Balanced Acc: 0.5874 +/- 0.1072\n",
      "Avg Test Precision: 0.4622 +/- 0.1019\n",
      "Avg Test Recall: 0.5417 +/- 0.1573\n",
      "Avg Test MCC: 0.1686 +/- 0.2094\n",
      "-------------------------------------------------\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet121...\n",
      "Freezing layers up to index: 263\n",
      "Run name: Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/16 15:52:08 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp07tax3vp/model/data, flavor: pytorch). Fall back to return ['torch==2.6.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/07/16 15:52:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, shape: torch.Size([25, 3, 224, 224])\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_0.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_1.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_2.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_3.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_4.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_5.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_6.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_7.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_8.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_9.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_10.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_11.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_12.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_13.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_14.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_15.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_16.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_17.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_18.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_19.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_20.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_21.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_22.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_23.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet121_oversamp_TL_pretrained:imagenet_freeze:263_torchvision_color_transforms:False_07-16_at:15-52-04/batch_0_img_24.png\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/base.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/densenet169.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.15, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 32, 'num_workers': 2}, 'model': {'model_name': 'Densenet169', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai', 'pretrained_weights': 'imagenet'}, 'training': {'num_epochs': 125, 'early_stopping_patience': 40, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': 308, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '1e-4', 'patience': 25}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}\n",
      "Number of classes in the dataset: 2\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:52:17,460] A new study created in memory with name: no-name-905f4f5e-6488-4973-abf8-4fc907734d06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2 unique classes.\n",
      "\n",
      "===== OUTER FOLD 1 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 1 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 1.\n",
      "--- Starting Hyperparameter Tuning for Fold 1 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:52:42,620] Trial 0 finished with value: 0.7133710384368896 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7133710384368896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:53:07,180] Trial 1 finished with value: 1.2877855971455574 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7133710384368896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 15:53:31,521] Trial 2 finished with value: 0.7450133015712102 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7133710384368896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 1 with LR=0.000047 ---\n",
      "X_train_es: (121,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 121, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 0 Epoch 1/125: Tr L: 0.6943, Tr Acc: 0.5455, Val L: 0.6777, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.5982, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 0 Epoch 2/125: Tr L: 0.5901, Tr Acc: 0.7208, Val L: 0.6826, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.6071, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 0 Epoch 3/125: Tr L: 0.5219, Tr Acc: 0.8377, Val L: 0.6504, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.6964, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 0 Epoch 4/125: Tr L: 0.4551, Tr Acc: 0.8506, Val L: 0.6303, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7411, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 0 Epoch 5/125: Tr L: 0.4191, Tr Acc: 0.8636, Val L: 0.6081, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7679, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 0 Epoch 6/125: Tr L: 0.3726, Tr Acc: 0.8961, Val L: 0.5890, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7679, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 7/125: Tr L: 0.3573, Tr Acc: 0.8831, Val L: 0.5897, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7857, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 8/125: Tr L: 0.2814, Tr Acc: 0.9351, Val L: 0.6210, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.7857, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 0 Epoch 9/125: Tr L: 0.2685, Tr Acc: 0.9351, Val L: 0.6566, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.8036, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 0 Epoch 10/125: Tr L: 0.2552, Tr Acc: 0.9416, Val L: 0.6262, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.8036, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 0 Epoch 11/125: Tr L: 0.2330, Tr Acc: 0.9221, Val L: 0.6150, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.7857, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 12/125: Tr L: 0.1974, Tr Acc: 0.9416, Val L: 0.5634, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 13/125: Tr L: 0.1758, Tr Acc: 0.9545, Val L: 0.5323, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 14/125: Tr L: 0.1838, Tr Acc: 0.9545, Val L: 0.5382, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 15/125: Tr L: 0.1518, Tr Acc: 0.9740, Val L: 0.5640, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8214, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 0 Epoch 16/125: Tr L: 0.1347, Tr Acc: 0.9675, Val L: 0.5792, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8036, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 0 Epoch 17/125: Tr L: 0.1452, Tr Acc: 0.9416, Val L: 0.5924, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8214, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 0 Epoch 18/125: Tr L: 0.1650, Tr Acc: 0.9351, Val L: 0.5293, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8482, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 19/125: Tr L: 0.1015, Tr Acc: 0.9805, Val L: 0.4626, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8571, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 20/125: Tr L: 0.1152, Tr Acc: 0.9675, Val L: 0.4283, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8839, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 21/125: Tr L: 0.1029, Tr Acc: 0.9610, Val L: 0.4418, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8839, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 22/125: Tr L: 0.0889, Tr Acc: 0.9740, Val L: 0.5287, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8839, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 0 Epoch 23/125: Tr L: 0.1366, Tr Acc: 0.9545, Val L: 0.5396, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8661, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 24/125: Tr L: 0.0685, Tr Acc: 0.9870, Val L: 0.4751, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8839, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 25/125: Tr L: 0.1110, Tr Acc: 0.9805, Val L: 0.6324, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8571, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 26/125: Tr L: 0.0859, Tr Acc: 0.9740, Val L: 0.7437, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8482, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 27/125: Tr L: 0.0627, Tr Acc: 0.9870, Val L: 0.5984, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8482, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 28/125: Tr L: 0.0872, Tr Acc: 0.9740, Val L: 0.4932, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8750, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 29/125: Tr L: 0.0845, Tr Acc: 0.9805, Val L: 0.5087, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8929, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 30/125: Tr L: 0.0604, Tr Acc: 0.9805, Val L: 0.5170, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8750, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 0 Epoch 31/125: Tr L: 0.0642, Tr Acc: 0.9805, Val L: 0.6112, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8750, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 0 Epoch 32/125: Tr L: 0.0638, Tr Acc: 0.9740, Val L: 0.6875, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.8661, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 0 Epoch 33/125: Tr L: 0.0525, Tr Acc: 0.9805, Val L: 0.5012, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8661, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 34/125: Tr L: 0.0526, Tr Acc: 0.9870, Val L: 0.4022, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.9018, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 35/125: Tr L: 0.0430, Tr Acc: 0.9870, Val L: 0.3854, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.9018, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 0 Epoch 36/125: Tr L: 0.0749, Tr Acc: 0.9805, Val L: 0.3954, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.9018, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 0 Epoch 37/125: Tr L: 0.0610, Tr Acc: 0.9805, Val L: 0.4695, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9196, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 38/125: Tr L: 0.0619, Tr Acc: 0.9740, Val L: 0.5416, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8929, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 39/125: Tr L: 0.0608, Tr Acc: 0.9805, Val L: 0.4072, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8929, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 40/125: Tr L: 0.0548, Tr Acc: 0.9740, Val L: 0.4320, Val Acc: 0.7727, Val Bal Acc: 0.7143, Val Roc AUC: 0.8929, Val_mcc: 0.4920, Val F1: 0.6154 lr: 0.000047\n",
      " Fold 0 Epoch 41/125: Tr L: 0.0767, Tr Acc: 0.9740, Val L: 0.4241, Val Acc: 0.7727, Val Bal Acc: 0.7143, Val Roc AUC: 0.9107, Val_mcc: 0.4920, Val F1: 0.6154 lr: 0.000047\n",
      " Fold 0 Epoch 42/125: Tr L: 0.0862, Tr Acc: 0.9740, Val L: 0.4255, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8929, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 0 Epoch 43/125: Tr L: 0.0364, Tr Acc: 0.9870, Val L: 0.7148, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8750, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000047\n",
      " Fold 0 Epoch 44/125: Tr L: 0.0526, Tr Acc: 0.9805, Val L: 1.0362, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8571, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 0 Epoch 45/125: Tr L: 0.0575, Tr Acc: 0.9675, Val L: 0.9114, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8482, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000047\n",
      " Fold 0 Epoch 46/125: Tr L: 0.0397, Tr Acc: 0.9805, Val L: 0.5691, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8750, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 47/125: Tr L: 0.0609, Tr Acc: 0.9740, Val L: 0.4430, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8929, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 0 Epoch 48/125: Tr L: 0.0449, Tr Acc: 0.9805, Val L: 0.4281, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8929, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 0 Epoch 49/125: Tr L: 0.0609, Tr Acc: 0.9740, Val L: 0.4241, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8929, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000047\n",
      " Fold 0 Epoch 50/125: Tr L: 0.0616, Tr Acc: 0.9675, Val L: 0.4916, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 51/125: Tr L: 0.0290, Tr Acc: 1.0000, Val L: 0.5094, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9018, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 52/125: Tr L: 0.0424, Tr Acc: 0.9805, Val L: 0.5186, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8929, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 53/125: Tr L: 0.0206, Tr Acc: 1.0000, Val L: 0.4606, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9196, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 54/125: Tr L: 0.0321, Tr Acc: 0.9870, Val L: 0.4435, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9107, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 55/125: Tr L: 0.0629, Tr Acc: 0.9805, Val L: 0.5035, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.9196, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000047\n",
      " Fold 0 Epoch 56/125: Tr L: 0.0592, Tr Acc: 0.9870, Val L: 0.5626, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9107, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 57/125: Tr L: 0.0421, Tr Acc: 0.9870, Val L: 0.6424, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 58/125: Tr L: 0.0565, Tr Acc: 0.9805, Val L: 0.6287, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9018, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000047\n",
      " Fold 0 Epoch 59/125: Tr L: 0.0570, Tr Acc: 0.9805, Val L: 0.5359, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9107, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 60/125: Tr L: 0.0591, Tr Acc: 0.9805, Val L: 0.4787, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9196, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 61/125: Tr L: 0.0272, Tr Acc: 0.9870, Val L: 0.4956, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9286, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000047\n",
      " Fold 0 Epoch 62/125: Tr L: 0.0587, Tr Acc: 0.9740, Val L: 0.4865, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9196, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      " Fold 0 Epoch 63/125: Tr L: 0.0421, Tr Acc: 0.9805, Val L: 0.5543, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9107, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      " Fold 0 Epoch 64/125: Tr L: 0.0298, Tr Acc: 0.9805, Val L: 0.5223, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000024\n",
      " Fold 0 Epoch 65/125: Tr L: 0.0271, Tr Acc: 0.9870, Val L: 0.5407, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9018, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 0 Epoch 66/125: Tr L: 0.0324, Tr Acc: 0.9870, Val L: 0.5789, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8929, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 0 Epoch 67/125: Tr L: 0.0154, Tr Acc: 0.9935, Val L: 0.6430, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9018, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 0 Epoch 68/125: Tr L: 0.0613, Tr Acc: 0.9675, Val L: 0.6694, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9107, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 0 Epoch 69/125: Tr L: 0.0135, Tr Acc: 0.9935, Val L: 0.6368, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9107, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 0 Epoch 70/125: Tr L: 0.0235, Tr Acc: 0.9870, Val L: 0.6940, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9196, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000024\n",
      " Fold 0 Epoch 71/125: Tr L: 0.0318, Tr Acc: 0.9870, Val L: 0.6896, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.9107, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000024\n",
      " Fold 0 Epoch 72/125: Tr L: 0.0659, Tr Acc: 0.9675, Val L: 0.5847, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.9107, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000024\n",
      " Fold 0 Epoch 73/125: Tr L: 0.0193, Tr Acc: 0.9935, Val L: 0.4656, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9107, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 74/125: Tr L: 0.0209, Tr Acc: 0.9870, Val L: 0.4143, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9196, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      " Fold 0 Epoch 75/125: Tr L: 0.0583, Tr Acc: 0.9870, Val L: 0.3990, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9196, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000024\n",
      "Early stopping triggered at epoch 75 for fold 0\n",
      "--- Evaluating Fold 1 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 0: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 0 FINAL] Test Loss: 0.7469 | Test Acc: 0.6667 | test Balanced Acc: 0.6587 | test F1: 0.5882 | Test AUC: 0.6923 | Test MCC: 0.3114\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:00:39,800] A new study created in memory with name: no-name-cc207364-a544-4972-abee-0ac99105664e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 2 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 2 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 2.\n",
      "--- Starting Hyperparameter Tuning for Fold 2 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:01:04,414] Trial 0 finished with value: 0.7129729290803273 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7129729290803273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:01:29,656] Trial 1 finished with value: 0.9233978142340977 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7129729290803273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:01:54,365] Trial 2 finished with value: 0.7096527864535649 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.7096527864535649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 2 with LR=0.000401 ---\n",
      "X_train_es: (120,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 120, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 1 Epoch 1/125: Tr L: 0.5934, Tr Acc: 0.6382, Val L: 1.2000, Val Acc: 0.3636, Val Bal Acc: 0.5000, Val Roc AUC: 0.6964, Val_mcc: 0.0000, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 1 Epoch 2/125: Tr L: 0.4459, Tr Acc: 0.7961, Val L: 0.6478, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8304, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 1 Epoch 3/125: Tr L: 0.2901, Tr Acc: 0.8487, Val L: 0.8327, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8125, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 4/125: Tr L: 0.1865, Tr Acc: 0.9342, Val L: 0.7563, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7768, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 5/125: Tr L: 0.1138, Tr Acc: 0.9474, Val L: 0.5614, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8571, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000401\n",
      " Fold 1 Epoch 6/125: Tr L: 0.1617, Tr Acc: 0.9211, Val L: 0.8125, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.8125, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 1 Epoch 7/125: Tr L: 0.1329, Tr Acc: 0.9539, Val L: 1.2593, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.7946, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 8/125: Tr L: 0.0831, Tr Acc: 0.9671, Val L: 1.9721, Val Acc: 0.6364, Val Bal Acc: 0.7143, Val Roc AUC: 0.7143, Val_mcc: 0.4629, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 9/125: Tr L: 0.0839, Tr Acc: 0.9737, Val L: 1.9279, Val Acc: 0.6818, Val Bal Acc: 0.7500, Val Roc AUC: 0.6696, Val_mcc: 0.5164, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 1 Epoch 10/125: Tr L: 0.1439, Tr Acc: 0.9539, Val L: 1.7533, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.7143, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 1 Epoch 11/125: Tr L: 0.1197, Tr Acc: 0.9474, Val L: 1.4274, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.7321, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 12/125: Tr L: 0.0984, Tr Acc: 0.9539, Val L: 1.2940, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7589, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 1 Epoch 13/125: Tr L: 0.1427, Tr Acc: 0.9539, Val L: 1.3285, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7857, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 14/125: Tr L: 0.1243, Tr Acc: 0.9474, Val L: 0.9665, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8125, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 15/125: Tr L: 0.0928, Tr Acc: 0.9474, Val L: 0.9433, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8839, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 16/125: Tr L: 0.1124, Tr Acc: 0.9539, Val L: 1.4132, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.7857, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 17/125: Tr L: 0.1019, Tr Acc: 0.9605, Val L: 1.5372, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.7768, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 18/125: Tr L: 0.0730, Tr Acc: 0.9539, Val L: 1.2702, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.7768, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 1 Epoch 19/125: Tr L: 0.0525, Tr Acc: 0.9803, Val L: 1.1761, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7768, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 20/125: Tr L: 0.0558, Tr Acc: 0.9737, Val L: 1.3976, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.7857, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 21/125: Tr L: 0.0782, Tr Acc: 0.9474, Val L: 1.3754, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7857, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 22/125: Tr L: 0.0636, Tr Acc: 0.9737, Val L: 1.8686, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.7054, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 1 Epoch 23/125: Tr L: 0.1622, Tr Acc: 0.9408, Val L: 2.2088, Val Acc: 0.5455, Val Bal Acc: 0.5357, Val Roc AUC: 0.6607, Val_mcc: 0.0690, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 1 Epoch 24/125: Tr L: 0.1728, Tr Acc: 0.9211, Val L: 1.8009, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.7589, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 25/125: Tr L: 0.0808, Tr Acc: 0.9605, Val L: 1.5624, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7857, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 26/125: Tr L: 0.0859, Tr Acc: 0.9539, Val L: 1.7244, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7589, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 27/125: Tr L: 0.1235, Tr Acc: 0.9408, Val L: 1.7806, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.6786, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 28/125: Tr L: 0.0612, Tr Acc: 0.9737, Val L: 1.3980, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.6964, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 29/125: Tr L: 0.0529, Tr Acc: 0.9868, Val L: 1.2355, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.7054, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 1 Epoch 30/125: Tr L: 0.0682, Tr Acc: 0.9671, Val L: 1.3394, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.7143, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 1 Epoch 31/125: Tr L: 0.0667, Tr Acc: 0.9671, Val L: 1.4314, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.7143, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 1 Epoch 32/125: Tr L: 0.0919, Tr Acc: 0.9474, Val L: 1.4566, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.6964, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 1 Epoch 33/125: Tr L: 0.0707, Tr Acc: 0.9605, Val L: 1.4498, Val Acc: 0.5909, Val Bal Acc: 0.5714, Val Roc AUC: 0.7321, Val_mcc: 0.1398, Val F1: 0.4706 lr: 0.000201\n",
      " Fold 1 Epoch 34/125: Tr L: 0.0739, Tr Acc: 0.9671, Val L: 1.4118, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7411, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000201\n",
      " Fold 1 Epoch 35/125: Tr L: 0.0751, Tr Acc: 0.9737, Val L: 1.2846, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7589, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000201\n",
      " Fold 1 Epoch 36/125: Tr L: 0.0426, Tr Acc: 0.9868, Val L: 1.1122, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7768, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 37/125: Tr L: 0.0374, Tr Acc: 0.9803, Val L: 0.9472, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8214, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 1 Epoch 38/125: Tr L: 0.0390, Tr Acc: 0.9868, Val L: 0.9117, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8304, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 1 Epoch 39/125: Tr L: 0.0195, Tr Acc: 0.9934, Val L: 0.9265, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8214, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 1 Epoch 40/125: Tr L: 0.0628, Tr Acc: 0.9671, Val L: 1.1408, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8393, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 1 Epoch 41/125: Tr L: 0.0231, Tr Acc: 0.9934, Val L: 1.3119, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8304, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000201\n",
      " Fold 1 Epoch 42/125: Tr L: 0.0367, Tr Acc: 0.9868, Val L: 1.3285, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8482, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000201\n",
      " Fold 1 Epoch 43/125: Tr L: 0.0750, Tr Acc: 0.9737, Val L: 1.4077, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8259, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 1 Epoch 44/125: Tr L: 0.0346, Tr Acc: 0.9868, Val L: 1.3822, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8393, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000201\n",
      " Fold 1 Epoch 45/125: Tr L: 0.0889, Tr Acc: 0.9539, Val L: 1.3617, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      "Early stopping triggered at epoch 45 for fold 1\n",
      "--- Evaluating Fold 2 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 1: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 1 FINAL] Test Loss: 1.4853 | Test Acc: 0.5909 | test Balanced Acc: 0.5714 | test F1: 0.4706 | Test AUC: 0.6339 | Test MCC: 0.1398\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:06:15,634] A new study created in memory with name: no-name-7d65b27a-a544-4727-89b7-87f5f7505c44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 3 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 3 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 3.\n",
      "--- Starting Hyperparameter Tuning for Fold 3 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:06:40,759] Trial 0 finished with value: 0.7201253275076549 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7201253275076549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:07:05,901] Trial 1 finished with value: 1.7262907430219154 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7201253275076549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:07:30,992] Trial 2 finished with value: 0.6194452991088232 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6194452991088232.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 3 with LR=0.000401 ---\n",
      "X_train_es: (121,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 121, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 2 Epoch 1/125: Tr L: 0.6343, Tr Acc: 0.6039, Val L: 0.7842, Val Acc: 0.4091, Val Bal Acc: 0.4821, Val Roc AUC: 0.5714, Val_mcc: -0.0410, Val F1: 0.4800 lr: 0.000401\n",
      " Fold 2 Epoch 2/125: Tr L: 0.2593, Tr Acc: 0.9156, Val L: 0.8507, Val Acc: 0.5455, Val Bal Acc: 0.5357, Val Roc AUC: 0.5982, Val_mcc: 0.0690, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 2 Epoch 3/125: Tr L: 0.2252, Tr Acc: 0.9026, Val L: 1.0137, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7321, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 2 Epoch 4/125: Tr L: 0.1442, Tr Acc: 0.9351, Val L: 1.2134, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7679, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 2 Epoch 5/125: Tr L: 0.0983, Tr Acc: 0.9610, Val L: 1.2789, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7500, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 2 Epoch 6/125: Tr L: 0.1202, Tr Acc: 0.9481, Val L: 0.7978, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7946, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000401\n",
      " Fold 2 Epoch 7/125: Tr L: 0.0764, Tr Acc: 0.9675, Val L: 1.3291, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.8214, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 2 Epoch 8/125: Tr L: 0.0451, Tr Acc: 0.9805, Val L: 3.7001, Val Acc: 0.5000, Val Bal Acc: 0.6071, Val Roc AUC: 0.7857, Val_mcc: 0.3004, Val F1: 0.5926 lr: 0.000401\n",
      " Fold 2 Epoch 9/125: Tr L: 0.2749, Tr Acc: 0.9416, Val L: 3.7840, Val Acc: 0.5000, Val Bal Acc: 0.6071, Val Roc AUC: 0.8080, Val_mcc: 0.3004, Val F1: 0.5926 lr: 0.000401\n",
      " Fold 2 Epoch 10/125: Tr L: 0.1101, Tr Acc: 0.9610, Val L: 1.9352, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8304, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 2 Epoch 11/125: Tr L: 0.0607, Tr Acc: 0.9805, Val L: 1.4014, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8393, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 12/125: Tr L: 0.0583, Tr Acc: 0.9740, Val L: 1.3299, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.7679, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 2 Epoch 13/125: Tr L: 0.0895, Tr Acc: 0.9740, Val L: 1.3051, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8125, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 14/125: Tr L: 0.1110, Tr Acc: 0.9545, Val L: 1.6402, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7857, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 2 Epoch 15/125: Tr L: 0.0846, Tr Acc: 0.9675, Val L: 1.4017, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7500, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 2 Epoch 16/125: Tr L: 0.0757, Tr Acc: 0.9610, Val L: 1.1534, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 2 Epoch 17/125: Tr L: 0.1495, Tr Acc: 0.9805, Val L: 1.3016, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 2 Epoch 18/125: Tr L: 0.1068, Tr Acc: 0.9481, Val L: 1.6528, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7679, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 2 Epoch 19/125: Tr L: 0.1048, Tr Acc: 0.9740, Val L: 2.1299, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7411, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 20/125: Tr L: 0.0640, Tr Acc: 0.9740, Val L: 2.4639, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7321, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 21/125: Tr L: 0.0450, Tr Acc: 0.9805, Val L: 2.6294, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7232, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 2 Epoch 22/125: Tr L: 0.0642, Tr Acc: 0.9740, Val L: 2.2216, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7589, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 23/125: Tr L: 0.0929, Tr Acc: 0.9675, Val L: 1.8741, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7768, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 24/125: Tr L: 0.0643, Tr Acc: 0.9740, Val L: 1.6305, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7589, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 25/125: Tr L: 0.0549, Tr Acc: 0.9740, Val L: 1.5055, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8036, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 26/125: Tr L: 0.0564, Tr Acc: 0.9610, Val L: 1.6399, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7857, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 27/125: Tr L: 0.0547, Tr Acc: 0.9805, Val L: 1.5837, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7500, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 2 Epoch 28/125: Tr L: 0.0411, Tr Acc: 0.9935, Val L: 1.6206, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7232, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 2 Epoch 29/125: Tr L: 0.0502, Tr Acc: 0.9740, Val L: 1.6907, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7232, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 30/125: Tr L: 0.0336, Tr Acc: 0.9870, Val L: 1.8608, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7321, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 2 Epoch 31/125: Tr L: 0.0420, Tr Acc: 0.9805, Val L: 1.8935, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 32/125: Tr L: 0.0342, Tr Acc: 0.9870, Val L: 1.9035, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 33/125: Tr L: 0.0441, Tr Acc: 0.9740, Val L: 1.9264, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7232, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 2 Epoch 34/125: Tr L: 0.0330, Tr Acc: 0.9935, Val L: 1.8246, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7232, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 2 Epoch 35/125: Tr L: 0.0537, Tr Acc: 0.9805, Val L: 1.7188, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7232, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 36/125: Tr L: 0.0233, Tr Acc: 0.9870, Val L: 1.7162, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 37/125: Tr L: 0.0266, Tr Acc: 0.9870, Val L: 1.7258, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7232, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 38/125: Tr L: 0.0307, Tr Acc: 0.9805, Val L: 2.0313, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7232, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 39/125: Tr L: 0.0158, Tr Acc: 0.9935, Val L: 2.2239, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 40/125: Tr L: 0.0070, Tr Acc: 1.0000, Val L: 2.2171, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 41/125: Tr L: 0.0559, Tr Acc: 0.9805, Val L: 2.1545, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      "Early stopping triggered at epoch 41 for fold 2\n",
      "--- Evaluating Fold 3 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 2: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 2 FINAL] Test Loss: 0.9844 | Test Acc: 0.2857 | test Balanced Acc: 0.3510 | test F1: 0.4000 | Test AUC: 0.2212 | Test MCC: -0.3686\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:11:34,215] A new study created in memory with name: no-name-64d15492-84ef-46f7-a91a-ce87d35d6c9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 4 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 4 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 4.\n",
      "--- Starting Hyperparameter Tuning for Fold 4 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:11:59,058] Trial 0 finished with value: 0.680461585521698 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.680461585521698.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:12:23,895] Trial 1 finished with value: 1.886740409148236 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.680461585521698.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:12:48,730] Trial 2 finished with value: 0.6771138856808345 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6771138856808345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 4 with LR=0.000401 ---\n",
      "X_train_es: (120,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 120, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 3 Epoch 1/125: Tr L: 0.6344, Tr Acc: 0.6316, Val L: 0.8514, Val Acc: 0.3636, Val Bal Acc: 0.4464, Val Roc AUC: 0.5179, Val_mcc: -0.1336, Val F1: 0.4615 lr: 0.000401\n",
      " Fold 3 Epoch 2/125: Tr L: 0.4671, Tr Acc: 0.7368, Val L: 0.7803, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.6339, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 3 Epoch 3/125: Tr L: 0.2082, Tr Acc: 0.9276, Val L: 1.3756, Val Acc: 0.4091, Val Bal Acc: 0.5089, Val Roc AUC: 0.6964, Val_mcc: 0.0250, Val F1: 0.5185 lr: 0.000401\n",
      " Fold 3 Epoch 4/125: Tr L: 0.1762, Tr Acc: 0.9276, Val L: 0.9939, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.7679, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 5/125: Tr L: 0.0958, Tr Acc: 0.9671, Val L: 1.0395, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8036, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 3 Epoch 6/125: Tr L: 0.1129, Tr Acc: 0.9474, Val L: 1.2714, Val Acc: 0.6364, Val Bal Acc: 0.7143, Val Roc AUC: 0.8393, Val_mcc: 0.4629, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 7/125: Tr L: 0.1347, Tr Acc: 0.9211, Val L: 1.1034, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.8571, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 3 Epoch 8/125: Tr L: 0.1578, Tr Acc: 0.9474, Val L: 1.3525, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8304, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 3 Epoch 9/125: Tr L: 0.0926, Tr Acc: 0.9671, Val L: 1.9825, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.7500, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 10/125: Tr L: 0.0859, Tr Acc: 0.9803, Val L: 1.6549, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8036, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 11/125: Tr L: 0.1042, Tr Acc: 0.9671, Val L: 0.7696, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8929, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 12/125: Tr L: 0.0997, Tr Acc: 0.9671, Val L: 0.6597, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8750, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000401\n",
      " Fold 3 Epoch 13/125: Tr L: 0.1266, Tr Acc: 0.9408, Val L: 0.8990, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8214, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 3 Epoch 14/125: Tr L: 0.0572, Tr Acc: 0.9671, Val L: 1.3545, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8214, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 15/125: Tr L: 0.1389, Tr Acc: 0.9408, Val L: 1.2527, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8482, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 16/125: Tr L: 0.0732, Tr Acc: 0.9671, Val L: 0.7583, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 17/125: Tr L: 0.0664, Tr Acc: 0.9737, Val L: 0.5542, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 18/125: Tr L: 0.0768, Tr Acc: 0.9671, Val L: 0.4138, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.9196, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000401\n",
      " Fold 3 Epoch 19/125: Tr L: 0.0515, Tr Acc: 0.9868, Val L: 0.7446, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 20/125: Tr L: 0.0614, Tr Acc: 0.9737, Val L: 1.0253, Val Acc: 0.8182, Val Bal Acc: 0.8571, Val Roc AUC: 0.8661, Val_mcc: 0.6901, Val F1: 0.8000 lr: 0.000401\n",
      " Fold 3 Epoch 21/125: Tr L: 0.1446, Tr Acc: 0.9539, Val L: 0.9505, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.9107, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 22/125: Tr L: 0.0619, Tr Acc: 0.9803, Val L: 0.7518, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8929, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000401\n",
      " Fold 3 Epoch 23/125: Tr L: 0.1214, Tr Acc: 0.9539, Val L: 1.3155, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.8125, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 24/125: Tr L: 0.1065, Tr Acc: 0.9474, Val L: 2.5146, Val Acc: 0.7273, Val Bal Acc: 0.7857, Val Roc AUC: 0.7857, Val_mcc: 0.5714, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 25/125: Tr L: 0.0758, Tr Acc: 0.9605, Val L: 1.2238, Val Acc: 0.7727, Val Bal Acc: 0.8214, Val Roc AUC: 0.8482, Val_mcc: 0.6290, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 3 Epoch 26/125: Tr L: 0.0774, Tr Acc: 0.9474, Val L: 1.0347, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8482, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000401\n",
      " Fold 3 Epoch 27/125: Tr L: 0.0582, Tr Acc: 0.9737, Val L: 1.1645, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.8304, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 3 Epoch 28/125: Tr L: 0.0981, Tr Acc: 0.9605, Val L: 0.9089, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.8482, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 3 Epoch 29/125: Tr L: 0.0505, Tr Acc: 0.9803, Val L: 0.6721, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8839, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 3 Epoch 30/125: Tr L: 0.0450, Tr Acc: 0.9868, Val L: 0.6373, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.9018, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 31/125: Tr L: 0.0418, Tr Acc: 0.9737, Val L: 0.7223, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.8929, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 32/125: Tr L: 0.0721, Tr Acc: 0.9539, Val L: 0.7383, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8661, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000401\n",
      " Fold 3 Epoch 33/125: Tr L: 0.0384, Tr Acc: 0.9868, Val L: 0.9882, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8393, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 3 Epoch 34/125: Tr L: 0.0517, Tr Acc: 0.9868, Val L: 0.9475, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.8750, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000401\n",
      " Fold 3 Epoch 35/125: Tr L: 0.0417, Tr Acc: 0.9737, Val L: 0.9595, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.8750, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000401\n",
      " Fold 3 Epoch 36/125: Tr L: 0.0676, Tr Acc: 0.9605, Val L: 0.7824, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8839, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 37/125: Tr L: 0.1243, Tr Acc: 0.9737, Val L: 0.9469, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.8839, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000401\n",
      " Fold 3 Epoch 38/125: Tr L: 0.0589, Tr Acc: 0.9671, Val L: 0.6910, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8839, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 39/125: Tr L: 0.0568, Tr Acc: 0.9671, Val L: 1.0935, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.8929, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 40/125: Tr L: 0.0581, Tr Acc: 0.9737, Val L: 1.4940, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.8795, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000401\n",
      " Fold 3 Epoch 41/125: Tr L: 0.0413, Tr Acc: 0.9868, Val L: 1.3085, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8661, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000401\n",
      " Fold 3 Epoch 42/125: Tr L: 0.0563, Tr Acc: 0.9605, Val L: 1.1770, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8661, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000401\n",
      " Fold 3 Epoch 43/125: Tr L: 0.0735, Tr Acc: 0.9671, Val L: 1.0985, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8482, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000401\n",
      " Fold 3 Epoch 44/125: Tr L: 0.0479, Tr Acc: 0.9737, Val L: 0.9730, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 45/125: Tr L: 0.0405, Tr Acc: 1.0000, Val L: 0.9300, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 3 Epoch 46/125: Tr L: 0.0483, Tr Acc: 0.9803, Val L: 0.9328, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 3 Epoch 47/125: Tr L: 0.0432, Tr Acc: 0.9671, Val L: 0.9087, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 3 Epoch 48/125: Tr L: 0.0642, Tr Acc: 0.9803, Val L: 0.9321, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 3 Epoch 49/125: Tr L: 0.0414, Tr Acc: 0.9803, Val L: 0.8961, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 3 Epoch 50/125: Tr L: 0.1004, Tr Acc: 0.9737, Val L: 0.8726, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8750, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 51/125: Tr L: 0.0496, Tr Acc: 0.9803, Val L: 0.8966, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8750, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 52/125: Tr L: 0.0771, Tr Acc: 0.9737, Val L: 0.9052, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8750, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000201\n",
      " Fold 3 Epoch 53/125: Tr L: 0.0342, Tr Acc: 0.9934, Val L: 0.9185, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.8750, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000201\n",
      " Fold 3 Epoch 54/125: Tr L: 0.0252, Tr Acc: 0.9934, Val L: 0.8279, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.8750, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000201\n",
      " Fold 3 Epoch 55/125: Tr L: 0.0668, Tr Acc: 0.9605, Val L: 0.7932, Val Acc: 0.9091, Val Bal Acc: 0.9286, Val Roc AUC: 0.8750, Val_mcc: 0.8281, Val F1: 0.8889 lr: 0.000201\n",
      " Fold 3 Epoch 56/125: Tr L: 0.0290, Tr Acc: 0.9803, Val L: 0.7146, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8750, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 57/125: Tr L: 0.0533, Tr Acc: 0.9803, Val L: 0.6694, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8750, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 3 Epoch 58/125: Tr L: 0.0570, Tr Acc: 0.9737, Val L: 0.6712, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8929, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000201\n",
      "Early stopping triggered at epoch 58 for fold 3\n",
      "--- Evaluating Fold 4 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 3: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 3 FINAL] Test Loss: 1.3917 | Test Acc: 0.5455 | test Balanced Acc: 0.5893 | test F1: 0.5455 | Test AUC: 0.5804 | Test MCC: 0.1786\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:18:28,248] A new study created in memory with name: no-name-ea2f2577-b8f9-4152-8653-13741c6e219e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 5 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 5 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 5.\n",
      "--- Starting Hyperparameter Tuning for Fold 5 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:18:53,103] Trial 0 finished with value: 0.7349719107151031 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7349719107151031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:19:17,791] Trial 1 finished with value: 1.0548797498146694 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7349719107151031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:19:42,286] Trial 2 finished with value: 0.7245377600193024 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.7245377600193024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 5 with LR=0.000401 ---\n",
      "X_train_es: (122,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 122, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 4 Epoch 1/125: Tr L: 0.6151, Tr Acc: 0.6250, Val L: 0.8584, Val Acc: 0.4091, Val Bal Acc: 0.5357, Val Roc AUC: 0.5625, Val_mcc: 0.1650, Val F1: 0.5517 lr: 0.000401\n",
      " Fold 4 Epoch 2/125: Tr L: 0.4130, Tr Acc: 0.7961, Val L: 0.7659, Val Acc: 0.4545, Val Bal Acc: 0.5179, Val Roc AUC: 0.5982, Val_mcc: 0.0386, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 4 Epoch 3/125: Tr L: 0.2387, Tr Acc: 0.9079, Val L: 1.2663, Val Acc: 0.5000, Val Bal Acc: 0.5804, Val Roc AUC: 0.6429, Val_mcc: 0.1845, Val F1: 0.5600 lr: 0.000401\n",
      " Fold 4 Epoch 4/125: Tr L: 0.2445, Tr Acc: 0.9145, Val L: 1.3338, Val Acc: 0.5455, Val Bal Acc: 0.6161, Val Roc AUC: 0.6786, Val_mcc: 0.2507, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 4 Epoch 5/125: Tr L: 0.1741, Tr Acc: 0.9079, Val L: 1.3134, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.6696, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 4 Epoch 6/125: Tr L: 0.1060, Tr Acc: 0.9474, Val L: 1.1473, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6786, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 4 Epoch 7/125: Tr L: 0.1318, Tr Acc: 0.9408, Val L: 1.1914, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6875, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 4 Epoch 8/125: Tr L: 0.1321, Tr Acc: 0.9671, Val L: 1.2299, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.6875, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 4 Epoch 9/125: Tr L: 0.0777, Tr Acc: 0.9671, Val L: 1.2552, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6696, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 4 Epoch 10/125: Tr L: 0.1902, Tr Acc: 0.9408, Val L: 1.8910, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.7054, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 4 Epoch 11/125: Tr L: 0.1107, Tr Acc: 0.9671, Val L: 2.2292, Val Acc: 0.5455, Val Bal Acc: 0.6161, Val Roc AUC: 0.7143, Val_mcc: 0.2507, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 4 Epoch 12/125: Tr L: 0.1889, Tr Acc: 0.9079, Val L: 1.3068, Val Acc: 0.5909, Val Bal Acc: 0.5179, Val Roc AUC: 0.7143, Val_mcc: 0.0410, Val F1: 0.3077 lr: 0.000401\n",
      " Fold 4 Epoch 13/125: Tr L: 0.1054, Tr Acc: 0.9605, Val L: 1.6548, Val Acc: 0.6364, Val Bal Acc: 0.5268, Val Roc AUC: 0.7321, Val_mcc: 0.0896, Val F1: 0.2000 lr: 0.000401\n",
      " Fold 4 Epoch 14/125: Tr L: 0.0550, Tr Acc: 0.9803, Val L: 1.2882, Val Acc: 0.5909, Val Bal Acc: 0.4911, Val Roc AUC: 0.7768, Val_mcc: -0.0250, Val F1: 0.1818 lr: 0.000401\n",
      " Fold 4 Epoch 15/125: Tr L: 0.0758, Tr Acc: 0.9539, Val L: 1.0143, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.7589, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 4 Epoch 16/125: Tr L: 0.0814, Tr Acc: 0.9671, Val L: 1.2820, Val Acc: 0.5909, Val Bal Acc: 0.5446, Val Roc AUC: 0.7232, Val_mcc: 0.0922, Val F1: 0.4000 lr: 0.000401\n",
      " Fold 4 Epoch 17/125: Tr L: 0.0872, Tr Acc: 0.9539, Val L: 1.1872, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7411, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 4 Epoch 18/125: Tr L: 0.0801, Tr Acc: 0.9671, Val L: 1.1269, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8125, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 4 Epoch 19/125: Tr L: 0.0781, Tr Acc: 0.9605, Val L: 1.5058, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7768, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 4 Epoch 20/125: Tr L: 0.1047, Tr Acc: 0.9671, Val L: 1.7680, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7589, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 4 Epoch 21/125: Tr L: 0.0746, Tr Acc: 0.9671, Val L: 1.6236, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7589, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 4 Epoch 22/125: Tr L: 0.0523, Tr Acc: 0.9737, Val L: 0.9995, Val Acc: 0.8636, Val Bal Acc: 0.8661, Val Roc AUC: 0.8393, Val_mcc: 0.7163, Val F1: 0.8235 lr: 0.000401\n",
      " Fold 4 Epoch 23/125: Tr L: 0.1164, Tr Acc: 0.9539, Val L: 0.9300, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8571, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 4 Epoch 24/125: Tr L: 0.0861, Tr Acc: 0.9539, Val L: 1.0735, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8125, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 4 Epoch 25/125: Tr L: 0.0605, Tr Acc: 0.9671, Val L: 1.3215, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8036, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 4 Epoch 26/125: Tr L: 0.1085, Tr Acc: 0.9737, Val L: 1.6607, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7679, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 4 Epoch 27/125: Tr L: 0.1654, Tr Acc: 0.9605, Val L: 1.0936, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8393, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 4 Epoch 28/125: Tr L: 0.1287, Tr Acc: 0.9342, Val L: 1.4530, Val Acc: 0.6364, Val Bal Acc: 0.5268, Val Roc AUC: 0.8661, Val_mcc: 0.0896, Val F1: 0.2000 lr: 0.000401\n",
      " Fold 4 Epoch 29/125: Tr L: 0.0736, Tr Acc: 0.9605, Val L: 1.1584, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.8661, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000201\n",
      " Fold 4 Epoch 30/125: Tr L: 0.0566, Tr Acc: 0.9737, Val L: 0.9537, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.8661, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000201\n",
      " Fold 4 Epoch 31/125: Tr L: 0.0565, Tr Acc: 0.9737, Val L: 0.8762, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8393, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 4 Epoch 32/125: Tr L: 0.0680, Tr Acc: 0.9605, Val L: 0.9408, Val Acc: 0.7727, Val Bal Acc: 0.7411, Val Roc AUC: 0.8304, Val_mcc: 0.4980, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 4 Epoch 33/125: Tr L: 0.0554, Tr Acc: 0.9671, Val L: 1.0339, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8214, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 4 Epoch 34/125: Tr L: 0.0411, Tr Acc: 0.9803, Val L: 1.1152, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8214, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 4 Epoch 35/125: Tr L: 0.0530, Tr Acc: 0.9671, Val L: 1.0725, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8214, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 4 Epoch 36/125: Tr L: 0.0624, Tr Acc: 0.9605, Val L: 1.0193, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8214, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 4 Epoch 37/125: Tr L: 0.0309, Tr Acc: 0.9868, Val L: 0.9308, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.8214, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 4 Epoch 38/125: Tr L: 0.0487, Tr Acc: 0.9803, Val L: 0.9189, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8482, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000201\n",
      " Fold 4 Epoch 39/125: Tr L: 0.0360, Tr Acc: 0.9803, Val L: 1.0310, Val Acc: 0.8636, Val Bal Acc: 0.8929, Val Roc AUC: 0.8304, Val_mcc: 0.7559, Val F1: 0.8421 lr: 0.000201\n",
      " Fold 4 Epoch 40/125: Tr L: 0.0872, Tr Acc: 0.9605, Val L: 0.9812, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8125, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000201\n",
      " Fold 4 Epoch 41/125: Tr L: 0.0338, Tr Acc: 0.9803, Val L: 1.0280, Val Acc: 0.6818, Val Bal Acc: 0.6161, Val Roc AUC: 0.8214, Val_mcc: 0.2665, Val F1: 0.4615 lr: 0.000201\n",
      " Fold 4 Epoch 42/125: Tr L: 0.0632, Tr Acc: 0.9671, Val L: 0.9154, Val Acc: 0.8182, Val Bal Acc: 0.8036, Val Roc AUC: 0.8393, Val_mcc: 0.6071, Val F1: 0.7500 lr: 0.000201\n",
      "Early stopping triggered at epoch 42 for fold 4\n",
      "--- Evaluating Fold 5 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 4: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 4 FINAL] Test Loss: 0.8155 | Test Acc: 0.6500 | test Balanced Acc: 0.7024 | test F1: 0.5882 | Test AUC: 0.7976 | Test MCC: 0.3728\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:23:44,631] A new study created in memory with name: no-name-efd81e7c-574f-4b69-b23f-1558317406a6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 6 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 6 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 6.\n",
      "--- Starting Hyperparameter Tuning for Fold 6 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:24:09,010] Trial 0 finished with value: 0.7362708151340485 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7362708151340485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:24:33,393] Trial 1 finished with value: 0.8723134398460388 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7362708151340485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:24:57,667] Trial 2 finished with value: 0.7137775123119354 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.7137775123119354.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 6 with LR=0.000401 ---\n",
      "X_train_es: (122,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 122, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 5 Epoch 1/125: Tr L: 0.5528, Tr Acc: 0.6645, Val L: 0.7977, Val Acc: 0.5000, Val Bal Acc: 0.5536, Val Roc AUC: 0.5179, Val_mcc: 0.1107, Val F1: 0.5217 lr: 0.000401\n",
      " Fold 5 Epoch 2/125: Tr L: 0.3983, Tr Acc: 0.8487, Val L: 0.8923, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.5089, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 5 Epoch 3/125: Tr L: 0.2649, Tr Acc: 0.8750, Val L: 1.3710, Val Acc: 0.5909, Val Bal Acc: 0.4911, Val Roc AUC: 0.4732, Val_mcc: -0.0250, Val F1: 0.1818 lr: 0.000401\n",
      " Fold 5 Epoch 4/125: Tr L: 0.2383, Tr Acc: 0.9211, Val L: 1.2272, Val Acc: 0.5455, Val Bal Acc: 0.4554, Val Roc AUC: 0.4821, Val_mcc: -0.1114, Val F1: 0.1667 lr: 0.000401\n",
      " Fold 5 Epoch 5/125: Tr L: 0.1606, Tr Acc: 0.9342, Val L: 1.4732, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.6518, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000401\n",
      " Fold 5 Epoch 6/125: Tr L: 0.1402, Tr Acc: 0.9605, Val L: 1.5811, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.5804, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000401\n",
      " Fold 5 Epoch 7/125: Tr L: 0.0892, Tr Acc: 0.9737, Val L: 1.8487, Val Acc: 0.5000, Val Bal Acc: 0.5268, Val Roc AUC: 0.4643, Val_mcc: 0.0524, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 5 Epoch 8/125: Tr L: 0.1710, Tr Acc: 0.9211, Val L: 2.0298, Val Acc: 0.4545, Val Bal Acc: 0.4107, Val Roc AUC: 0.5000, Val_mcc: -0.1786, Val F1: 0.2500 lr: 0.000401\n",
      " Fold 5 Epoch 9/125: Tr L: 0.1083, Tr Acc: 0.9474, Val L: 2.3063, Val Acc: 0.5000, Val Bal Acc: 0.5000, Val Roc AUC: 0.4554, Val_mcc: 0.0000, Val F1: 0.4211 lr: 0.000401\n",
      " Fold 5 Epoch 10/125: Tr L: 0.0823, Tr Acc: 0.9671, Val L: 1.8358, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.6161, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 5 Epoch 11/125: Tr L: 0.1121, Tr Acc: 0.9671, Val L: 2.0727, Val Acc: 0.6364, Val Bal Acc: 0.5536, Val Roc AUC: 0.5893, Val_mcc: 0.1336, Val F1: 0.3333 lr: 0.000401\n",
      " Fold 5 Epoch 12/125: Tr L: 0.0875, Tr Acc: 0.9605, Val L: 2.5002, Val Acc: 0.5909, Val Bal Acc: 0.4911, Val Roc AUC: 0.5714, Val_mcc: -0.0250, Val F1: 0.1818 lr: 0.000401\n",
      " Fold 5 Epoch 13/125: Tr L: 0.2199, Tr Acc: 0.9211, Val L: 2.4650, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.5446, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 5 Epoch 14/125: Tr L: 0.0730, Tr Acc: 0.9605, Val L: 2.6833, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.5625, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 15/125: Tr L: 0.0572, Tr Acc: 0.9868, Val L: 2.5909, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.6339, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 5 Epoch 16/125: Tr L: 0.1535, Tr Acc: 0.9276, Val L: 2.2368, Val Acc: 0.5909, Val Bal Acc: 0.5982, Val Roc AUC: 0.5982, Val_mcc: 0.1890, Val F1: 0.5263 lr: 0.000401\n",
      " Fold 5 Epoch 17/125: Tr L: 0.0701, Tr Acc: 0.9605, Val L: 2.3540, Val Acc: 0.5000, Val Bal Acc: 0.4464, Val Roc AUC: 0.5179, Val_mcc: -0.1107, Val F1: 0.2667 lr: 0.000401\n",
      " Fold 5 Epoch 18/125: Tr L: 0.0981, Tr Acc: 0.9605, Val L: 3.0685, Val Acc: 0.6364, Val Bal Acc: 0.5268, Val Roc AUC: 0.4732, Val_mcc: 0.0896, Val F1: 0.2000 lr: 0.000401\n",
      " Fold 5 Epoch 19/125: Tr L: 0.0670, Tr Acc: 0.9671, Val L: 3.2806, Val Acc: 0.6364, Val Bal Acc: 0.5268, Val Roc AUC: 0.4554, Val_mcc: 0.0896, Val F1: 0.2000 lr: 0.000401\n",
      " Fold 5 Epoch 20/125: Tr L: 0.0903, Tr Acc: 0.9539, Val L: 3.0961, Val Acc: 0.6364, Val Bal Acc: 0.5268, Val Roc AUC: 0.4911, Val_mcc: 0.0896, Val F1: 0.2000 lr: 0.000401\n",
      " Fold 5 Epoch 21/125: Tr L: 0.0638, Tr Acc: 0.9803, Val L: 2.6866, Val Acc: 0.5909, Val Bal Acc: 0.4911, Val Roc AUC: 0.4464, Val_mcc: -0.0250, Val F1: 0.1818 lr: 0.000401\n",
      " Fold 5 Epoch 22/125: Tr L: 0.0702, Tr Acc: 0.9737, Val L: 2.1754, Val Acc: 0.4545, Val Bal Acc: 0.3839, Val Roc AUC: 0.4643, Val_mcc: -0.2507, Val F1: 0.1429 lr: 0.000401\n",
      " Fold 5 Epoch 23/125: Tr L: 0.0989, Tr Acc: 0.9803, Val L: 1.5426, Val Acc: 0.5909, Val Bal Acc: 0.5179, Val Roc AUC: 0.5714, Val_mcc: 0.0410, Val F1: 0.3077 lr: 0.000401\n",
      " Fold 5 Epoch 24/125: Tr L: 0.0788, Tr Acc: 0.9539, Val L: 1.4194, Val Acc: 0.5455, Val Bal Acc: 0.5089, Val Roc AUC: 0.5893, Val_mcc: 0.0179, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 5 Epoch 25/125: Tr L: 0.0911, Tr Acc: 0.9539, Val L: 1.5483, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.6071, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 5 Epoch 26/125: Tr L: 0.0725, Tr Acc: 0.9671, Val L: 1.8622, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.5893, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 5 Epoch 27/125: Tr L: 0.0762, Tr Acc: 0.9605, Val L: 2.0163, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.6161, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 28/125: Tr L: 0.0806, Tr Acc: 0.9605, Val L: 1.8601, Val Acc: 0.6364, Val Bal Acc: 0.6071, Val Roc AUC: 0.5804, Val_mcc: 0.2143, Val F1: 0.5000 lr: 0.000201\n",
      " Fold 5 Epoch 29/125: Tr L: 0.0566, Tr Acc: 0.9605, Val L: 1.7815, Val Acc: 0.6364, Val Bal Acc: 0.5804, Val Roc AUC: 0.6250, Val_mcc: 0.1736, Val F1: 0.4286 lr: 0.000201\n",
      " Fold 5 Epoch 30/125: Tr L: 0.0574, Tr Acc: 0.9737, Val L: 1.7304, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.6429, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 5 Epoch 31/125: Tr L: 0.0433, Tr Acc: 0.9868, Val L: 1.6542, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.6518, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 5 Epoch 32/125: Tr L: 0.0736, Tr Acc: 0.9671, Val L: 1.5304, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.6607, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 5 Epoch 33/125: Tr L: 0.0331, Tr Acc: 0.9934, Val L: 1.5532, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6250, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 34/125: Tr L: 0.0748, Tr Acc: 0.9671, Val L: 1.5869, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6339, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 35/125: Tr L: 0.0341, Tr Acc: 0.9868, Val L: 1.7028, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6161, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 36/125: Tr L: 0.0572, Tr Acc: 0.9803, Val L: 1.6384, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6250, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 37/125: Tr L: 0.0475, Tr Acc: 0.9803, Val L: 1.6163, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6161, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 38/125: Tr L: 0.0530, Tr Acc: 0.9868, Val L: 1.6761, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6071, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 39/125: Tr L: 0.0353, Tr Acc: 0.9803, Val L: 1.9368, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.5982, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 5 Epoch 40/125: Tr L: 0.0583, Tr Acc: 0.9671, Val L: 2.1998, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.5804, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 5 Epoch 41/125: Tr L: 0.0166, Tr Acc: 0.9934, Val L: 2.3323, Val Acc: 0.6364, Val Bal Acc: 0.5804, Val Roc AUC: 0.5804, Val_mcc: 0.1736, Val F1: 0.4286 lr: 0.000201\n",
      "Early stopping triggered at epoch 41 for fold 5\n",
      "--- Evaluating Fold 6 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 5: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 5 FINAL] Test Loss: 0.8947 | Test Acc: 0.3000 | test Balanced Acc: 0.4048 | test F1: 0.3636 | Test AUC: 0.5476 | Test MCC: -0.2182\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:28:56,201] A new study created in memory with name: no-name-654fd9fd-b6ac-4258-96f5-aa1b3ef72329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 7 / 8 =====\n",
      "Outer Train images: 146 | Outer Test images: 18\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 7 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 7.\n",
      "--- Starting Hyperparameter Tuning for Fold 7 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:29:22,476] Trial 0 finished with value: 0.7099560995896657 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7099560995896657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:29:49,158] Trial 1 finished with value: 2.168976294332727 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7099560995896657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:30:15,385] Trial 2 finished with value: 0.843284750978152 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7099560995896657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 7 with LR=0.000047 ---\n",
      "X_train_es: (124,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 124, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 6 Epoch 1/125: Tr L: 0.6891, Tr Acc: 0.5750, Val L: 0.6770, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.5982, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 6 Epoch 2/125: Tr L: 0.5748, Tr Acc: 0.7312, Val L: 0.6821, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.5625, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 3/125: Tr L: 0.4783, Tr Acc: 0.8313, Val L: 0.6442, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.7232, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 4/125: Tr L: 0.4181, Tr Acc: 0.8438, Val L: 0.6052, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7768, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 6 Epoch 5/125: Tr L: 0.3658, Tr Acc: 0.8688, Val L: 0.5746, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7946, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 6/125: Tr L: 0.3170, Tr Acc: 0.9187, Val L: 0.5488, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 7/125: Tr L: 0.2818, Tr Acc: 0.9062, Val L: 0.5238, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 8/125: Tr L: 0.2362, Tr Acc: 0.9313, Val L: 0.5115, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 9/125: Tr L: 0.1957, Tr Acc: 0.9563, Val L: 0.5210, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7946, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 10/125: Tr L: 0.1931, Tr Acc: 0.9625, Val L: 0.5493, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7500, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 11/125: Tr L: 0.1871, Tr Acc: 0.9437, Val L: 0.5635, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7589, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 12/125: Tr L: 0.1445, Tr Acc: 0.9625, Val L: 0.5784, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7500, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 13/125: Tr L: 0.0972, Tr Acc: 1.0000, Val L: 0.5597, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7500, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 14/125: Tr L: 0.1184, Tr Acc: 0.9625, Val L: 0.5714, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7411, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 6 Epoch 15/125: Tr L: 0.1290, Tr Acc: 0.9563, Val L: 0.6017, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7411, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 16/125: Tr L: 0.1612, Tr Acc: 0.9313, Val L: 0.6479, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7411, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 6 Epoch 17/125: Tr L: 0.0855, Tr Acc: 0.9812, Val L: 0.6472, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7411, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 18/125: Tr L: 0.0937, Tr Acc: 0.9688, Val L: 0.6453, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7411, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 19/125: Tr L: 0.0612, Tr Acc: 0.9875, Val L: 0.6868, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7321, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 20/125: Tr L: 0.0739, Tr Acc: 0.9750, Val L: 0.6851, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7321, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 21/125: Tr L: 0.0836, Tr Acc: 0.9688, Val L: 0.6954, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7411, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 22/125: Tr L: 0.0826, Tr Acc: 0.9688, Val L: 0.6927, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7143, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 23/125: Tr L: 0.0486, Tr Acc: 0.9875, Val L: 0.7857, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 6 Epoch 24/125: Tr L: 0.0655, Tr Acc: 0.9688, Val L: 0.8767, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.7054, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 25/125: Tr L: 0.0487, Tr Acc: 0.9812, Val L: 0.8460, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.6875, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 6 Epoch 26/125: Tr L: 0.1101, Tr Acc: 0.9688, Val L: 0.8206, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.6786, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 27/125: Tr L: 0.0367, Tr Acc: 0.9938, Val L: 0.7994, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.6875, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 28/125: Tr L: 0.0592, Tr Acc: 0.9875, Val L: 0.8602, Val Acc: 0.6364, Val Bal Acc: 0.6339, Val Roc AUC: 0.6786, Val_mcc: 0.2588, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 29/125: Tr L: 0.0560, Tr Acc: 0.9812, Val L: 1.0430, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.6964, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 30/125: Tr L: 0.0464, Tr Acc: 0.9812, Val L: 1.0481, Val Acc: 0.5455, Val Bal Acc: 0.5893, Val Roc AUC: 0.7054, Val_mcc: 0.1786, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 31/125: Tr L: 0.0835, Tr Acc: 0.9750, Val L: 0.8874, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7232, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 32/125: Tr L: 0.0326, Tr Acc: 0.9875, Val L: 0.7525, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7321, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 6 Epoch 33/125: Tr L: 0.0415, Tr Acc: 0.9812, Val L: 0.7708, Val Acc: 0.7273, Val Bal Acc: 0.6786, Val Roc AUC: 0.7321, Val_mcc: 0.3858, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 34/125: Tr L: 0.0465, Tr Acc: 0.9875, Val L: 0.7329, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7321, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 6 Epoch 35/125: Tr L: 0.0420, Tr Acc: 0.9875, Val L: 0.7582, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7143, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 36/125: Tr L: 0.0846, Tr Acc: 0.9625, Val L: 0.8624, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 6 Epoch 37/125: Tr L: 0.0635, Tr Acc: 0.9812, Val L: 0.8479, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 6 Epoch 38/125: Tr L: 0.0533, Tr Acc: 0.9812, Val L: 0.9295, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.6964, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 6 Epoch 39/125: Tr L: 0.0800, Tr Acc: 0.9750, Val L: 0.9422, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.7054, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 6 Epoch 40/125: Tr L: 0.0479, Tr Acc: 0.9688, Val L: 0.9581, Val Acc: 0.5909, Val Bal Acc: 0.6250, Val Roc AUC: 0.7143, Val_mcc: 0.2446, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 6 Epoch 41/125: Tr L: 0.1187, Tr Acc: 0.9500, Val L: 0.9542, Val Acc: 0.6364, Val Bal Acc: 0.6607, Val Roc AUC: 0.6964, Val_mcc: 0.3105, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 6 Epoch 42/125: Tr L: 0.0281, Tr Acc: 0.9812, Val L: 0.8485, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6964, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 43/125: Tr L: 0.0565, Tr Acc: 0.9688, Val L: 0.7667, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7054, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 44/125: Tr L: 0.0372, Tr Acc: 0.9812, Val L: 0.7175, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7232, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 45/125: Tr L: 0.0185, Tr Acc: 0.9938, Val L: 0.7158, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7411, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 6 Epoch 46/125: Tr L: 0.0264, Tr Acc: 0.9938, Val L: 0.7140, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.7411, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000024\n",
      " Fold 6 Epoch 47/125: Tr L: 0.0387, Tr Acc: 0.9812, Val L: 0.7584, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7411, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 48/125: Tr L: 0.0278, Tr Acc: 1.0000, Val L: 0.7855, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.7411, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000024\n",
      "Early stopping triggered at epoch 48 for fold 6\n",
      "--- Evaluating Fold 7 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 6: {0: 10, 1: 8}\n",
      "percentage of classes in test set: 0    0.555556\n",
      "1    0.444444\n",
      "Name: count, dtype: float64\n",
      " [FOLD 6 FINAL] Test Loss: 0.8451 | Test Acc: 0.5000 | test Balanced Acc: 0.5000 | test F1: 0.4706 | Test AUC: 0.5500 | Test MCC: 0.0000\n",
      "model class name: DenseNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:35:14,048] A new study created in memory with name: no-name-36ef5aaa-6b03-4e5a-b3f1-4a6fccf62a4b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 8 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 8 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 8.\n",
      "--- Starting Hyperparameter Tuning for Fold 8 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:35:39,510] Trial 0 finished with value: 0.7242034077644348 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7242034077644348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:36:04,941] Trial 1 finished with value: 1.1746802429358163 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7242034077644348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:36:30,342] Trial 2 finished with value: 0.7227608660856883 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.7227608660856883.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 8 with LR=0.000401 ---\n",
      "X_train_es: (122,) | X_val_es: (22,)\n",
      "Early stopping split: Train images: 122, Validation images: 22\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 12,487,810\n",
      "Trainable parameters: 6,742,018\n",
      "Non-trainable parameters: 5,745,792\n",
      "===========================\n",
      " Fold 7 Epoch 1/125: Tr L: 0.6031, Tr Acc: 0.6474, Val L: 0.8115, Val Acc: 0.5000, Val Bal Acc: 0.5536, Val Roc AUC: 0.6339, Val_mcc: 0.1107, Val F1: 0.5217 lr: 0.000401\n",
      " Fold 7 Epoch 2/125: Tr L: 0.3672, Tr Acc: 0.8333, Val L: 0.7728, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.6964, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 7 Epoch 3/125: Tr L: 0.2205, Tr Acc: 0.9167, Val L: 0.9664, Val Acc: 0.5455, Val Bal Acc: 0.5625, Val Roc AUC: 0.7232, Val_mcc: 0.1208, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 7 Epoch 4/125: Tr L: 0.2103, Tr Acc: 0.8910, Val L: 0.8704, Val Acc: 0.6818, Val Bal Acc: 0.6964, Val Roc AUC: 0.8036, Val_mcc: 0.3780, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 7 Epoch 5/125: Tr L: 0.1323, Tr Acc: 0.9423, Val L: 0.7609, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 6/125: Tr L: 0.1423, Tr Acc: 0.9167, Val L: 0.7770, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8393, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 7 Epoch 7/125: Tr L: 0.1580, Tr Acc: 0.9359, Val L: 0.8748, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8214, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 7 Epoch 8/125: Tr L: 0.1039, Tr Acc: 0.9487, Val L: 1.1826, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7589, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 9/125: Tr L: 0.1283, Tr Acc: 0.9487, Val L: 1.0028, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7589, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 7 Epoch 10/125: Tr L: 0.0680, Tr Acc: 0.9679, Val L: 1.0723, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.7321, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 7 Epoch 11/125: Tr L: 0.0880, Tr Acc: 0.9615, Val L: 1.0786, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.7589, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 7 Epoch 12/125: Tr L: 0.0990, Tr Acc: 0.9744, Val L: 1.4403, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7500, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 7 Epoch 13/125: Tr L: 0.1544, Tr Acc: 0.9487, Val L: 1.5070, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.7500, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 7 Epoch 14/125: Tr L: 0.0772, Tr Acc: 0.9744, Val L: 1.7755, Val Acc: 0.6364, Val Bal Acc: 0.5536, Val Roc AUC: 0.7946, Val_mcc: 0.1336, Val F1: 0.3333 lr: 0.000401\n",
      " Fold 7 Epoch 15/125: Tr L: 0.0707, Tr Acc: 0.9551, Val L: 1.1761, Val Acc: 0.6818, Val Bal Acc: 0.6429, Val Roc AUC: 0.8214, Val_mcc: 0.2951, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 7 Epoch 16/125: Tr L: 0.1036, Tr Acc: 0.9551, Val L: 1.7227, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7857, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 17/125: Tr L: 0.0899, Tr Acc: 0.9487, Val L: 2.0169, Val Acc: 0.5909, Val Bal Acc: 0.6518, Val Roc AUC: 0.8393, Val_mcc: 0.3135, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 7 Epoch 18/125: Tr L: 0.1025, Tr Acc: 0.9679, Val L: 1.8552, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8125, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 7 Epoch 19/125: Tr L: 0.0832, Tr Acc: 0.9551, Val L: 1.4910, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.7857, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 7 Epoch 20/125: Tr L: 0.0744, Tr Acc: 0.9615, Val L: 1.2445, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7679, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 21/125: Tr L: 0.0503, Tr Acc: 0.9808, Val L: 1.2117, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.7946, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 7 Epoch 22/125: Tr L: 0.1379, Tr Acc: 0.9359, Val L: 1.0417, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 23/125: Tr L: 0.0942, Tr Acc: 0.9487, Val L: 1.0161, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8125, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000401\n",
      " Fold 7 Epoch 24/125: Tr L: 0.0499, Tr Acc: 0.9808, Val L: 1.4371, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.8304, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 25/125: Tr L: 0.0693, Tr Acc: 0.9808, Val L: 1.5274, Val Acc: 0.6364, Val Bal Acc: 0.6875, Val Roc AUC: 0.8393, Val_mcc: 0.3750, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 7 Epoch 26/125: Tr L: 0.0841, Tr Acc: 0.9744, Val L: 1.5430, Val Acc: 0.6818, Val Bal Acc: 0.7232, Val Roc AUC: 0.8393, Val_mcc: 0.4368, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 27/125: Tr L: 0.0496, Tr Acc: 0.9744, Val L: 1.0524, Val Acc: 0.7273, Val Bal Acc: 0.7589, Val Roc AUC: 0.8571, Val_mcc: 0.5003, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 7 Epoch 28/125: Tr L: 0.1069, Tr Acc: 0.9615, Val L: 0.8619, Val Acc: 0.8182, Val Bal Acc: 0.8304, Val Roc AUC: 0.8661, Val_mcc: 0.6383, Val F1: 0.7778 lr: 0.000401\n",
      " Fold 7 Epoch 29/125: Tr L: 0.0589, Tr Acc: 0.9679, Val L: 0.8480, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8571, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000401\n",
      " Fold 7 Epoch 30/125: Tr L: 0.0756, Tr Acc: 0.9679, Val L: 1.1564, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 31/125: Tr L: 0.0504, Tr Acc: 0.9808, Val L: 1.7280, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 32/125: Tr L: 0.0981, Tr Acc: 0.9615, Val L: 1.6972, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8214, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 33/125: Tr L: 0.0605, Tr Acc: 0.9551, Val L: 1.5537, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8125, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 34/125: Tr L: 0.0455, Tr Acc: 0.9872, Val L: 1.4025, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 35/125: Tr L: 0.0614, Tr Acc: 0.9744, Val L: 1.0407, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8304, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000201\n",
      " Fold 7 Epoch 36/125: Tr L: 0.0527, Tr Acc: 0.9744, Val L: 0.9193, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.8482, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 7 Epoch 37/125: Tr L: 0.0489, Tr Acc: 0.9744, Val L: 0.9182, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.8393, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 7 Epoch 38/125: Tr L: 0.0339, Tr Acc: 0.9808, Val L: 0.9263, Val Acc: 0.7273, Val Bal Acc: 0.7054, Val Roc AUC: 0.8214, Val_mcc: 0.4107, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 7 Epoch 39/125: Tr L: 0.0728, Tr Acc: 0.9808, Val L: 0.9887, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8304, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 40/125: Tr L: 0.0377, Tr Acc: 0.9872, Val L: 0.9909, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8393, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 41/125: Tr L: 0.0839, Tr Acc: 0.9679, Val L: 0.9454, Val Acc: 0.7727, Val Bal Acc: 0.7679, Val Roc AUC: 0.8482, Val_mcc: 0.5241, Val F1: 0.7059 lr: 0.000201\n",
      " Fold 7 Epoch 42/125: Tr L: 0.0588, Tr Acc: 0.9808, Val L: 1.0611, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.7946, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 43/125: Tr L: 0.0212, Tr Acc: 0.9936, Val L: 1.1937, Val Acc: 0.6818, Val Bal Acc: 0.6696, Val Roc AUC: 0.8036, Val_mcc: 0.3320, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 7 Epoch 44/125: Tr L: 0.0349, Tr Acc: 0.9808, Val L: 1.3596, Val Acc: 0.7273, Val Bal Acc: 0.7321, Val Roc AUC: 0.8036, Val_mcc: 0.4485, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 45/125: Tr L: 0.0474, Tr Acc: 0.9744, Val L: 1.5435, Val Acc: 0.7727, Val Bal Acc: 0.7946, Val Roc AUC: 0.8036, Val_mcc: 0.5669, Val F1: 0.7368 lr: 0.000201\n",
      "Early stopping triggered at epoch 45 for fold 7\n",
      "--- Evaluating Fold 8 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Test set class counts for fold 7: {0: 12, 1: 8}\n",
      "percentage of classes in test set: 0    0.6\n",
      "1    0.4\n",
      "Name: count, dtype: float64\n",
      " [FOLD 7 FINAL] Test Loss: 1.5636 | Test Acc: 0.6500 | test Balanced Acc: 0.6667 | test F1: 0.6316 | Test AUC: 0.6562 | Test MCC: 0.3282\n",
      "model class name: DenseNet\n",
      "\n",
      "-------------------------------------------------\n",
      "Cross-validation results (outer folds):\n",
      "  Fold 0: Test Loss=0.7469, Acc=0.6667, F1=0.5882, Bal Acc=0.6587, AUC=0.6923, MCC=0.3114 (Best LR=0.000047)\n",
      "  Fold 1: Test Loss=1.4853, Acc=0.5909, F1=0.4706, Bal Acc=0.5714, AUC=0.6339, MCC=0.1398 (Best LR=0.000401)\n",
      "  Fold 2: Test Loss=0.9844, Acc=0.2857, F1=0.4000, Bal Acc=0.3510, AUC=0.2212, MCC=-0.3686 (Best LR=0.000401)\n",
      "  Fold 3: Test Loss=1.3917, Acc=0.5455, F1=0.5455, Bal Acc=0.5893, AUC=0.5804, MCC=0.1786 (Best LR=0.000401)\n",
      "  Fold 4: Test Loss=0.8155, Acc=0.6500, F1=0.5882, Bal Acc=0.7024, AUC=0.7976, MCC=0.3728 (Best LR=0.000401)\n",
      "  Fold 5: Test Loss=0.8947, Acc=0.3000, F1=0.3636, Bal Acc=0.4048, AUC=0.5476, MCC=-0.2182 (Best LR=0.000401)\n",
      "  Fold 6: Test Loss=0.8451, Acc=0.5000, F1=0.4706, Bal Acc=0.5000, AUC=0.5500, MCC=0.0000 (Best LR=0.000047)\n",
      "  Fold 7: Test Loss=1.5636, Acc=0.6500, F1=0.6316, Bal Acc=0.6667, AUC=0.6562, MCC=0.3282 (Best LR=0.000401)\n",
      "\n",
      "--- Aggregate Results ---\n",
      "Avg Test Accuracy: 0.5236 +/- 0.1434\n",
      "Avg Test F1-Score: 0.5073 +/- 0.0900\n",
      "Avg Test Balanced Acc: 0.5555 +/- 0.1192\n",
      "Avg Test Precision: 0.4271 +/- 0.1006\n",
      "Avg Test Recall: 0.6562 +/- 0.1117\n",
      "Avg Test MCC: 0.0930 +/- 0.2524\n",
      "-------------------------------------------------\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision DenseNet169...\n",
      "Freezing layers up to index: 308\n",
      "Run name: Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/16 16:41:06 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpggz_4cja/model/data, flavor: pytorch). Fall back to return ['torch==2.6.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/07/16 16:41:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, shape: torch.Size([25, 3, 224, 224])\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_0.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_1.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_2.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_3.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_4.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_5.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_6.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_7.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_8.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_9.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_10.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_11.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_12.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_13.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_14.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_15.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_16.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_17.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_18.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_19.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_20.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_21.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_22.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:41:15,225] A new study created in memory with name: no-name-eee2df35-7263-4c1a-82c9-6824f7a37948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Densenet169_oversamp_TL_pretrained:imagenet_freeze:308_torchvision_color_transforms:False_07-16_at:16-41-01/batch_0_img_24.png\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/base.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/resnet18.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.17, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 32, 'num_workers': 0}, 'model': {'model_name': 'Resnet18', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'torchvision', 'pretrained_weights': 'imagenet'}, 'training': {'num_epochs': 200, 'early_stopping_patience': 60, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': 50, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '2e-4', 'patience': 30}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}\n",
      "Number of classes in the dataset: 2\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Detected 2 unique classes.\n",
      "\n",
      "===== OUTER FOLD 1 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 1 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 1.\n",
      "--- Starting Hyperparameter Tuning for Fold 1 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:41:41,662] Trial 0 finished with value: 0.7067619313796362 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7067619313796362.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:42:07,854] Trial 1 finished with value: 2.4749840895334883 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7067619313796362.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:42:34,156] Trial 2 finished with value: 0.8099178473154703 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7067619313796362.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 1 with LR=0.000047 ---\n",
      "X_train_es: (118,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 118, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 0 Epoch 1/200: Tr L: 0.6947, Tr Acc: 0.5533, Val L: 0.7773, Val Acc: 0.4000, Val Bal Acc: 0.4826, Val Roc AUC: 0.5556, Val_mcc: -0.0417, Val F1: 0.4828 lr: 0.000047\n",
      " Fold 0 Epoch 2/200: Tr L: 0.6422, Tr Acc: 0.6467, Val L: 0.7416, Val Acc: 0.4000, Val Bal Acc: 0.4826, Val Roc AUC: 0.5694, Val_mcc: -0.0417, Val F1: 0.4828 lr: 0.000047\n",
      " Fold 0 Epoch 3/200: Tr L: 0.5615, Tr Acc: 0.7667, Val L: 0.6657, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6250, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 0 Epoch 4/200: Tr L: 0.5203, Tr Acc: 0.7467, Val L: 0.6475, Val Acc: 0.5600, Val Bal Acc: 0.5104, Val Roc AUC: 0.6389, Val_mcc: 0.0214, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 0 Epoch 5/200: Tr L: 0.4838, Tr Acc: 0.7800, Val L: 0.6577, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6181, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 6/200: Tr L: 0.4001, Tr Acc: 0.8400, Val L: 0.6705, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.5972, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 7/200: Tr L: 0.4295, Tr Acc: 0.7867, Val L: 0.6790, Val Acc: 0.5600, Val Bal Acc: 0.5104, Val Roc AUC: 0.5972, Val_mcc: 0.0214, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 0 Epoch 8/200: Tr L: 0.3821, Tr Acc: 0.8533, Val L: 0.6752, Val Acc: 0.5600, Val Bal Acc: 0.5104, Val Roc AUC: 0.5972, Val_mcc: 0.0214, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 0 Epoch 9/200: Tr L: 0.3348, Tr Acc: 0.8867, Val L: 0.6700, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6111, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 10/200: Tr L: 0.4533, Tr Acc: 0.7933, Val L: 0.6623, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6111, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 11/200: Tr L: 0.3297, Tr Acc: 0.8800, Val L: 0.6641, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6250, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 12/200: Tr L: 0.3049, Tr Acc: 0.9000, Val L: 0.6668, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6319, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000047\n",
      " Fold 0 Epoch 13/200: Tr L: 0.2957, Tr Acc: 0.9000, Val L: 0.6751, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6528, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000047\n",
      " Fold 0 Epoch 14/200: Tr L: 0.2741, Tr Acc: 0.9267, Val L: 0.6804, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6389, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000047\n",
      " Fold 0 Epoch 15/200: Tr L: 0.2834, Tr Acc: 0.8733, Val L: 0.6876, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6528, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000047\n",
      " Fold 0 Epoch 16/200: Tr L: 0.2471, Tr Acc: 0.9067, Val L: 0.6831, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6528, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000047\n",
      " Fold 0 Epoch 17/200: Tr L: 0.2441, Tr Acc: 0.9467, Val L: 0.6681, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6458, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000047\n",
      " Fold 0 Epoch 18/200: Tr L: 0.2759, Tr Acc: 0.8933, Val L: 0.6570, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6597, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 0 Epoch 19/200: Tr L: 0.2527, Tr Acc: 0.9067, Val L: 0.6465, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6597, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 0 Epoch 20/200: Tr L: 0.2023, Tr Acc: 0.9200, Val L: 0.6381, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6806, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 21/200: Tr L: 0.2040, Tr Acc: 0.9267, Val L: 0.6555, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6667, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 22/200: Tr L: 0.2461, Tr Acc: 0.8867, Val L: 0.6479, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6875, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 23/200: Tr L: 0.1865, Tr Acc: 0.9400, Val L: 0.6550, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6875, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 24/200: Tr L: 0.1641, Tr Acc: 0.9400, Val L: 0.6351, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6736, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 25/200: Tr L: 0.1961, Tr Acc: 0.9400, Val L: 0.6388, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6736, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 26/200: Tr L: 0.1719, Tr Acc: 0.9267, Val L: 0.6521, Val Acc: 0.5600, Val Bal Acc: 0.5104, Val Roc AUC: 0.6806, Val_mcc: 0.0214, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 0 Epoch 27/200: Tr L: 0.1880, Tr Acc: 0.9400, Val L: 0.6839, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6875, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 28/200: Tr L: 0.1247, Tr Acc: 0.9800, Val L: 0.7288, Val Acc: 0.6400, Val Bal Acc: 0.5486, Val Roc AUC: 0.6458, Val_mcc: 0.1273, Val F1: 0.3077 lr: 0.000047\n",
      " Fold 0 Epoch 29/200: Tr L: 0.1384, Tr Acc: 0.9600, Val L: 0.7499, Val Acc: 0.6400, Val Bal Acc: 0.5486, Val Roc AUC: 0.6458, Val_mcc: 0.1273, Val F1: 0.3077 lr: 0.000047\n",
      " Fold 0 Epoch 30/200: Tr L: 0.1640, Tr Acc: 0.9667, Val L: 0.7206, Val Acc: 0.6400, Val Bal Acc: 0.5729, Val Roc AUC: 0.6458, Val_mcc: 0.1639, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 0 Epoch 31/200: Tr L: 0.1343, Tr Acc: 0.9467, Val L: 0.7035, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6806, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 32/200: Tr L: 0.2212, Tr Acc: 0.9200, Val L: 0.6874, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6806, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 0 Epoch 33/200: Tr L: 0.1597, Tr Acc: 0.9600, Val L: 0.6814, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6667, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 0 Epoch 34/200: Tr L: 0.1698, Tr Acc: 0.9133, Val L: 0.6688, Val Acc: 0.5600, Val Bal Acc: 0.5104, Val Roc AUC: 0.6944, Val_mcc: 0.0214, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 0 Epoch 35/200: Tr L: 0.1481, Tr Acc: 0.9467, Val L: 0.6859, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6944, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 36/200: Tr L: 0.1378, Tr Acc: 0.9333, Val L: 0.6907, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6875, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 0 Epoch 37/200: Tr L: 0.1946, Tr Acc: 0.9200, Val L: 0.6797, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6944, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 0 Epoch 38/200: Tr L: 0.1229, Tr Acc: 0.9667, Val L: 0.6842, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7083, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 0 Epoch 39/200: Tr L: 0.1521, Tr Acc: 0.9400, Val L: 0.7022, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7083, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 0 Epoch 40/200: Tr L: 0.1447, Tr Acc: 0.9467, Val L: 0.6964, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7014, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 0 Epoch 41/200: Tr L: 0.0772, Tr Acc: 0.9800, Val L: 0.7224, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6944, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 0 Epoch 42/200: Tr L: 0.1454, Tr Acc: 0.9267, Val L: 0.7412, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6944, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 0 Epoch 43/200: Tr L: 0.1139, Tr Acc: 0.9667, Val L: 0.7707, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6875, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 0 Epoch 44/200: Tr L: 0.1203, Tr Acc: 0.9467, Val L: 0.7777, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6736, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 45/200: Tr L: 0.0918, Tr Acc: 0.9667, Val L: 0.8076, Val Acc: 0.6000, Val Bal Acc: 0.5174, Val Roc AUC: 0.6458, Val_mcc: 0.0417, Val F1: 0.2857 lr: 0.000047\n",
      " Fold 0 Epoch 46/200: Tr L: 0.1423, Tr Acc: 0.9467, Val L: 0.8017, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6458, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 47/200: Tr L: 0.1649, Tr Acc: 0.9333, Val L: 0.7836, Val Acc: 0.5600, Val Bal Acc: 0.5104, Val Roc AUC: 0.6667, Val_mcc: 0.0214, Val F1: 0.3529 lr: 0.000047\n",
      " Fold 0 Epoch 48/200: Tr L: 0.1165, Tr Acc: 0.9467, Val L: 0.7804, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6597, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 0 Epoch 49/200: Tr L: 0.1576, Tr Acc: 0.9267, Val L: 0.7804, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6736, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 50/200: Tr L: 0.1103, Tr Acc: 0.9467, Val L: 0.7672, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6667, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 51/200: Tr L: 0.0964, Tr Acc: 0.9667, Val L: 0.8232, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6458, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 52/200: Tr L: 0.1025, Tr Acc: 0.9667, Val L: 0.8128, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6528, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 53/200: Tr L: 0.1026, Tr Acc: 0.9533, Val L: 0.7981, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6528, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 0 Epoch 54/200: Tr L: 0.1500, Tr Acc: 0.9267, Val L: 0.7701, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6944, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 0 Epoch 55/200: Tr L: 0.1090, Tr Acc: 0.9400, Val L: 0.7848, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6875, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 0 Epoch 56/200: Tr L: 0.1222, Tr Acc: 0.9467, Val L: 0.7922, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6944, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000024\n",
      " Fold 0 Epoch 57/200: Tr L: 0.1014, Tr Acc: 0.9600, Val L: 0.8059, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6736, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000024\n",
      " Fold 0 Epoch 58/200: Tr L: 0.1483, Tr Acc: 0.9267, Val L: 0.8098, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6736, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000024\n",
      " Fold 0 Epoch 59/200: Tr L: 0.1393, Tr Acc: 0.9267, Val L: 0.7972, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6875, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 0 Epoch 60/200: Tr L: 0.0827, Tr Acc: 0.9600, Val L: 0.7685, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6806, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 0 Epoch 61/200: Tr L: 0.0613, Tr Acc: 0.9933, Val L: 0.7650, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6806, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 0 Epoch 62/200: Tr L: 0.1166, Tr Acc: 0.9667, Val L: 0.7671, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6806, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 0 Epoch 63/200: Tr L: 0.0721, Tr Acc: 0.9800, Val L: 0.7346, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.6875, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 0 Epoch 64/200: Tr L: 0.1146, Tr Acc: 0.9533, Val L: 0.7282, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.6875, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 0 Epoch 65/200: Tr L: 0.1272, Tr Acc: 0.9467, Val L: 0.7203, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.6944, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 0 Epoch 66/200: Tr L: 0.0996, Tr Acc: 0.9600, Val L: 0.7158, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7222, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 0 Epoch 67/200: Tr L: 0.1253, Tr Acc: 0.9200, Val L: 0.7011, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7222, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 0 Epoch 68/200: Tr L: 0.1221, Tr Acc: 0.9533, Val L: 0.7053, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7083, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 0 Epoch 69/200: Tr L: 0.0874, Tr Acc: 0.9600, Val L: 0.7195, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 70/200: Tr L: 0.0963, Tr Acc: 0.9400, Val L: 0.7291, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7014, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000024\n",
      " Fold 0 Epoch 71/200: Tr L: 0.1059, Tr Acc: 0.9800, Val L: 0.7450, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7222, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000024\n",
      " Fold 0 Epoch 72/200: Tr L: 0.0508, Tr Acc: 0.9867, Val L: 0.7357, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7222, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000024\n",
      " Fold 0 Epoch 73/200: Tr L: 0.0493, Tr Acc: 0.9867, Val L: 0.7556, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7083, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 74/200: Tr L: 0.0858, Tr Acc: 0.9867, Val L: 0.7692, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7014, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 0 Epoch 75/200: Tr L: 0.0931, Tr Acc: 0.9733, Val L: 0.7835, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6944, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 0 Epoch 76/200: Tr L: 0.1430, Tr Acc: 0.9400, Val L: 0.7646, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7083, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 77/200: Tr L: 0.1086, Tr Acc: 0.9467, Val L: 0.7622, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7083, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 0 Epoch 78/200: Tr L: 0.0817, Tr Acc: 0.9733, Val L: 0.7810, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7014, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 0 Epoch 79/200: Tr L: 0.0878, Tr Acc: 0.9733, Val L: 0.7753, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7083, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 80/200: Tr L: 0.0918, Tr Acc: 0.9400, Val L: 0.7727, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.7083, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000024\n",
      " Fold 0 Epoch 81/200: Tr L: 0.0644, Tr Acc: 0.9667, Val L: 0.7828, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7014, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 82/200: Tr L: 0.0799, Tr Acc: 0.9667, Val L: 0.7782, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7083, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 83/200: Tr L: 0.1853, Tr Acc: 0.9200, Val L: 0.7751, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7014, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 0 Epoch 84/200: Tr L: 0.0676, Tr Acc: 0.9667, Val L: 0.8218, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6875, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000024\n",
      "Early stopping triggered at epoch 84 for fold 0\n",
      "--- Evaluating Fold 1 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 0: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 0 FINAL] Test Loss: 0.5004 | Test Acc: 0.8095 | test Balanced Acc: 0.8221 | test F1: 0.7778 | Test AUC: 0.8750 | Test MCC: 0.6264\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:52:17,697] A new study created in memory with name: no-name-9838d589-85ca-46a8-a442-4b07db35d81c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 2 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 2 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 2.\n",
      "--- Starting Hyperparameter Tuning for Fold 2 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:52:43,912] Trial 0 finished with value: 0.680057500799497 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.680057500799497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:53:09,904] Trial 1 finished with value: 3.2621150302390256 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.680057500799497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 16:53:35,409] Trial 2 finished with value: 0.7382180988788605 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.680057500799497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 2 with LR=0.000047 ---\n",
      "X_train_es: (117,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 117, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 1 Epoch 1/200: Tr L: 0.7023, Tr Acc: 0.5878, Val L: 0.8129, Val Acc: 0.3200, Val Bal Acc: 0.3958, Val Roc AUC: 0.3958, Val_mcc: -0.2500, Val F1: 0.4138 lr: 0.000047\n",
      " Fold 1 Epoch 2/200: Tr L: 0.6010, Tr Acc: 0.6892, Val L: 0.8189, Val Acc: 0.3600, Val Bal Acc: 0.4757, Val Roc AUC: 0.5833, Val_mcc: -0.0860, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 1 Epoch 3/200: Tr L: 0.5268, Tr Acc: 0.7838, Val L: 0.7474, Val Acc: 0.5200, Val Bal Acc: 0.6007, Val Roc AUC: 0.7153, Val_mcc: 0.2263, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 1 Epoch 4/200: Tr L: 0.4782, Tr Acc: 0.8108, Val L: 0.6904, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.7153, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000047\n",
      " Fold 1 Epoch 5/200: Tr L: 0.4703, Tr Acc: 0.8108, Val L: 0.6453, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7222, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 1 Epoch 6/200: Tr L: 0.3935, Tr Acc: 0.8378, Val L: 0.6345, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7153, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 1 Epoch 7/200: Tr L: 0.3807, Tr Acc: 0.8716, Val L: 0.6155, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.6944, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 8/200: Tr L: 0.3332, Tr Acc: 0.9054, Val L: 0.6104, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7153, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 1 Epoch 9/200: Tr L: 0.3711, Tr Acc: 0.8851, Val L: 0.6115, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7222, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 1 Epoch 10/200: Tr L: 0.3071, Tr Acc: 0.8581, Val L: 0.6252, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7014, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 11/200: Tr L: 0.2753, Tr Acc: 0.9122, Val L: 0.6424, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7222, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 12/200: Tr L: 0.2569, Tr Acc: 0.9189, Val L: 0.6631, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7222, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 1 Epoch 13/200: Tr L: 0.2758, Tr Acc: 0.9054, Val L: 0.6781, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7222, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 1 Epoch 14/200: Tr L: 0.2918, Tr Acc: 0.8649, Val L: 0.6702, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7222, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 1 Epoch 15/200: Tr L: 0.2756, Tr Acc: 0.9122, Val L: 0.6490, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7431, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 16/200: Tr L: 0.2960, Tr Acc: 0.8784, Val L: 0.6522, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7639, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 17/200: Tr L: 0.2564, Tr Acc: 0.8851, Val L: 0.7017, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7708, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000047\n",
      " Fold 1 Epoch 18/200: Tr L: 0.2212, Tr Acc: 0.8986, Val L: 0.7003, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7708, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000047\n",
      " Fold 1 Epoch 19/200: Tr L: 0.2350, Tr Acc: 0.9257, Val L: 0.6782, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7639, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 1 Epoch 20/200: Tr L: 0.1912, Tr Acc: 0.9324, Val L: 0.6914, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7639, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 1 Epoch 21/200: Tr L: 0.1752, Tr Acc: 0.9189, Val L: 0.6927, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7778, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 1 Epoch 22/200: Tr L: 0.1627, Tr Acc: 0.9595, Val L: 0.7027, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7847, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 1 Epoch 23/200: Tr L: 0.2262, Tr Acc: 0.8986, Val L: 0.6596, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7639, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 24/200: Tr L: 0.2040, Tr Acc: 0.9189, Val L: 0.6590, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7569, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 1 Epoch 25/200: Tr L: 0.1857, Tr Acc: 0.9122, Val L: 0.6677, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7569, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 1 Epoch 26/200: Tr L: 0.1899, Tr Acc: 0.9257, Val L: 0.6905, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7639, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 1 Epoch 27/200: Tr L: 0.1864, Tr Acc: 0.9392, Val L: 0.6820, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7569, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 1 Epoch 28/200: Tr L: 0.1679, Tr Acc: 0.9392, Val L: 0.6920, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7500, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 1 Epoch 29/200: Tr L: 0.1996, Tr Acc: 0.8986, Val L: 0.6943, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7639, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 30/200: Tr L: 0.1527, Tr Acc: 0.9459, Val L: 0.6754, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7778, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 31/200: Tr L: 0.1850, Tr Acc: 0.9054, Val L: 0.6696, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7708, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 1 Epoch 32/200: Tr L: 0.1629, Tr Acc: 0.9392, Val L: 0.6498, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7778, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 1 Epoch 33/200: Tr L: 0.1382, Tr Acc: 0.9595, Val L: 0.6802, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7639, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 1 Epoch 34/200: Tr L: 0.1786, Tr Acc: 0.9324, Val L: 0.6991, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7708, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 1 Epoch 35/200: Tr L: 0.1184, Tr Acc: 0.9595, Val L: 0.7250, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7569, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 1 Epoch 36/200: Tr L: 0.1523, Tr Acc: 0.9189, Val L: 0.7336, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 1 Epoch 37/200: Tr L: 0.0859, Tr Acc: 0.9797, Val L: 0.8036, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7431, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 1 Epoch 38/200: Tr L: 0.1433, Tr Acc: 0.9324, Val L: 0.8541, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7500, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 1 Epoch 39/200: Tr L: 0.1526, Tr Acc: 0.9257, Val L: 0.8046, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7500, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 1 Epoch 40/200: Tr L: 0.1236, Tr Acc: 0.9459, Val L: 0.7840, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7431, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 1 Epoch 41/200: Tr L: 0.1233, Tr Acc: 0.9595, Val L: 0.7554, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.7431, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 1 Epoch 42/200: Tr L: 0.1351, Tr Acc: 0.9459, Val L: 0.7570, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7500, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 1 Epoch 43/200: Tr L: 0.1665, Tr Acc: 0.9392, Val L: 0.7518, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7431, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 1 Epoch 44/200: Tr L: 0.1222, Tr Acc: 0.9797, Val L: 0.7781, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7500, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 45/200: Tr L: 0.0901, Tr Acc: 0.9662, Val L: 0.7917, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 46/200: Tr L: 0.1307, Tr Acc: 0.9392, Val L: 0.7827, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 47/200: Tr L: 0.1369, Tr Acc: 0.9459, Val L: 0.7840, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 1 Epoch 48/200: Tr L: 0.1196, Tr Acc: 0.9595, Val L: 0.8390, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 1 Epoch 49/200: Tr L: 0.1016, Tr Acc: 0.9595, Val L: 0.8289, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 1 Epoch 50/200: Tr L: 0.1697, Tr Acc: 0.9257, Val L: 0.8149, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 1 Epoch 51/200: Tr L: 0.1490, Tr Acc: 0.9324, Val L: 0.7571, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7292, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 1 Epoch 52/200: Tr L: 0.1889, Tr Acc: 0.8986, Val L: 0.7551, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7500, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 1 Epoch 53/200: Tr L: 0.1494, Tr Acc: 0.9459, Val L: 0.7501, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7569, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 1 Epoch 54/200: Tr L: 0.1255, Tr Acc: 0.9392, Val L: 0.7448, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7431, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 1 Epoch 55/200: Tr L: 0.1240, Tr Acc: 0.9527, Val L: 0.7538, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7361, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 1 Epoch 56/200: Tr L: 0.0871, Tr Acc: 0.9730, Val L: 0.7697, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7292, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 1 Epoch 57/200: Tr L: 0.1109, Tr Acc: 0.9595, Val L: 0.7826, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7361, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 58/200: Tr L: 0.0952, Tr Acc: 0.9662, Val L: 0.7627, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7431, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 1 Epoch 59/200: Tr L: 0.1639, Tr Acc: 0.9257, Val L: 0.7724, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 60/200: Tr L: 0.1409, Tr Acc: 0.9392, Val L: 0.7821, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7500, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 61/200: Tr L: 0.1007, Tr Acc: 0.9527, Val L: 0.8252, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7500, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000024\n",
      " Fold 1 Epoch 62/200: Tr L: 0.1094, Tr Acc: 0.9595, Val L: 0.8567, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7431, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 1 Epoch 63/200: Tr L: 0.1329, Tr Acc: 0.9459, Val L: 0.8117, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7500, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 1 Epoch 64/200: Tr L: 0.1269, Tr Acc: 0.9459, Val L: 0.7684, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7500, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 65/200: Tr L: 0.0884, Tr Acc: 0.9730, Val L: 0.7437, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.7431, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 1 Epoch 66/200: Tr L: 0.1291, Tr Acc: 0.9459, Val L: 0.7645, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 67/200: Tr L: 0.1623, Tr Acc: 0.9459, Val L: 0.7934, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 1 Epoch 68/200: Tr L: 0.1237, Tr Acc: 0.9459, Val L: 0.7816, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.7431, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      "Early stopping triggered at epoch 68 for fold 1\n",
      "--- Evaluating Fold 2 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 1: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 1 FINAL] Test Loss: 0.7042 | Test Acc: 0.6818 | test Balanced Acc: 0.6161 | test F1: 0.4615 | Test AUC: 0.6161 | Test MCC: 0.2665\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:01:17,563] A new study created in memory with name: no-name-0238c15b-c7b6-4b00-8ab6-cdfe6e8f63fe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 3 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 3 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 3.\n",
      "--- Starting Hyperparameter Tuning for Fold 3 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:01:42,488] Trial 0 finished with value: 0.7070213655630747 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7070213655630747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:02:07,069] Trial 1 finished with value: 1.5069339275360107 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7070213655630747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:02:32,408] Trial 2 finished with value: 0.7387103339036305 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7070213655630747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 3 with LR=0.000047 ---\n",
      "X_train_es: (118,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 118, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 2 Epoch 1/200: Tr L: 0.6561, Tr Acc: 0.6067, Val L: 0.8568, Val Acc: 0.4400, Val Bal Acc: 0.5382, Val Roc AUC: 0.3472, Val_mcc: 0.1000, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 2 Epoch 2/200: Tr L: 0.5873, Tr Acc: 0.7067, Val L: 0.8806, Val Acc: 0.4400, Val Bal Acc: 0.5382, Val Roc AUC: 0.5347, Val_mcc: 0.1000, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 2 Epoch 3/200: Tr L: 0.5303, Tr Acc: 0.7667, Val L: 0.8275, Val Acc: 0.4800, Val Bal Acc: 0.5451, Val Roc AUC: 0.5972, Val_mcc: 0.0965, Val F1: 0.5185 lr: 0.000047\n",
      " Fold 2 Epoch 4/200: Tr L: 0.4821, Tr Acc: 0.7600, Val L: 0.7770, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6319, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 2 Epoch 5/200: Tr L: 0.4329, Tr Acc: 0.8200, Val L: 0.7443, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6458, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 2 Epoch 6/200: Tr L: 0.3809, Tr Acc: 0.8600, Val L: 0.7361, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6458, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 2 Epoch 7/200: Tr L: 0.3989, Tr Acc: 0.8133, Val L: 0.7773, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6597, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 2 Epoch 8/200: Tr L: 0.3601, Tr Acc: 0.8600, Val L: 0.7758, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6597, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 2 Epoch 9/200: Tr L: 0.3193, Tr Acc: 0.8533, Val L: 0.7680, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6597, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 2 Epoch 10/200: Tr L: 0.3802, Tr Acc: 0.8400, Val L: 0.7663, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6597, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 2 Epoch 11/200: Tr L: 0.3081, Tr Acc: 0.8867, Val L: 0.7848, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6528, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 2 Epoch 12/200: Tr L: 0.2981, Tr Acc: 0.8867, Val L: 0.7753, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6528, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 13/200: Tr L: 0.2759, Tr Acc: 0.9067, Val L: 0.7726, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6667, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 2 Epoch 14/200: Tr L: 0.2561, Tr Acc: 0.9067, Val L: 0.7886, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6528, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 15/200: Tr L: 0.2908, Tr Acc: 0.8800, Val L: 0.8111, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6597, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 2 Epoch 16/200: Tr L: 0.2323, Tr Acc: 0.9000, Val L: 0.8174, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6528, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 2 Epoch 17/200: Tr L: 0.2398, Tr Acc: 0.8933, Val L: 0.8301, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6528, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 18/200: Tr L: 0.2065, Tr Acc: 0.9400, Val L: 0.8758, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6458, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 2 Epoch 19/200: Tr L: 0.2317, Tr Acc: 0.9200, Val L: 0.9040, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6389, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 2 Epoch 20/200: Tr L: 0.1952, Tr Acc: 0.9267, Val L: 0.9110, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6181, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 21/200: Tr L: 0.1949, Tr Acc: 0.9267, Val L: 0.9083, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6181, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 22/200: Tr L: 0.2385, Tr Acc: 0.9000, Val L: 0.9347, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6250, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 23/200: Tr L: 0.1662, Tr Acc: 0.9533, Val L: 0.9453, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6111, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 2 Epoch 24/200: Tr L: 0.1925, Tr Acc: 0.9200, Val L: 0.9669, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6319, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 25/200: Tr L: 0.1914, Tr Acc: 0.9067, Val L: 0.9555, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6458, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 26/200: Tr L: 0.1946, Tr Acc: 0.9067, Val L: 0.9613, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6389, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 27/200: Tr L: 0.1839, Tr Acc: 0.9467, Val L: 0.9612, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6458, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 28/200: Tr L: 0.1797, Tr Acc: 0.9400, Val L: 0.9633, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6389, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 29/200: Tr L: 0.1413, Tr Acc: 0.9467, Val L: 0.9754, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6458, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 2 Epoch 30/200: Tr L: 0.1879, Tr Acc: 0.9200, Val L: 0.9813, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 31/200: Tr L: 0.1522, Tr Acc: 0.9467, Val L: 0.9838, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6250, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 32/200: Tr L: 0.1491, Tr Acc: 0.9400, Val L: 1.0025, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 33/200: Tr L: 0.1590, Tr Acc: 0.9467, Val L: 1.0056, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 34/200: Tr L: 0.1322, Tr Acc: 0.9533, Val L: 0.9798, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6389, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 35/200: Tr L: 0.1327, Tr Acc: 0.9467, Val L: 0.9946, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6458, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 36/200: Tr L: 0.1005, Tr Acc: 0.9733, Val L: 1.0228, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 37/200: Tr L: 0.1547, Tr Acc: 0.9133, Val L: 1.0444, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6528, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 2 Epoch 38/200: Tr L: 0.1149, Tr Acc: 0.9533, Val L: 1.0579, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6389, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 39/200: Tr L: 0.1062, Tr Acc: 0.9867, Val L: 1.0913, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6250, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 40/200: Tr L: 0.1348, Tr Acc: 0.9467, Val L: 1.1068, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6181, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 41/200: Tr L: 0.0872, Tr Acc: 0.9733, Val L: 1.1051, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6181, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 42/200: Tr L: 0.1784, Tr Acc: 0.9133, Val L: 1.1107, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6181, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 43/200: Tr L: 0.1349, Tr Acc: 0.9600, Val L: 1.1274, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 44/200: Tr L: 0.1021, Tr Acc: 0.9600, Val L: 1.1470, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6250, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 45/200: Tr L: 0.0951, Tr Acc: 0.9733, Val L: 1.1232, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 46/200: Tr L: 0.1643, Tr Acc: 0.9333, Val L: 1.1250, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6250, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 47/200: Tr L: 0.1571, Tr Acc: 0.9333, Val L: 1.1484, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6181, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 48/200: Tr L: 0.1675, Tr Acc: 0.9467, Val L: 1.1636, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6250, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 49/200: Tr L: 0.1758, Tr Acc: 0.9133, Val L: 1.1593, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.6181, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 2 Epoch 50/200: Tr L: 0.1313, Tr Acc: 0.9467, Val L: 1.1395, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.6042, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 2 Epoch 51/200: Tr L: 0.1513, Tr Acc: 0.9267, Val L: 1.1270, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6111, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 52/200: Tr L: 0.1173, Tr Acc: 0.9600, Val L: 1.1486, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6042, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 53/200: Tr L: 0.1043, Tr Acc: 0.9667, Val L: 1.1551, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.5972, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 2 Epoch 54/200: Tr L: 0.1039, Tr Acc: 0.9667, Val L: 1.1630, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.5972, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 2 Epoch 55/200: Tr L: 0.1185, Tr Acc: 0.9400, Val L: 1.1663, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5972, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 56/200: Tr L: 0.0786, Tr Acc: 0.9867, Val L: 1.1577, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5972, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 57/200: Tr L: 0.0453, Tr Acc: 0.9933, Val L: 1.1741, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5972, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 58/200: Tr L: 0.1713, Tr Acc: 0.9133, Val L: 1.1913, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6042, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 59/200: Tr L: 0.1303, Tr Acc: 0.9600, Val L: 1.1786, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6111, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 60/200: Tr L: 0.1075, Tr Acc: 0.9533, Val L: 1.2055, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6042, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 61/200: Tr L: 0.1168, Tr Acc: 0.9733, Val L: 1.1949, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5972, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 62/200: Tr L: 0.1496, Tr Acc: 0.9533, Val L: 1.1870, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5972, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 63/200: Tr L: 0.1413, Tr Acc: 0.9333, Val L: 1.1946, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6042, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 64/200: Tr L: 0.1030, Tr Acc: 0.9800, Val L: 1.1947, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6250, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000024\n",
      " Fold 2 Epoch 65/200: Tr L: 0.1286, Tr Acc: 0.9600, Val L: 1.1989, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.6181, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 2 Epoch 66/200: Tr L: 0.0891, Tr Acc: 0.9667, Val L: 1.1801, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.6181, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      "Early stopping triggered at epoch 66 for fold 2\n",
      "--- Evaluating Fold 3 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 2: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 2 FINAL] Test Loss: 0.8212 | Test Acc: 0.4762 | test Balanced Acc: 0.4808 | test F1: 0.4211 | Test AUC: 0.4135 | Test MCC: -0.0374\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:09:50,397] A new study created in memory with name: no-name-7a68b9b4-24a5-400a-80cd-e0c834c525f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 4 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 4 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 4.\n",
      "--- Starting Hyperparameter Tuning for Fold 4 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:10:15,163] Trial 0 finished with value: 0.7121490240097046 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7121490240097046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:10:40,118] Trial 1 finished with value: 2.1440735226497054 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7121490240097046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:11:04,952] Trial 2 finished with value: 1.0480024119218192 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7121490240097046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 4 with LR=0.000047 ---\n",
      "X_train_es: (117,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 117, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 3 Epoch 1/200: Tr L: 0.6637, Tr Acc: 0.5811, Val L: 0.8302, Val Acc: 0.3200, Val Bal Acc: 0.4201, Val Roc AUC: 0.4861, Val_mcc: -0.2359, Val F1: 0.4516 lr: 0.000047\n",
      " Fold 3 Epoch 2/200: Tr L: 0.5776, Tr Acc: 0.6824, Val L: 0.9554, Val Acc: 0.3200, Val Bal Acc: 0.4444, Val Roc AUC: 0.5000, Val_mcc: -0.2722, Val F1: 0.4848 lr: 0.000047\n",
      " Fold 3 Epoch 3/200: Tr L: 0.5262, Tr Acc: 0.7635, Val L: 0.9215, Val Acc: 0.4400, Val Bal Acc: 0.5382, Val Roc AUC: 0.5625, Val_mcc: 0.1000, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 3 Epoch 4/200: Tr L: 0.4609, Tr Acc: 0.8378, Val L: 0.8643, Val Acc: 0.4800, Val Bal Acc: 0.5451, Val Roc AUC: 0.5694, Val_mcc: 0.0965, Val F1: 0.5185 lr: 0.000047\n",
      " Fold 3 Epoch 5/200: Tr L: 0.4728, Tr Acc: 0.8108, Val L: 0.8065, Val Acc: 0.5200, Val Bal Acc: 0.5764, Val Roc AUC: 0.5694, Val_mcc: 0.1572, Val F1: 0.5385 lr: 0.000047\n",
      " Fold 3 Epoch 6/200: Tr L: 0.4072, Tr Acc: 0.8378, Val L: 0.7293, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.5694, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000047\n",
      " Fold 3 Epoch 7/200: Tr L: 0.4091, Tr Acc: 0.8108, Val L: 0.6877, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.5556, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000047\n",
      " Fold 3 Epoch 8/200: Tr L: 0.3278, Tr Acc: 0.8716, Val L: 0.6743, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.5833, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 3 Epoch 9/200: Tr L: 0.3249, Tr Acc: 0.8716, Val L: 0.6684, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6042, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000047\n",
      " Fold 3 Epoch 10/200: Tr L: 0.3267, Tr Acc: 0.8851, Val L: 0.6958, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5903, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 3 Epoch 11/200: Tr L: 0.3116, Tr Acc: 0.8784, Val L: 0.7077, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.5833, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 3 Epoch 12/200: Tr L: 0.2523, Tr Acc: 0.9054, Val L: 0.7076, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.5903, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 3 Epoch 13/200: Tr L: 0.2470, Tr Acc: 0.9054, Val L: 0.7229, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6250, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 14/200: Tr L: 0.2440, Tr Acc: 0.8986, Val L: 0.7315, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6319, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 15/200: Tr L: 0.2461, Tr Acc: 0.9257, Val L: 0.7130, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6528, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 3 Epoch 16/200: Tr L: 0.2559, Tr Acc: 0.8784, Val L: 0.7319, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6319, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 3 Epoch 17/200: Tr L: 0.2813, Tr Acc: 0.8784, Val L: 0.7586, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6528, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 18/200: Tr L: 0.1749, Tr Acc: 0.9730, Val L: 0.7855, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6319, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 19/200: Tr L: 0.2303, Tr Acc: 0.9324, Val L: 0.8025, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6250, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 20/200: Tr L: 0.1968, Tr Acc: 0.9324, Val L: 0.8258, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6181, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 21/200: Tr L: 0.1676, Tr Acc: 0.9392, Val L: 0.8117, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6319, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 22/200: Tr L: 0.1791, Tr Acc: 0.9257, Val L: 0.8544, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6181, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 23/200: Tr L: 0.2293, Tr Acc: 0.8649, Val L: 0.8240, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6111, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 24/200: Tr L: 0.1866, Tr Acc: 0.9324, Val L: 0.7895, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6250, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 25/200: Tr L: 0.1328, Tr Acc: 0.9662, Val L: 0.7660, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6250, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 26/200: Tr L: 0.1987, Tr Acc: 0.8986, Val L: 0.7751, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.6042, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000047\n",
      " Fold 3 Epoch 27/200: Tr L: 0.1915, Tr Acc: 0.9392, Val L: 0.7812, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.5903, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 3 Epoch 28/200: Tr L: 0.1575, Tr Acc: 0.9459, Val L: 0.7623, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.5903, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 3 Epoch 29/200: Tr L: 0.1887, Tr Acc: 0.9392, Val L: 0.7615, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6042, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 3 Epoch 30/200: Tr L: 0.1310, Tr Acc: 0.9392, Val L: 0.8011, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.5833, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 3 Epoch 31/200: Tr L: 0.1508, Tr Acc: 0.9189, Val L: 0.8053, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6042, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 3 Epoch 32/200: Tr L: 0.1493, Tr Acc: 0.9459, Val L: 0.8144, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6250, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 3 Epoch 33/200: Tr L: 0.1280, Tr Acc: 0.9392, Val L: 0.8499, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5972, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 34/200: Tr L: 0.1365, Tr Acc: 0.9527, Val L: 0.8713, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.6181, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000047\n",
      " Fold 3 Epoch 35/200: Tr L: 0.0976, Tr Acc: 0.9730, Val L: 0.8587, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.5903, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 3 Epoch 36/200: Tr L: 0.1592, Tr Acc: 0.9257, Val L: 0.8386, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6042, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 3 Epoch 37/200: Tr L: 0.0833, Tr Acc: 0.9797, Val L: 0.8343, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.5972, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000047\n",
      " Fold 3 Epoch 38/200: Tr L: 0.0987, Tr Acc: 0.9730, Val L: 0.9035, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.5903, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000047\n",
      " Fold 3 Epoch 39/200: Tr L: 0.0965, Tr Acc: 0.9595, Val L: 0.9830, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.5972, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000047\n",
      " Fold 3 Epoch 40/200: Tr L: 0.0972, Tr Acc: 0.9730, Val L: 0.9156, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5972, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 3 Epoch 41/200: Tr L: 0.1023, Tr Acc: 0.9662, Val L: 0.8847, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6042, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 42/200: Tr L: 0.0925, Tr Acc: 0.9595, Val L: 0.8731, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5833, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 43/200: Tr L: 0.1338, Tr Acc: 0.9459, Val L: 0.9061, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5764, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 44/200: Tr L: 0.0926, Tr Acc: 0.9730, Val L: 0.8942, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 45/200: Tr L: 0.1254, Tr Acc: 0.9459, Val L: 0.8706, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 46/200: Tr L: 0.1095, Tr Acc: 0.9392, Val L: 0.8835, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 47/200: Tr L: 0.1495, Tr Acc: 0.9257, Val L: 0.8844, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5903, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 48/200: Tr L: 0.0949, Tr Acc: 0.9662, Val L: 0.8542, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5833, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 49/200: Tr L: 0.1017, Tr Acc: 0.9662, Val L: 0.8435, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 50/200: Tr L: 0.1797, Tr Acc: 0.9257, Val L: 0.8470, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5764, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 51/200: Tr L: 0.1158, Tr Acc: 0.9595, Val L: 0.8115, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.5972, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000024\n",
      " Fold 3 Epoch 52/200: Tr L: 0.1926, Tr Acc: 0.9257, Val L: 0.8092, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.5972, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000024\n",
      " Fold 3 Epoch 53/200: Tr L: 0.1691, Tr Acc: 0.9122, Val L: 0.8025, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6250, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 3 Epoch 54/200: Tr L: 0.1083, Tr Acc: 0.9459, Val L: 0.8139, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6250, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 3 Epoch 55/200: Tr L: 0.0918, Tr Acc: 0.9595, Val L: 0.8277, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.6250, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000024\n",
      " Fold 3 Epoch 56/200: Tr L: 0.0909, Tr Acc: 0.9662, Val L: 0.8447, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.6042, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000024\n",
      " Fold 3 Epoch 57/200: Tr L: 0.0647, Tr Acc: 0.9797, Val L: 0.8439, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.5972, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000024\n",
      " Fold 3 Epoch 58/200: Tr L: 0.1284, Tr Acc: 0.9527, Val L: 0.8505, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.6042, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000024\n",
      " Fold 3 Epoch 59/200: Tr L: 0.1462, Tr Acc: 0.9392, Val L: 0.8681, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.5972, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000024\n",
      " Fold 3 Epoch 60/200: Tr L: 0.1249, Tr Acc: 0.9459, Val L: 0.8860, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.5903, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000024\n",
      " Fold 3 Epoch 61/200: Tr L: 0.0929, Tr Acc: 0.9459, Val L: 0.9613, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 62/200: Tr L: 0.0656, Tr Acc: 0.9730, Val L: 0.9998, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.5694, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000024\n",
      " Fold 3 Epoch 63/200: Tr L: 0.1380, Tr Acc: 0.9392, Val L: 1.0102, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 64/200: Tr L: 0.0876, Tr Acc: 0.9730, Val L: 0.9709, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5694, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 65/200: Tr L: 0.0882, Tr Acc: 0.9662, Val L: 0.9105, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5764, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 66/200: Tr L: 0.1341, Tr Acc: 0.9527, Val L: 0.9512, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5764, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 67/200: Tr L: 0.0823, Tr Acc: 0.9730, Val L: 0.9830, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5833, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 68/200: Tr L: 0.1203, Tr Acc: 0.9257, Val L: 0.9645, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5764, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      " Fold 3 Epoch 69/200: Tr L: 0.0923, Tr Acc: 0.9459, Val L: 0.9765, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.5833, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000024\n",
      "Early stopping triggered at epoch 69 for fold 3\n",
      "--- Evaluating Fold 4 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 3: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 3 FINAL] Test Loss: 0.8821 | Test Acc: 0.3636 | test Balanced Acc: 0.3393 | test F1: 0.2222 | Test AUC: 0.4196 | Test MCC: -0.3105\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:18:37,357] A new study created in memory with name: no-name-3ad9b923-6369-4112-a0a7-9f57f7fa562a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 5 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 5 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 5.\n",
      "--- Starting Hyperparameter Tuning for Fold 5 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:19:02,072] Trial 0 finished with value: 0.7130440473556519 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7130440473556519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:19:27,186] Trial 1 finished with value: 2.0990987109641233 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7130440473556519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:19:52,307] Trial 2 finished with value: 0.8985878477493923 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7130440473556519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 5 with LR=0.000047 ---\n",
      "X_train_es: (119,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 119, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 4 Epoch 1/200: Tr L: 0.7153, Tr Acc: 0.4797, Val L: 0.7245, Val Acc: 0.5600, Val Bal Acc: 0.6319, Val Roc AUC: 0.6181, Val_mcc: 0.2821, Val F1: 0.5926 lr: 0.000047\n",
      " Fold 4 Epoch 2/200: Tr L: 0.6234, Tr Acc: 0.6554, Val L: 0.7466, Val Acc: 0.4000, Val Bal Acc: 0.4826, Val Roc AUC: 0.6111, Val_mcc: -0.0417, Val F1: 0.4828 lr: 0.000047\n",
      " Fold 4 Epoch 3/200: Tr L: 0.5402, Tr Acc: 0.7973, Val L: 0.7280, Val Acc: 0.5600, Val Bal Acc: 0.6562, Val Roc AUC: 0.6528, Val_mcc: 0.3750, Val F1: 0.6207 lr: 0.000047\n",
      " Fold 4 Epoch 4/200: Tr L: 0.4892, Tr Acc: 0.7973, Val L: 0.7170, Val Acc: 0.6400, Val Bal Acc: 0.7188, Val Roc AUC: 0.7083, Val_mcc: 0.4677, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 4 Epoch 5/200: Tr L: 0.4611, Tr Acc: 0.8243, Val L: 0.6837, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6944, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 4 Epoch 6/200: Tr L: 0.4244, Tr Acc: 0.8378, Val L: 0.6894, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6736, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 4 Epoch 7/200: Tr L: 0.4505, Tr Acc: 0.8041, Val L: 0.6397, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6528, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 8/200: Tr L: 0.3823, Tr Acc: 0.8446, Val L: 0.6304, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6667, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 9/200: Tr L: 0.3500, Tr Acc: 0.8784, Val L: 0.6407, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6667, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 4 Epoch 10/200: Tr L: 0.3355, Tr Acc: 0.8514, Val L: 0.6481, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6667, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 11/200: Tr L: 0.3220, Tr Acc: 0.8851, Val L: 0.6476, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6389, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 4 Epoch 12/200: Tr L: 0.2696, Tr Acc: 0.9324, Val L: 0.6707, Val Acc: 0.4800, Val Bal Acc: 0.4965, Val Roc AUC: 0.6319, Val_mcc: -0.0067, Val F1: 0.4348 lr: 0.000047\n",
      " Fold 4 Epoch 13/200: Tr L: 0.2833, Tr Acc: 0.8986, Val L: 0.6954, Val Acc: 0.5200, Val Bal Acc: 0.5764, Val Roc AUC: 0.6111, Val_mcc: 0.1572, Val F1: 0.5385 lr: 0.000047\n",
      " Fold 4 Epoch 14/200: Tr L: 0.2703, Tr Acc: 0.9189, Val L: 0.7095, Val Acc: 0.5200, Val Bal Acc: 0.5764, Val Roc AUC: 0.6042, Val_mcc: 0.1572, Val F1: 0.5385 lr: 0.000047\n",
      " Fold 4 Epoch 15/200: Tr L: 0.2797, Tr Acc: 0.9122, Val L: 0.7010, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.5972, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000047\n",
      " Fold 4 Epoch 16/200: Tr L: 0.2621, Tr Acc: 0.9054, Val L: 0.6821, Val Acc: 0.4800, Val Bal Acc: 0.4965, Val Roc AUC: 0.6319, Val_mcc: -0.0067, Val F1: 0.4348 lr: 0.000047\n",
      " Fold 4 Epoch 17/200: Tr L: 0.2762, Tr Acc: 0.9122, Val L: 0.6672, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6319, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 4 Epoch 18/200: Tr L: 0.2097, Tr Acc: 0.9392, Val L: 0.6526, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6389, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 19/200: Tr L: 0.2353, Tr Acc: 0.9122, Val L: 0.6421, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6667, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 20/200: Tr L: 0.1994, Tr Acc: 0.9392, Val L: 0.6769, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6458, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 21/200: Tr L: 0.1898, Tr Acc: 0.9257, Val L: 0.6949, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6458, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 22/200: Tr L: 0.1649, Tr Acc: 0.9527, Val L: 0.6956, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6597, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 4 Epoch 23/200: Tr L: 0.2278, Tr Acc: 0.9122, Val L: 0.6860, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6736, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 24/200: Tr L: 0.1600, Tr Acc: 0.9527, Val L: 0.6891, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6736, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 25/200: Tr L: 0.1422, Tr Acc: 0.9459, Val L: 0.6889, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6736, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 26/200: Tr L: 0.1700, Tr Acc: 0.9392, Val L: 0.6805, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6736, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 27/200: Tr L: 0.1524, Tr Acc: 0.9527, Val L: 0.6774, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6875, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 28/200: Tr L: 0.1971, Tr Acc: 0.9189, Val L: 0.6819, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6667, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 4 Epoch 29/200: Tr L: 0.2312, Tr Acc: 0.9054, Val L: 0.6809, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6667, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 4 Epoch 30/200: Tr L: 0.1722, Tr Acc: 0.9257, Val L: 0.6877, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6736, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 4 Epoch 31/200: Tr L: 0.1411, Tr Acc: 0.9527, Val L: 0.6943, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6597, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 4 Epoch 32/200: Tr L: 0.2094, Tr Acc: 0.9392, Val L: 0.7200, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6458, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 4 Epoch 33/200: Tr L: 0.1394, Tr Acc: 0.9595, Val L: 0.7381, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6319, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 4 Epoch 34/200: Tr L: 0.1404, Tr Acc: 0.9527, Val L: 0.7341, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6389, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 4 Epoch 35/200: Tr L: 0.1314, Tr Acc: 0.9797, Val L: 0.7613, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6250, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 4 Epoch 36/200: Tr L: 0.1664, Tr Acc: 0.9324, Val L: 0.7628, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6528, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 4 Epoch 37/200: Tr L: 0.1017, Tr Acc: 0.9662, Val L: 0.7649, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6597, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 4 Epoch 38/200: Tr L: 0.1539, Tr Acc: 0.9257, Val L: 0.7623, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 4 Epoch 39/200: Tr L: 0.1191, Tr Acc: 0.9459, Val L: 0.7528, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6667, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 4 Epoch 40/200: Tr L: 0.1195, Tr Acc: 0.9459, Val L: 0.7628, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000024\n",
      " Fold 4 Epoch 41/200: Tr L: 0.1511, Tr Acc: 0.9189, Val L: 0.7406, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6597, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 4 Epoch 42/200: Tr L: 0.0897, Tr Acc: 0.9662, Val L: 0.7598, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000024\n",
      " Fold 4 Epoch 43/200: Tr L: 0.1838, Tr Acc: 0.9257, Val L: 0.7648, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000024\n",
      " Fold 4 Epoch 44/200: Tr L: 0.1213, Tr Acc: 0.9527, Val L: 0.7766, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000024\n",
      " Fold 4 Epoch 45/200: Tr L: 0.1217, Tr Acc: 0.9459, Val L: 0.7638, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6597, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000024\n",
      " Fold 4 Epoch 46/200: Tr L: 0.1158, Tr Acc: 0.9527, Val L: 0.7811, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6528, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 47/200: Tr L: 0.1103, Tr Acc: 0.9595, Val L: 0.7985, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6458, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000024\n",
      " Fold 4 Epoch 48/200: Tr L: 0.1112, Tr Acc: 0.9595, Val L: 0.8041, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6389, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000024\n",
      " Fold 4 Epoch 49/200: Tr L: 0.1233, Tr Acc: 0.9324, Val L: 0.7742, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6389, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000024\n",
      " Fold 4 Epoch 50/200: Tr L: 0.1699, Tr Acc: 0.9257, Val L: 0.7601, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6319, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000024\n",
      " Fold 4 Epoch 51/200: Tr L: 0.1427, Tr Acc: 0.9189, Val L: 0.7312, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6458, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 4 Epoch 52/200: Tr L: 0.1378, Tr Acc: 0.9459, Val L: 0.7676, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6389, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 4 Epoch 53/200: Tr L: 0.1351, Tr Acc: 0.9527, Val L: 0.7561, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6458, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000024\n",
      " Fold 4 Epoch 54/200: Tr L: 0.1672, Tr Acc: 0.9189, Val L: 0.7674, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6458, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 4 Epoch 55/200: Tr L: 0.1130, Tr Acc: 0.9527, Val L: 0.7574, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6458, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 4 Epoch 56/200: Tr L: 0.1038, Tr Acc: 0.9527, Val L: 0.7662, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.6458, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000024\n",
      " Fold 4 Epoch 57/200: Tr L: 0.0920, Tr Acc: 0.9730, Val L: 0.7391, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6528, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 58/200: Tr L: 0.1281, Tr Acc: 0.9527, Val L: 0.7276, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6667, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 59/200: Tr L: 0.1911, Tr Acc: 0.9189, Val L: 0.7244, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6806, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 60/200: Tr L: 0.1409, Tr Acc: 0.9324, Val L: 0.7434, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6736, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 61/200: Tr L: 0.0990, Tr Acc: 0.9527, Val L: 0.7539, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6944, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 62/200: Tr L: 0.1159, Tr Acc: 0.9662, Val L: 0.7839, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6667, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 63/200: Tr L: 0.1176, Tr Acc: 0.9324, Val L: 0.7812, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6667, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 64/200: Tr L: 0.0734, Tr Acc: 0.9865, Val L: 0.7936, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6528, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 4 Epoch 65/200: Tr L: 0.0728, Tr Acc: 0.9797, Val L: 0.8020, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6458, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 4 Epoch 66/200: Tr L: 0.1231, Tr Acc: 0.9392, Val L: 0.7990, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6389, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 4 Epoch 67/200: Tr L: 0.0927, Tr Acc: 0.9730, Val L: 0.8044, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.6528, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000024\n",
      " Fold 4 Epoch 68/200: Tr L: 0.1162, Tr Acc: 0.9595, Val L: 0.7846, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6597, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      "Early stopping triggered at epoch 68 for fold 4\n",
      "--- Evaluating Fold 5 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 4: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 4 FINAL] Test Loss: 0.5020 | Test Acc: 0.6500 | test Balanced Acc: 0.6071 | test F1: 0.4615 | Test AUC: 0.7857 | Test MCC: 0.2059\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:27:21,804] A new study created in memory with name: no-name-07070414-5c4b-4f4b-8e2d-5fd6781e2a1f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 6 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 6 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 6.\n",
      "--- Starting Hyperparameter Tuning for Fold 6 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:27:46,846] Trial 0 finished with value: 0.6953784227371216 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6953784227371216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:28:11,887] Trial 1 finished with value: 2.5431141654650373 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6953784227371216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:28:36,914] Trial 2 finished with value: 0.8288053373495738 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6953784227371216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 6 with LR=0.000047 ---\n",
      "X_train_es: (119,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 119, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 5 Epoch 1/200: Tr L: 0.7031, Tr Acc: 0.5203, Val L: 0.7458, Val Acc: 0.4400, Val Bal Acc: 0.5625, Val Roc AUC: 0.6667, Val_mcc: 0.2212, Val F1: 0.5625 lr: 0.000047\n",
      " Fold 5 Epoch 2/200: Tr L: 0.6234, Tr Acc: 0.6689, Val L: 0.6698, Val Acc: 0.4800, Val Bal Acc: 0.5451, Val Roc AUC: 0.7847, Val_mcc: 0.0965, Val F1: 0.5185 lr: 0.000047\n",
      " Fold 5 Epoch 3/200: Tr L: 0.5490, Tr Acc: 0.7770, Val L: 0.6153, Val Acc: 0.4800, Val Bal Acc: 0.5451, Val Roc AUC: 0.8403, Val_mcc: 0.0965, Val F1: 0.5185 lr: 0.000047\n",
      " Fold 5 Epoch 4/200: Tr L: 0.4792, Tr Acc: 0.8041, Val L: 0.5755, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.8750, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 5/200: Tr L: 0.4675, Tr Acc: 0.8041, Val L: 0.5355, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8750, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000047\n",
      " Fold 5 Epoch 6/200: Tr L: 0.4477, Tr Acc: 0.7770, Val L: 0.5012, Val Acc: 0.8000, Val Bal Acc: 0.7951, Val Roc AUC: 0.8750, Val_mcc: 0.5784, Val F1: 0.7368 lr: 0.000047\n",
      " Fold 5 Epoch 7/200: Tr L: 0.4388, Tr Acc: 0.8446, Val L: 0.4841, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.8750, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 8/200: Tr L: 0.3661, Tr Acc: 0.8649, Val L: 0.4936, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.8472, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 9/200: Tr L: 0.3967, Tr Acc: 0.8514, Val L: 0.5024, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.8264, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 10/200: Tr L: 0.3583, Tr Acc: 0.8649, Val L: 0.5067, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.8194, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 11/200: Tr L: 0.3324, Tr Acc: 0.8919, Val L: 0.5284, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.8056, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 5 Epoch 12/200: Tr L: 0.2733, Tr Acc: 0.9054, Val L: 0.5535, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7778, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 13/200: Tr L: 0.2692, Tr Acc: 0.9189, Val L: 0.5769, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7847, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 5 Epoch 14/200: Tr L: 0.2774, Tr Acc: 0.9122, Val L: 0.5810, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7778, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 5 Epoch 15/200: Tr L: 0.2862, Tr Acc: 0.8784, Val L: 0.5719, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7639, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 5 Epoch 16/200: Tr L: 0.2667, Tr Acc: 0.9122, Val L: 0.5807, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7639, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 5 Epoch 17/200: Tr L: 0.2703, Tr Acc: 0.8919, Val L: 0.5942, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7569, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 5 Epoch 18/200: Tr L: 0.2242, Tr Acc: 0.9122, Val L: 0.5844, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7500, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 5 Epoch 19/200: Tr L: 0.2666, Tr Acc: 0.9054, Val L: 0.5672, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7431, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 5 Epoch 20/200: Tr L: 0.2091, Tr Acc: 0.9122, Val L: 0.5634, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7500, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 21/200: Tr L: 0.1910, Tr Acc: 0.9324, Val L: 0.5724, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7431, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 5 Epoch 22/200: Tr L: 0.1733, Tr Acc: 0.9324, Val L: 0.5807, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7431, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 5 Epoch 23/200: Tr L: 0.2099, Tr Acc: 0.9189, Val L: 0.5889, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7292, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 24/200: Tr L: 0.1885, Tr Acc: 0.9459, Val L: 0.5942, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7292, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 5 Epoch 25/200: Tr L: 0.1521, Tr Acc: 0.9595, Val L: 0.6094, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 26/200: Tr L: 0.1548, Tr Acc: 0.9662, Val L: 0.6052, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 5 Epoch 27/200: Tr L: 0.1736, Tr Acc: 0.9392, Val L: 0.5887, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7292, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 5 Epoch 28/200: Tr L: 0.1990, Tr Acc: 0.9054, Val L: 0.5887, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.7500, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 29/200: Tr L: 0.2010, Tr Acc: 0.9257, Val L: 0.5909, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7431, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 5 Epoch 30/200: Tr L: 0.1755, Tr Acc: 0.9257, Val L: 0.5938, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7431, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 5 Epoch 31/200: Tr L: 0.1516, Tr Acc: 0.9324, Val L: 0.6160, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.7500, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 32/200: Tr L: 0.1681, Tr Acc: 0.9122, Val L: 0.6342, Val Acc: 0.8400, Val Bal Acc: 0.7778, Val Roc AUC: 0.7500, Val_mcc: 0.6667, Val F1: 0.7143 lr: 0.000047\n",
      " Fold 5 Epoch 33/200: Tr L: 0.1104, Tr Acc: 0.9595, Val L: 0.6419, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.7500, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 5 Epoch 34/200: Tr L: 0.2051, Tr Acc: 0.9054, Val L: 0.6780, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7292, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 5 Epoch 35/200: Tr L: 0.1133, Tr Acc: 0.9527, Val L: 0.6659, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7500, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 5 Epoch 36/200: Tr L: 0.1564, Tr Acc: 0.9527, Val L: 0.6604, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7639, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000047\n",
      " Fold 5 Epoch 37/200: Tr L: 0.1036, Tr Acc: 0.9730, Val L: 0.6340, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7639, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000047\n",
      " Fold 5 Epoch 38/200: Tr L: 0.1724, Tr Acc: 0.9257, Val L: 0.6200, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7500, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 5 Epoch 39/200: Tr L: 0.1172, Tr Acc: 0.9527, Val L: 0.6141, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7500, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      " Fold 5 Epoch 40/200: Tr L: 0.1067, Tr Acc: 0.9662, Val L: 0.6202, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.7431, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 41/200: Tr L: 0.1926, Tr Acc: 0.8986, Val L: 0.6147, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.7778, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 42/200: Tr L: 0.0951, Tr Acc: 0.9730, Val L: 0.6161, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7778, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      " Fold 5 Epoch 43/200: Tr L: 0.1355, Tr Acc: 0.9459, Val L: 0.6276, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7778, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000024\n",
      " Fold 5 Epoch 44/200: Tr L: 0.1182, Tr Acc: 0.9595, Val L: 0.6278, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7639, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 5 Epoch 45/200: Tr L: 0.1069, Tr Acc: 0.9459, Val L: 0.6131, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.7708, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 46/200: Tr L: 0.1273, Tr Acc: 0.9527, Val L: 0.6258, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.7639, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 47/200: Tr L: 0.1737, Tr Acc: 0.9324, Val L: 0.6363, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.7639, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 48/200: Tr L: 0.0878, Tr Acc: 0.9730, Val L: 0.6459, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7639, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 49/200: Tr L: 0.1030, Tr Acc: 0.9527, Val L: 0.6375, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7708, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 50/200: Tr L: 0.1754, Tr Acc: 0.9189, Val L: 0.6487, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7639, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 51/200: Tr L: 0.1440, Tr Acc: 0.9324, Val L: 0.6341, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7569, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 5 Epoch 52/200: Tr L: 0.1015, Tr Acc: 0.9797, Val L: 0.6355, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.7778, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 53/200: Tr L: 0.1334, Tr Acc: 0.9459, Val L: 0.6584, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7639, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000024\n",
      " Fold 5 Epoch 54/200: Tr L: 0.1462, Tr Acc: 0.9459, Val L: 0.6640, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7778, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000024\n",
      " Fold 5 Epoch 55/200: Tr L: 0.1636, Tr Acc: 0.9392, Val L: 0.6767, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.7708, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 5 Epoch 56/200: Tr L: 0.0846, Tr Acc: 0.9797, Val L: 0.6885, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7708, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 5 Epoch 57/200: Tr L: 0.1168, Tr Acc: 0.9662, Val L: 0.6850, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7778, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 58/200: Tr L: 0.1079, Tr Acc: 0.9662, Val L: 0.6937, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7569, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 59/200: Tr L: 0.1613, Tr Acc: 0.9189, Val L: 0.6905, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7569, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 60/200: Tr L: 0.1017, Tr Acc: 0.9527, Val L: 0.6842, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7639, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 61/200: Tr L: 0.0687, Tr Acc: 0.9730, Val L: 0.6939, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7708, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 5 Epoch 62/200: Tr L: 0.1013, Tr Acc: 0.9662, Val L: 0.6846, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7708, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 5 Epoch 63/200: Tr L: 0.1491, Tr Acc: 0.9459, Val L: 0.6852, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7708, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 5 Epoch 64/200: Tr L: 0.0827, Tr Acc: 0.9730, Val L: 0.6781, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.7708, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000024\n",
      " Fold 5 Epoch 65/200: Tr L: 0.0570, Tr Acc: 0.9932, Val L: 0.6783, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7639, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      " Fold 5 Epoch 66/200: Tr L: 0.1232, Tr Acc: 0.9392, Val L: 0.6762, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7639, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      " Fold 5 Epoch 67/200: Tr L: 0.0996, Tr Acc: 0.9662, Val L: 0.6725, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7639, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      "Early stopping triggered at epoch 67 for fold 5\n",
      "--- Evaluating Fold 6 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 5: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 5 FINAL] Test Loss: 0.5527 | Test Acc: 0.6500 | test Balanced Acc: 0.5595 | test F1: 0.3636 | Test AUC: 0.7262 | Test MCC: 0.1260\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:36:00,625] A new study created in memory with name: no-name-3ab20c9e-dbb4-4c63-975d-ba8673d4e2ee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 7 / 8 =====\n",
      "Outer Train images: 146 | Outer Test images: 18\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 7 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 7.\n",
      "--- Starting Hyperparameter Tuning for Fold 7 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:36:26,363] Trial 0 finished with value: 0.7215182681878407 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7215182681878407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:36:51,996] Trial 1 finished with value: 1.4998085896174114 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7215182681878407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:37:18,096] Trial 2 finished with value: 0.9470564027627308 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7215182681878407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 7 with LR=0.000047 ---\n",
      "X_train_es: (121,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 121, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 6 Epoch 1/200: Tr L: 0.6621, Tr Acc: 0.5705, Val L: 0.9792, Val Acc: 0.4000, Val Bal Acc: 0.5312, Val Roc AUC: 0.3750, Val_mcc: 0.1531, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 2/200: Tr L: 0.5576, Tr Acc: 0.6987, Val L: 0.9550, Val Acc: 0.4000, Val Bal Acc: 0.5312, Val Roc AUC: 0.6111, Val_mcc: 0.1531, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 3/200: Tr L: 0.4715, Tr Acc: 0.8205, Val L: 0.8271, Val Acc: 0.4800, Val Bal Acc: 0.5694, Val Roc AUC: 0.6875, Val_mcc: 0.1667, Val F1: 0.5517 lr: 0.000047\n",
      " Fold 6 Epoch 4/200: Tr L: 0.4622, Tr Acc: 0.8077, Val L: 0.7291, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.6944, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000047\n",
      " Fold 6 Epoch 5/200: Tr L: 0.3825, Tr Acc: 0.8590, Val L: 0.6948, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6944, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 6 Epoch 6/200: Tr L: 0.3753, Tr Acc: 0.8333, Val L: 0.6872, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.7014, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 6 Epoch 7/200: Tr L: 0.3377, Tr Acc: 0.8590, Val L: 0.6752, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.6875, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 6 Epoch 8/200: Tr L: 0.3986, Tr Acc: 0.8013, Val L: 0.6628, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6806, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 6 Epoch 9/200: Tr L: 0.3236, Tr Acc: 0.8590, Val L: 0.6423, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6806, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 6 Epoch 10/200: Tr L: 0.3142, Tr Acc: 0.8782, Val L: 0.6373, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6806, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 11/200: Tr L: 0.2541, Tr Acc: 0.9231, Val L: 0.6442, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6944, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 12/200: Tr L: 0.2967, Tr Acc: 0.8718, Val L: 0.6531, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6875, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 6 Epoch 13/200: Tr L: 0.2349, Tr Acc: 0.9038, Val L: 0.6667, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.6875, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 6 Epoch 14/200: Tr L: 0.2481, Tr Acc: 0.8910, Val L: 0.6978, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6667, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000047\n",
      " Fold 6 Epoch 15/200: Tr L: 0.2078, Tr Acc: 0.9359, Val L: 0.7347, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6667, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 6 Epoch 16/200: Tr L: 0.2138, Tr Acc: 0.9295, Val L: 0.7523, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6806, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 6 Epoch 17/200: Tr L: 0.1877, Tr Acc: 0.9295, Val L: 0.7698, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6736, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 6 Epoch 18/200: Tr L: 0.2009, Tr Acc: 0.9167, Val L: 0.7534, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6667, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 6 Epoch 19/200: Tr L: 0.1644, Tr Acc: 0.9487, Val L: 0.7554, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.6667, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 6 Epoch 20/200: Tr L: 0.1883, Tr Acc: 0.9487, Val L: 0.7525, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6736, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 6 Epoch 21/200: Tr L: 0.1760, Tr Acc: 0.9231, Val L: 0.7577, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6875, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 22/200: Tr L: 0.1786, Tr Acc: 0.9231, Val L: 0.7652, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6875, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 23/200: Tr L: 0.1770, Tr Acc: 0.9295, Val L: 0.7673, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6944, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 24/200: Tr L: 0.1360, Tr Acc: 0.9231, Val L: 0.7793, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6806, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 25/200: Tr L: 0.1710, Tr Acc: 0.9295, Val L: 0.7924, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6875, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 26/200: Tr L: 0.1767, Tr Acc: 0.9423, Val L: 0.8038, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6944, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 27/200: Tr L: 0.1131, Tr Acc: 0.9808, Val L: 0.8268, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6875, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 28/200: Tr L: 0.1374, Tr Acc: 0.9423, Val L: 0.8532, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6875, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 29/200: Tr L: 0.1548, Tr Acc: 0.9295, Val L: 0.8307, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6875, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 30/200: Tr L: 0.1003, Tr Acc: 0.9679, Val L: 0.8278, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6944, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 31/200: Tr L: 0.1419, Tr Acc: 0.9487, Val L: 0.8413, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7014, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 32/200: Tr L: 0.0980, Tr Acc: 0.9744, Val L: 0.8539, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6875, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 33/200: Tr L: 0.0960, Tr Acc: 0.9679, Val L: 0.8597, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7014, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 34/200: Tr L: 0.0955, Tr Acc: 0.9744, Val L: 0.8745, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7014, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 6 Epoch 35/200: Tr L: 0.1267, Tr Acc: 0.9423, Val L: 0.9121, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7083, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 6 Epoch 36/200: Tr L: 0.1314, Tr Acc: 0.9487, Val L: 0.9311, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6806, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000047\n",
      " Fold 6 Epoch 37/200: Tr L: 0.1217, Tr Acc: 0.9551, Val L: 0.9380, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6875, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 38/200: Tr L: 0.1036, Tr Acc: 0.9359, Val L: 0.9167, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 39/200: Tr L: 0.1555, Tr Acc: 0.9423, Val L: 0.8987, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000047\n",
      " Fold 6 Epoch 40/200: Tr L: 0.0998, Tr Acc: 0.9679, Val L: 0.8757, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7083, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000047\n",
      " Fold 6 Epoch 41/200: Tr L: 0.1124, Tr Acc: 0.9551, Val L: 0.8751, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7153, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000047\n",
      " Fold 6 Epoch 42/200: Tr L: 0.0946, Tr Acc: 0.9744, Val L: 0.8596, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7153, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      " Fold 6 Epoch 43/200: Tr L: 0.0982, Tr Acc: 0.9551, Val L: 0.8677, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7222, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 44/200: Tr L: 0.1766, Tr Acc: 0.9295, Val L: 0.8806, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7222, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 45/200: Tr L: 0.1032, Tr Acc: 0.9615, Val L: 0.8800, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7222, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 46/200: Tr L: 0.0872, Tr Acc: 0.9615, Val L: 0.8820, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 47/200: Tr L: 0.1153, Tr Acc: 0.9551, Val L: 0.8885, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7083, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 48/200: Tr L: 0.1046, Tr Acc: 0.9423, Val L: 0.9032, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7083, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 49/200: Tr L: 0.2293, Tr Acc: 0.8974, Val L: 0.8980, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7083, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 50/200: Tr L: 0.1090, Tr Acc: 0.9551, Val L: 0.8871, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7083, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 51/200: Tr L: 0.0897, Tr Acc: 0.9551, Val L: 0.8891, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7153, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      " Fold 6 Epoch 52/200: Tr L: 0.1382, Tr Acc: 0.9359, Val L: 0.8938, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7222, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 53/200: Tr L: 0.0694, Tr Acc: 0.9808, Val L: 0.8777, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7222, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 54/200: Tr L: 0.0923, Tr Acc: 0.9615, Val L: 0.8955, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.7222, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 6 Epoch 55/200: Tr L: 0.1983, Tr Acc: 0.9231, Val L: 0.8925, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7153, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 56/200: Tr L: 0.0871, Tr Acc: 0.9808, Val L: 0.8921, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 57/200: Tr L: 0.0726, Tr Acc: 0.9808, Val L: 0.8950, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7222, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 58/200: Tr L: 0.0734, Tr Acc: 0.9744, Val L: 0.8911, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7222, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 59/200: Tr L: 0.0735, Tr Acc: 0.9744, Val L: 0.8947, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 60/200: Tr L: 0.0775, Tr Acc: 0.9744, Val L: 0.8964, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7153, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 61/200: Tr L: 0.1040, Tr Acc: 0.9487, Val L: 0.8982, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7153, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 62/200: Tr L: 0.0647, Tr Acc: 0.9744, Val L: 0.8963, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7153, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000024\n",
      " Fold 6 Epoch 63/200: Tr L: 0.0819, Tr Acc: 0.9808, Val L: 0.8987, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7153, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 64/200: Tr L: 0.0943, Tr Acc: 0.9615, Val L: 0.9059, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7292, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 65/200: Tr L: 0.0704, Tr Acc: 0.9615, Val L: 0.9062, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7361, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 66/200: Tr L: 0.0644, Tr Acc: 0.9872, Val L: 0.9219, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7292, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000024\n",
      " Fold 6 Epoch 67/200: Tr L: 0.0831, Tr Acc: 0.9744, Val L: 0.9190, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7292, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000024\n",
      " Fold 6 Epoch 68/200: Tr L: 0.0840, Tr Acc: 0.9808, Val L: 0.9080, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7292, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 69/200: Tr L: 0.0655, Tr Acc: 0.9744, Val L: 0.9106, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7222, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000024\n",
      " Fold 6 Epoch 70/200: Tr L: 0.0537, Tr Acc: 0.9936, Val L: 0.9186, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7153, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000024\n",
      "Early stopping triggered at epoch 70 for fold 6\n",
      "--- Evaluating Fold 7 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 6: {0: 10, 1: 8}\n",
      "percentage of classes in test set: 0    0.555556\n",
      "1    0.444444\n",
      "Name: count, dtype: float64\n",
      " [FOLD 6 FINAL] Test Loss: 0.8654 | Test Acc: 0.5556 | test Balanced Acc: 0.5375 | test F1: 0.4286 | Test AUC: 0.5375 | Test MCC: 0.0791\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:45:28,268] A new study created in memory with name: no-name-cd14c28e-0b6f-4248-9855-a4c827650b2c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 8 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 8 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[256]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 8.\n",
      "--- Starting Hyperparameter Tuning for Fold 8 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:45:53,537] Trial 0 finished with value: 0.7046504418055217 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7046504418055217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:46:18,820] Trial 1 finished with value: 2.2420648016656437 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7046504418055217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:46:44,069] Trial 2 finished with value: 0.9021811783313751 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7046504418055217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 8 with LR=0.000047 ---\n",
      "X_train_es: (119,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 119, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 11,177,538\n",
      "Trainable parameters: 4,853,762\n",
      "Non-trainable parameters: 6,323,776\n",
      "===========================\n",
      " Fold 7 Epoch 1/200: Tr L: 0.6897, Tr Acc: 0.5526, Val L: 0.8382, Val Acc: 0.3200, Val Bal Acc: 0.4201, Val Roc AUC: 0.3889, Val_mcc: -0.2359, Val F1: 0.4516 lr: 0.000047\n",
      " Fold 7 Epoch 2/200: Tr L: 0.5837, Tr Acc: 0.7171, Val L: 0.8353, Val Acc: 0.3600, Val Bal Acc: 0.4271, Val Roc AUC: 0.4583, Val_mcc: -0.1639, Val F1: 0.4286 lr: 0.000047\n",
      " Fold 7 Epoch 3/200: Tr L: 0.5141, Tr Acc: 0.8026, Val L: 0.8258, Val Acc: 0.4000, Val Bal Acc: 0.4340, Val Roc AUC: 0.4444, Val_mcc: -0.1319, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 7 Epoch 4/200: Tr L: 0.4584, Tr Acc: 0.8224, Val L: 0.8601, Val Acc: 0.4000, Val Bal Acc: 0.4340, Val Roc AUC: 0.4653, Val_mcc: -0.1319, Val F1: 0.4000 lr: 0.000047\n",
      " Fold 7 Epoch 5/200: Tr L: 0.4418, Tr Acc: 0.7895, Val L: 0.8571, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.4653, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000047\n",
      " Fold 7 Epoch 6/200: Tr L: 0.3608, Tr Acc: 0.8618, Val L: 0.8725, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5000, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 7/200: Tr L: 0.3707, Tr Acc: 0.8750, Val L: 0.9175, Val Acc: 0.4800, Val Bal Acc: 0.4965, Val Roc AUC: 0.4931, Val_mcc: -0.0067, Val F1: 0.4348 lr: 0.000047\n",
      " Fold 7 Epoch 8/200: Tr L: 0.3639, Tr Acc: 0.8355, Val L: 0.9296, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.4722, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 7 Epoch 9/200: Tr L: 0.3666, Tr Acc: 0.8421, Val L: 0.9521, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.4653, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000047\n",
      " Fold 7 Epoch 10/200: Tr L: 0.3312, Tr Acc: 0.8816, Val L: 0.9475, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.4861, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 7 Epoch 11/200: Tr L: 0.2912, Tr Acc: 0.9276, Val L: 0.9503, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.4722, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 12/200: Tr L: 0.2493, Tr Acc: 0.9145, Val L: 0.9503, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.4861, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 13/200: Tr L: 0.2392, Tr Acc: 0.9276, Val L: 0.9654, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.4792, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 14/200: Tr L: 0.2464, Tr Acc: 0.9211, Val L: 0.9721, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.4861, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 15/200: Tr L: 0.2851, Tr Acc: 0.9013, Val L: 0.9732, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5069, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 16/200: Tr L: 0.2303, Tr Acc: 0.8882, Val L: 0.9807, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5069, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 17/200: Tr L: 0.2254, Tr Acc: 0.9408, Val L: 0.9918, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5069, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 18/200: Tr L: 0.2268, Tr Acc: 0.9079, Val L: 1.0209, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.5069, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000047\n",
      " Fold 7 Epoch 19/200: Tr L: 0.2614, Tr Acc: 0.8947, Val L: 1.0519, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.5139, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 7 Epoch 20/200: Tr L: 0.1825, Tr Acc: 0.9276, Val L: 1.0332, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5139, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 21/200: Tr L: 0.2455, Tr Acc: 0.9013, Val L: 1.0147, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5208, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 22/200: Tr L: 0.2007, Tr Acc: 0.9342, Val L: 1.0387, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5208, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 23/200: Tr L: 0.1885, Tr Acc: 0.9145, Val L: 1.0568, Val Acc: 0.5200, Val Bal Acc: 0.4792, Val Roc AUC: 0.5347, Val_mcc: -0.0417, Val F1: 0.3333 lr: 0.000047\n",
      " Fold 7 Epoch 24/200: Tr L: 0.1761, Tr Acc: 0.9342, Val L: 1.0672, Val Acc: 0.5200, Val Bal Acc: 0.4792, Val Roc AUC: 0.5417, Val_mcc: -0.0417, Val F1: 0.3333 lr: 0.000047\n",
      " Fold 7 Epoch 25/200: Tr L: 0.1962, Tr Acc: 0.9211, Val L: 1.0771, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5417, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 26/200: Tr L: 0.1852, Tr Acc: 0.9342, Val L: 1.0598, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5625, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 27/200: Tr L: 0.1442, Tr Acc: 0.9671, Val L: 1.0764, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5625, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 28/200: Tr L: 0.1744, Tr Acc: 0.9342, Val L: 1.0790, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5556, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000047\n",
      " Fold 7 Epoch 29/200: Tr L: 0.1587, Tr Acc: 0.9474, Val L: 1.0939, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5694, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 30/200: Tr L: 0.1201, Tr Acc: 0.9539, Val L: 1.1323, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5625, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000047\n",
      " Fold 7 Epoch 31/200: Tr L: 0.1648, Tr Acc: 0.9474, Val L: 1.1173, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 32/200: Tr L: 0.1773, Tr Acc: 0.9276, Val L: 1.1352, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 33/200: Tr L: 0.1517, Tr Acc: 0.9342, Val L: 1.1363, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5694, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 34/200: Tr L: 0.1447, Tr Acc: 0.9539, Val L: 1.1494, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5694, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000047\n",
      " Fold 7 Epoch 35/200: Tr L: 0.1503, Tr Acc: 0.9211, Val L: 1.1570, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 36/200: Tr L: 0.1094, Tr Acc: 0.9737, Val L: 1.1600, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5486, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 37/200: Tr L: 0.1666, Tr Acc: 0.9276, Val L: 1.1563, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5625, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 7 Epoch 38/200: Tr L: 0.1111, Tr Acc: 0.9605, Val L: 1.1642, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.5625, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 7 Epoch 39/200: Tr L: 0.1034, Tr Acc: 0.9539, Val L: 1.1695, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.5556, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 7 Epoch 40/200: Tr L: 0.1414, Tr Acc: 0.9408, Val L: 1.1730, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5556, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 7 Epoch 41/200: Tr L: 0.1250, Tr Acc: 0.9342, Val L: 1.1886, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5556, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 42/200: Tr L: 0.1250, Tr Acc: 0.9539, Val L: 1.2009, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5556, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 43/200: Tr L: 0.1227, Tr Acc: 0.9539, Val L: 1.2091, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5556, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 44/200: Tr L: 0.1103, Tr Acc: 0.9539, Val L: 1.2029, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 45/200: Tr L: 0.1348, Tr Acc: 0.9408, Val L: 1.2020, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 46/200: Tr L: 0.1303, Tr Acc: 0.9276, Val L: 1.1978, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5556, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 47/200: Tr L: 0.1009, Tr Acc: 0.9539, Val L: 1.1946, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5556, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 48/200: Tr L: 0.1103, Tr Acc: 0.9605, Val L: 1.2048, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5556, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 49/200: Tr L: 0.1134, Tr Acc: 0.9605, Val L: 1.2090, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5556, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 50/200: Tr L: 0.1107, Tr Acc: 0.9539, Val L: 1.2011, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 51/200: Tr L: 0.1254, Tr Acc: 0.9539, Val L: 1.1898, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5625, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000024\n",
      " Fold 7 Epoch 52/200: Tr L: 0.1231, Tr Acc: 0.9342, Val L: 1.2213, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5625, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 53/200: Tr L: 0.1437, Tr Acc: 0.9408, Val L: 1.2377, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5625, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 54/200: Tr L: 0.0748, Tr Acc: 0.9737, Val L: 1.2474, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5625, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 55/200: Tr L: 0.1304, Tr Acc: 0.9408, Val L: 1.2168, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5556, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 56/200: Tr L: 0.1244, Tr Acc: 0.9276, Val L: 1.2192, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5903, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000024\n",
      " Fold 7 Epoch 57/200: Tr L: 0.1544, Tr Acc: 0.9474, Val L: 1.2241, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.5903, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000024\n",
      " Fold 7 Epoch 58/200: Tr L: 0.0974, Tr Acc: 0.9408, Val L: 1.2300, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.5903, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 7 Epoch 59/200: Tr L: 0.0892, Tr Acc: 0.9605, Val L: 1.2213, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.5972, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 7 Epoch 60/200: Tr L: 0.0590, Tr Acc: 0.9868, Val L: 1.2277, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.5903, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 7 Epoch 61/200: Tr L: 0.1407, Tr Acc: 0.9342, Val L: 1.2383, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.5972, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 7 Epoch 62/200: Tr L: 0.1264, Tr Acc: 0.9605, Val L: 1.2334, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.5833, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      " Fold 7 Epoch 63/200: Tr L: 0.0743, Tr Acc: 0.9868, Val L: 1.2325, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.5694, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000024\n",
      "Early stopping triggered at epoch 63 for fold 7\n",
      "--- Evaluating Fold 8 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Test set class counts for fold 7: {0: 12, 1: 8}\n",
      "percentage of classes in test set: 0    0.6\n",
      "1    0.4\n",
      "Name: count, dtype: float64\n",
      " [FOLD 7 FINAL] Test Loss: 0.7189 | Test Acc: 0.5500 | test Balanced Acc: 0.5833 | test F1: 0.5714 | Test AUC: 0.5833 | Test MCC: 0.1712\n",
      "model class name: ResNet\n",
      "\n",
      "-------------------------------------------------\n",
      "Cross-validation results (outer folds):\n",
      "  Fold 0: Test Loss=0.5004, Acc=0.8095, F1=0.7778, Bal Acc=0.8221, AUC=0.8750, MCC=0.6264 (Best LR=0.000047)\n",
      "  Fold 1: Test Loss=0.7042, Acc=0.6818, F1=0.4615, Bal Acc=0.6161, AUC=0.6161, MCC=0.2665 (Best LR=0.000047)\n",
      "  Fold 2: Test Loss=0.8212, Acc=0.4762, F1=0.4211, Bal Acc=0.4808, AUC=0.4135, MCC=-0.0374 (Best LR=0.000047)\n",
      "  Fold 3: Test Loss=0.8821, Acc=0.3636, F1=0.2222, Bal Acc=0.3393, AUC=0.4196, MCC=-0.3105 (Best LR=0.000047)\n",
      "  Fold 4: Test Loss=0.5020, Acc=0.6500, F1=0.4615, Bal Acc=0.6071, AUC=0.7857, MCC=0.2059 (Best LR=0.000047)\n",
      "  Fold 5: Test Loss=0.5527, Acc=0.6500, F1=0.3636, Bal Acc=0.5595, AUC=0.7262, MCC=0.1260 (Best LR=0.000047)\n",
      "  Fold 6: Test Loss=0.8654, Acc=0.5556, F1=0.4286, Bal Acc=0.5375, AUC=0.5375, MCC=0.0791 (Best LR=0.000047)\n",
      "  Fold 7: Test Loss=0.7189, Acc=0.5500, F1=0.5714, Bal Acc=0.5833, AUC=0.5833, MCC=0.1712 (Best LR=0.000047)\n",
      "\n",
      "--- Aggregate Results ---\n",
      "Avg Test Accuracy: 0.5921 +/- 0.1279\n",
      "Avg Test F1-Score: 0.4635 +/- 0.1507\n",
      "Avg Test Balanced Acc: 0.5682 +/- 0.1273\n",
      "Avg Test Precision: 0.4567 +/- 0.1415\n",
      "Avg Test Recall: 0.4948 +/- 0.2014\n",
      "Avg Test MCC: 0.1409 +/- 0.2491\n",
      "-------------------------------------------------\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet18...\n",
      "Freezing layers up to index: 50\n",
      "Run name: Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/16 17:53:53 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpjvxo9l4p/model/data, flavor: pytorch). Fall back to return ['torch==2.6.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/07/16 17:53:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, shape: torch.Size([25, 3, 224, 224])\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_0.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_1.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_2.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_3.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_4.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_5.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_6.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_7.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_8.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_9.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_10.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_11.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_12.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_13.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_14.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_15.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_16.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_17.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_18.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_19.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_20.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_21.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_22.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_23.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet18_oversamp_TL_pretrained:imagenet_freeze:50_torchvision_color_transforms:False_07-16_at:17-53-49/batch_0_img_24.png\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/base.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n",
      "Configuration loaded from /home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained/resnet50.yaml\n",
      "Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.17, 'test_set_size': 0.1, 'num_folds': 8}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 32, 'num_workers': 2}, 'model': {'model_name': 'Resnet50', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'torchvision', 'pretrained_weights': 'imagenet'}, 'training': {'num_epochs': 125, 'early_stopping_patience': 40, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': 94, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '2e-4', 'patience': 25}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}\n",
      "Number of classes in the dataset: 2\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:54:00,605] A new study created in memory with name: no-name-8c8fbd1f-2052-4d05-81fb-a79d010fc351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2 unique classes.\n",
      "\n",
      "===== OUTER FOLD 1 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 1 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 1.\n",
      "--- Starting Hyperparameter Tuning for Fold 1 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:54:24,940] Trial 0 finished with value: 0.6838252743085225 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6838252743085225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:54:49,298] Trial 1 finished with value: 1.026356821258863 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6838252743085225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:55:13,654] Trial 2 finished with value: 0.683028926452001 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.683028926452001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 1 with LR=0.000401 ---\n",
      "X_train_es: (118,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 118, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 0 Epoch 1/125: Tr L: 0.6775, Tr Acc: 0.5467, Val L: 0.8340, Val Acc: 0.3600, Val Bal Acc: 0.5000, Val Roc AUC: 0.5833, Val_mcc: 0.0000, Val F1: 0.5294 lr: 0.000401\n",
      " Fold 0 Epoch 2/125: Tr L: 0.5411, Tr Acc: 0.7933, Val L: 0.9727, Val Acc: 0.4000, Val Bal Acc: 0.5312, Val Roc AUC: 0.7639, Val_mcc: 0.1531, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 0 Epoch 3/125: Tr L: 0.3794, Tr Acc: 0.8200, Val L: 0.8850, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.7847, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 0 Epoch 4/125: Tr L: 0.2493, Tr Acc: 0.9267, Val L: 0.7886, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7431, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 0 Epoch 5/125: Tr L: 0.1638, Tr Acc: 0.9533, Val L: 0.9908, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.7014, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 0 Epoch 6/125: Tr L: 0.1221, Tr Acc: 0.9333, Val L: 1.0061, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7083, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 0 Epoch 7/125: Tr L: 0.1287, Tr Acc: 0.9400, Val L: 1.1744, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7431, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 0 Epoch 8/125: Tr L: 0.1353, Tr Acc: 0.9333, Val L: 1.4013, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7222, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 0 Epoch 9/125: Tr L: 0.1102, Tr Acc: 0.9400, Val L: 1.4365, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.7500, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 0 Epoch 10/125: Tr L: 0.2281, Tr Acc: 0.9200, Val L: 1.3876, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.7222, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 0 Epoch 11/125: Tr L: 0.0806, Tr Acc: 0.9667, Val L: 1.3562, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.6736, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 0 Epoch 12/125: Tr L: 0.1001, Tr Acc: 0.9400, Val L: 1.1196, Val Acc: 0.6800, Val Bal Acc: 0.6042, Val Roc AUC: 0.7778, Val_mcc: 0.2500, Val F1: 0.4286 lr: 0.000401\n",
      " Fold 0 Epoch 13/125: Tr L: 0.1060, Tr Acc: 0.9600, Val L: 0.9161, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.8125, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 0 Epoch 14/125: Tr L: 0.0788, Tr Acc: 0.9533, Val L: 0.8401, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.8333, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 0 Epoch 15/125: Tr L: 0.1545, Tr Acc: 0.9133, Val L: 1.3206, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.8056, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000401\n",
      " Fold 0 Epoch 16/125: Tr L: 0.1035, Tr Acc: 0.9667, Val L: 1.7099, Val Acc: 0.5200, Val Bal Acc: 0.6007, Val Roc AUC: 0.8125, Val_mcc: 0.2263, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 0 Epoch 17/125: Tr L: 0.0515, Tr Acc: 0.9800, Val L: 1.4394, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.7986, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 0 Epoch 18/125: Tr L: 0.1028, Tr Acc: 0.9400, Val L: 1.6466, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7083, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 0 Epoch 19/125: Tr L: 0.1069, Tr Acc: 0.9600, Val L: 1.6708, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.6736, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 0 Epoch 20/125: Tr L: 0.1827, Tr Acc: 0.9133, Val L: 1.4207, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6250, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 0 Epoch 21/125: Tr L: 0.0831, Tr Acc: 0.9600, Val L: 1.3223, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 0 Epoch 22/125: Tr L: 0.1142, Tr Acc: 0.9467, Val L: 1.3401, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.6944, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 0 Epoch 23/125: Tr L: 0.1810, Tr Acc: 0.9333, Val L: 1.5913, Val Acc: 0.6800, Val Bal Acc: 0.5799, Val Roc AUC: 0.7083, Val_mcc: 0.2359, Val F1: 0.3333 lr: 0.000401\n",
      " Fold 0 Epoch 24/125: Tr L: 0.0899, Tr Acc: 0.9800, Val L: 2.0019, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.6944, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 0 Epoch 25/125: Tr L: 0.1394, Tr Acc: 0.9600, Val L: 1.3740, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7431, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 0 Epoch 26/125: Tr L: 0.0762, Tr Acc: 0.9600, Val L: 0.9320, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7569, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 0 Epoch 27/125: Tr L: 0.1029, Tr Acc: 0.9467, Val L: 0.8045, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7569, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 0 Epoch 28/125: Tr L: 0.1060, Tr Acc: 0.9667, Val L: 0.8893, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7292, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 0 Epoch 29/125: Tr L: 0.0567, Tr Acc: 0.9800, Val L: 1.0320, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6667, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 0 Epoch 30/125: Tr L: 0.1316, Tr Acc: 0.9533, Val L: 1.0875, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6736, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 0 Epoch 31/125: Tr L: 0.0978, Tr Acc: 0.9733, Val L: 1.0644, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.7083, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000201\n",
      " Fold 0 Epoch 32/125: Tr L: 0.0589, Tr Acc: 0.9733, Val L: 0.9599, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.7431, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000201\n",
      " Fold 0 Epoch 33/125: Tr L: 0.0893, Tr Acc: 0.9467, Val L: 1.0010, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7847, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 0 Epoch 34/125: Tr L: 0.0603, Tr Acc: 0.9800, Val L: 1.0108, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7917, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 0 Epoch 35/125: Tr L: 0.0557, Tr Acc: 0.9733, Val L: 0.9778, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7708, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 0 Epoch 36/125: Tr L: 0.0317, Tr Acc: 0.9933, Val L: 0.9733, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7847, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 0 Epoch 37/125: Tr L: 0.1102, Tr Acc: 0.9400, Val L: 0.9467, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7708, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 0 Epoch 38/125: Tr L: 0.0228, Tr Acc: 0.9933, Val L: 0.9730, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7708, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 0 Epoch 39/125: Tr L: 0.0673, Tr Acc: 0.9733, Val L: 1.0384, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7639, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 0 Epoch 40/125: Tr L: 0.0213, Tr Acc: 1.0000, Val L: 1.0755, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7153, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 0 Epoch 41/125: Tr L: 0.1242, Tr Acc: 0.9733, Val L: 1.0550, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7361, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 0 Epoch 42/125: Tr L: 0.0907, Tr Acc: 0.9467, Val L: 1.1129, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7708, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 0 Epoch 43/125: Tr L: 0.0509, Tr Acc: 0.9733, Val L: 1.0895, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7569, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 0 Epoch 44/125: Tr L: 0.0488, Tr Acc: 0.9867, Val L: 1.1194, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7708, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      "Early stopping triggered at epoch 44 for fold 0\n",
      "--- Evaluating Fold 1 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 0: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 0 FINAL] Test Loss: 0.3610 | Test Acc: 0.8571 | test Balanced Acc: 0.8606 | test F1: 0.8235 | Test AUC: 0.9423 | Test MCC: 0.7077\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:59:17,627] A new study created in memory with name: no-name-611d857e-7e7a-4734-856b-48feda673f74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 2 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 2 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 2.\n",
      "--- Starting Hyperparameter Tuning for Fold 2 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 17:59:41,986] Trial 0 finished with value: 0.6805706818898518 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6805706818898518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:00:06,245] Trial 1 finished with value: 0.7512795180082321 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6805706818898518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:00:30,487] Trial 2 finished with value: 0.6659032702445984 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6659032702445984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 2 with LR=0.000401 ---\n",
      "X_train_es: (117,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 117, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 1 Epoch 1/125: Tr L: 0.6614, Tr Acc: 0.5811, Val L: 0.7888, Val Acc: 0.3600, Val Bal Acc: 0.5000, Val Roc AUC: 0.5000, Val_mcc: 0.0000, Val F1: 0.5294 lr: 0.000401\n",
      " Fold 1 Epoch 2/125: Tr L: 0.5170, Tr Acc: 0.8176, Val L: 0.9841, Val Acc: 0.4400, Val Bal Acc: 0.5625, Val Roc AUC: 0.7361, Val_mcc: 0.2212, Val F1: 0.5625 lr: 0.000401\n",
      " Fold 1 Epoch 3/125: Tr L: 0.3435, Tr Acc: 0.8649, Val L: 0.7520, Val Acc: 0.7200, Val Bal Acc: 0.7812, Val Roc AUC: 0.7778, Val_mcc: 0.5625, Val F1: 0.7200 lr: 0.000401\n",
      " Fold 1 Epoch 4/125: Tr L: 0.2868, Tr Acc: 0.8649, Val L: 0.8625, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7917, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 1 Epoch 5/125: Tr L: 0.1945, Tr Acc: 0.9189, Val L: 1.2013, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.7569, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 1 Epoch 6/125: Tr L: 0.2044, Tr Acc: 0.9257, Val L: 0.7816, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.8056, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 7/125: Tr L: 0.1959, Tr Acc: 0.9257, Val L: 1.0454, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7708, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 1 Epoch 8/125: Tr L: 0.1052, Tr Acc: 0.9392, Val L: 0.9929, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7569, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 1 Epoch 9/125: Tr L: 0.0975, Tr Acc: 0.9527, Val L: 0.8273, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7917, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 1 Epoch 10/125: Tr L: 0.0980, Tr Acc: 0.9324, Val L: 0.8291, Val Acc: 0.8000, Val Bal Acc: 0.8194, Val Roc AUC: 0.8403, Val_mcc: 0.6138, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 1 Epoch 11/125: Tr L: 0.0768, Tr Acc: 0.9527, Val L: 0.9816, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.8056, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 12/125: Tr L: 0.1299, Tr Acc: 0.9595, Val L: 1.0706, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7222, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 1 Epoch 13/125: Tr L: 0.0917, Tr Acc: 0.9595, Val L: 1.2285, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.6181, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 1 Epoch 14/125: Tr L: 0.1266, Tr Acc: 0.9392, Val L: 1.1760, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6944, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000401\n",
      " Fold 1 Epoch 15/125: Tr L: 0.1813, Tr Acc: 0.9527, Val L: 1.9039, Val Acc: 0.4800, Val Bal Acc: 0.5451, Val Roc AUC: 0.6806, Val_mcc: 0.0965, Val F1: 0.5185 lr: 0.000401\n",
      " Fold 1 Epoch 16/125: Tr L: 0.1153, Tr Acc: 0.9730, Val L: 1.3509, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6736, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 1 Epoch 17/125: Tr L: 0.1424, Tr Acc: 0.9257, Val L: 0.9983, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.6736, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000401\n",
      " Fold 1 Epoch 18/125: Tr L: 0.1822, Tr Acc: 0.9459, Val L: 0.7943, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.7431, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 1 Epoch 19/125: Tr L: 0.1113, Tr Acc: 0.9595, Val L: 0.8738, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7153, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 1 Epoch 20/125: Tr L: 0.0798, Tr Acc: 0.9595, Val L: 1.6220, Val Acc: 0.5200, Val Bal Acc: 0.6250, Val Roc AUC: 0.6250, Val_mcc: 0.3273, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 1 Epoch 21/125: Tr L: 0.0668, Tr Acc: 0.9730, Val L: 2.0423, Val Acc: 0.5200, Val Bal Acc: 0.6007, Val Roc AUC: 0.6528, Val_mcc: 0.2263, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 1 Epoch 22/125: Tr L: 0.0551, Tr Acc: 0.9865, Val L: 2.0657, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.6458, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000401\n",
      " Fold 1 Epoch 23/125: Tr L: 0.1547, Tr Acc: 0.9595, Val L: 1.6042, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6875, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 1 Epoch 24/125: Tr L: 0.1258, Tr Acc: 0.9662, Val L: 1.5919, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7083, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 1 Epoch 25/125: Tr L: 0.0998, Tr Acc: 0.9459, Val L: 1.6581, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7014, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 1 Epoch 26/125: Tr L: 0.0628, Tr Acc: 0.9797, Val L: 1.1841, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7083, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 1 Epoch 27/125: Tr L: 0.0725, Tr Acc: 0.9459, Val L: 0.7655, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.8056, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 1 Epoch 28/125: Tr L: 0.0689, Tr Acc: 0.9459, Val L: 0.8906, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8125, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 1 Epoch 29/125: Tr L: 0.0480, Tr Acc: 0.9932, Val L: 1.1520, Val Acc: 0.7600, Val Bal Acc: 0.8125, Val Roc AUC: 0.8056, Val_mcc: 0.6124, Val F1: 0.7500 lr: 0.000401\n",
      " Fold 1 Epoch 30/125: Tr L: 0.0894, Tr Acc: 0.9527, Val L: 1.1026, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7986, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 1 Epoch 31/125: Tr L: 0.0590, Tr Acc: 0.9932, Val L: 0.8612, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.8125, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 1 Epoch 32/125: Tr L: 0.1048, Tr Acc: 0.9527, Val L: 0.7843, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8056, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 1 Epoch 33/125: Tr L: 0.1372, Tr Acc: 0.9527, Val L: 0.7677, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7986, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 1 Epoch 34/125: Tr L: 0.0807, Tr Acc: 0.9662, Val L: 0.7794, Val Acc: 0.8000, Val Bal Acc: 0.7951, Val Roc AUC: 0.8194, Val_mcc: 0.5784, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 1 Epoch 35/125: Tr L: 0.0559, Tr Acc: 0.9730, Val L: 0.8719, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7847, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 36/125: Tr L: 0.0601, Tr Acc: 0.9730, Val L: 0.9793, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.7847, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000201\n",
      " Fold 1 Epoch 37/125: Tr L: 0.0311, Tr Acc: 0.9932, Val L: 1.2608, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7778, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 1 Epoch 38/125: Tr L: 0.0507, Tr Acc: 0.9797, Val L: 1.0120, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.8056, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 1 Epoch 39/125: Tr L: 0.0613, Tr Acc: 0.9730, Val L: 0.7389, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.8472, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000201\n",
      " Fold 1 Epoch 40/125: Tr L: 0.0954, Tr Acc: 0.9662, Val L: 0.7897, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.8333, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 1 Epoch 41/125: Tr L: 0.0744, Tr Acc: 0.9797, Val L: 0.9275, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.8194, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 1 Epoch 42/125: Tr L: 0.0651, Tr Acc: 0.9865, Val L: 0.8858, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.7986, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 1 Epoch 43/125: Tr L: 0.0374, Tr Acc: 0.9730, Val L: 1.0591, Val Acc: 0.8000, Val Bal Acc: 0.7951, Val Roc AUC: 0.7569, Val_mcc: 0.5784, Val F1: 0.7368 lr: 0.000201\n",
      " Fold 1 Epoch 44/125: Tr L: 0.0475, Tr Acc: 0.9730, Val L: 1.2610, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7292, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 1 Epoch 45/125: Tr L: 0.0615, Tr Acc: 0.9662, Val L: 1.4059, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7292, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 46/125: Tr L: 0.0611, Tr Acc: 0.9730, Val L: 1.8099, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.6667, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 1 Epoch 47/125: Tr L: 0.0375, Tr Acc: 0.9730, Val L: 1.8641, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.6667, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 1 Epoch 48/125: Tr L: 0.1166, Tr Acc: 0.9527, Val L: 1.4822, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7083, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 1 Epoch 49/125: Tr L: 0.0363, Tr Acc: 0.9730, Val L: 1.2338, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000201\n",
      " Fold 1 Epoch 50/125: Tr L: 0.0545, Tr Acc: 0.9797, Val L: 1.2001, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7083, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000201\n",
      " Fold 1 Epoch 51/125: Tr L: 0.0774, Tr Acc: 0.9797, Val L: 1.0365, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.7222, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000201\n",
      " Fold 1 Epoch 52/125: Tr L: 0.0315, Tr Acc: 0.9865, Val L: 1.0801, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7361, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 1 Epoch 53/125: Tr L: 0.0785, Tr Acc: 0.9730, Val L: 0.8881, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7153, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 1 Epoch 54/125: Tr L: 0.0623, Tr Acc: 0.9730, Val L: 0.9192, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7500, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 55/125: Tr L: 0.0525, Tr Acc: 0.9662, Val L: 0.9098, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7361, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 56/125: Tr L: 0.0570, Tr Acc: 0.9797, Val L: 0.9643, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.7361, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 1 Epoch 57/125: Tr L: 0.0403, Tr Acc: 0.9730, Val L: 0.8885, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7431, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 58/125: Tr L: 0.0570, Tr Acc: 0.9730, Val L: 0.7076, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7778, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 59/125: Tr L: 0.0461, Tr Acc: 0.9797, Val L: 0.5802, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.8194, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000201\n",
      " Fold 1 Epoch 60/125: Tr L: 0.0400, Tr Acc: 0.9865, Val L: 0.5781, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8472, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 1 Epoch 61/125: Tr L: 0.0349, Tr Acc: 0.9865, Val L: 0.5304, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8472, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 62/125: Tr L: 0.0378, Tr Acc: 0.9932, Val L: 0.5432, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.8750, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 63/125: Tr L: 0.0220, Tr Acc: 0.9730, Val L: 0.5497, Val Acc: 0.8000, Val Bal Acc: 0.7465, Val Roc AUC: 0.8750, Val_mcc: 0.5541, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 64/125: Tr L: 0.0306, Tr Acc: 0.9797, Val L: 0.6212, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.8333, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 1 Epoch 65/125: Tr L: 0.0728, Tr Acc: 0.9797, Val L: 0.6560, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.8264, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 1 Epoch 66/125: Tr L: 0.0386, Tr Acc: 0.9865, Val L: 0.6666, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.8194, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 1 Epoch 67/125: Tr L: 0.0546, Tr Acc: 0.9662, Val L: 0.7566, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.8264, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 1 Epoch 68/125: Tr L: 0.0800, Tr Acc: 0.9797, Val L: 0.8379, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.8542, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 1 Epoch 69/125: Tr L: 0.0368, Tr Acc: 0.9932, Val L: 0.7616, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8403, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 70/125: Tr L: 0.0382, Tr Acc: 0.9797, Val L: 0.8280, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8472, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 71/125: Tr L: 0.1249, Tr Acc: 0.9595, Val L: 0.8441, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8750, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 72/125: Tr L: 0.0422, Tr Acc: 0.9730, Val L: 0.9209, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8403, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 73/125: Tr L: 0.0542, Tr Acc: 0.9865, Val L: 0.9076, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8125, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 74/125: Tr L: 0.0298, Tr Acc: 0.9797, Val L: 0.8236, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.8056, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 1 Epoch 75/125: Tr L: 0.0267, Tr Acc: 0.9865, Val L: 0.8037, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.8056, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 1 Epoch 76/125: Tr L: 0.0449, Tr Acc: 0.9797, Val L: 0.8372, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8125, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 77/125: Tr L: 0.0355, Tr Acc: 0.9865, Val L: 0.8105, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8125, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 78/125: Tr L: 0.0809, Tr Acc: 0.9865, Val L: 0.8029, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.8194, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 1 Epoch 79/125: Tr L: 0.0315, Tr Acc: 0.9865, Val L: 0.8587, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.8056, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 1 Epoch 80/125: Tr L: 0.0472, Tr Acc: 0.9797, Val L: 0.8486, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.8056, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 1 Epoch 81/125: Tr L: 0.0260, Tr Acc: 0.9865, Val L: 0.9275, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7778, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 1 Epoch 82/125: Tr L: 0.0523, Tr Acc: 0.9797, Val L: 1.0454, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7639, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 1 Epoch 83/125: Tr L: 0.0934, Tr Acc: 0.9662, Val L: 1.0355, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7847, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 1 Epoch 84/125: Tr L: 0.0806, Tr Acc: 0.9797, Val L: 0.9999, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8542, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 85/125: Tr L: 0.0325, Tr Acc: 0.9865, Val L: 1.0362, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8194, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 86/125: Tr L: 0.0252, Tr Acc: 0.9932, Val L: 1.1213, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7847, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000201\n",
      " Fold 1 Epoch 87/125: Tr L: 0.0262, Tr Acc: 0.9932, Val L: 1.0120, Val Acc: 0.6800, Val Bal Acc: 0.6042, Val Roc AUC: 0.7569, Val_mcc: 0.2500, Val F1: 0.4286 lr: 0.000201\n",
      " Fold 1 Epoch 88/125: Tr L: 0.0268, Tr Acc: 0.9932, Val L: 0.9476, Val Acc: 0.6800, Val Bal Acc: 0.6042, Val Roc AUC: 0.7986, Val_mcc: 0.2500, Val F1: 0.4286 lr: 0.000100\n",
      " Fold 1 Epoch 89/125: Tr L: 0.0302, Tr Acc: 0.9932, Val L: 0.9280, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7986, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 90/125: Tr L: 0.0305, Tr Acc: 0.9865, Val L: 0.9379, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7847, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 91/125: Tr L: 0.0198, Tr Acc: 0.9865, Val L: 0.9223, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8194, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 92/125: Tr L: 0.0190, Tr Acc: 0.9932, Val L: 0.8938, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7986, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 93/125: Tr L: 0.0358, Tr Acc: 0.9865, Val L: 0.8512, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8056, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 94/125: Tr L: 0.0355, Tr Acc: 0.9865, Val L: 0.9079, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8056, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 95/125: Tr L: 0.0337, Tr Acc: 0.9932, Val L: 0.9248, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8056, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 96/125: Tr L: 0.0399, Tr Acc: 0.9865, Val L: 0.8702, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.8125, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000100\n",
      " Fold 1 Epoch 97/125: Tr L: 0.0526, Tr Acc: 0.9797, Val L: 0.8730, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.8056, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000100\n",
      " Fold 1 Epoch 98/125: Tr L: 0.0394, Tr Acc: 0.9865, Val L: 0.8991, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.8056, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000100\n",
      " Fold 1 Epoch 99/125: Tr L: 0.0272, Tr Acc: 0.9797, Val L: 0.9926, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7986, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000100\n",
      " Fold 1 Epoch 100/125: Tr L: 0.0086, Tr Acc: 1.0000, Val L: 1.0436, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7917, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000100\n",
      " Fold 1 Epoch 101/125: Tr L: 0.0174, Tr Acc: 0.9932, Val L: 0.9876, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7847, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000100\n",
      "Early stopping triggered at epoch 101 for fold 1\n",
      "--- Evaluating Fold 2 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 1: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 1 FINAL] Test Loss: 0.8902 | Test Acc: 0.7727 | test Balanced Acc: 0.7946 | test F1: 0.7368 | Test AUC: 0.8750 | Test MCC: 0.5669\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:09:44,463] A new study created in memory with name: no-name-362b31c6-fb6f-43a8-9b3a-0e842dacdda3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 3 / 8 =====\n",
      "Outer Train images: 143 | Outer Test images: 21\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 3 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 3.\n",
      "--- Starting Hyperparameter Tuning for Fold 3 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:10:09,044] Trial 0 finished with value: 0.677332987387975 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.677332987387975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:10:33,441] Trial 1 finished with value: 0.7592630287011465 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.677332987387975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:10:58,001] Trial 2 finished with value: 0.6692570100227991 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6692570100227991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 3 with LR=0.000401 ---\n",
      "X_train_es: (118,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 118, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 2 Epoch 1/125: Tr L: 0.6770, Tr Acc: 0.5400, Val L: 0.7384, Val Acc: 0.4000, Val Bal Acc: 0.5069, Val Roc AUC: 0.6597, Val_mcc: 0.0205, Val F1: 0.5161 lr: 0.000401\n",
      " Fold 2 Epoch 2/125: Tr L: 0.5303, Tr Acc: 0.7933, Val L: 0.7482, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6667, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 2 Epoch 3/125: Tr L: 0.3410, Tr Acc: 0.8600, Val L: 1.2368, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.7014, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 2 Epoch 4/125: Tr L: 0.2395, Tr Acc: 0.9200, Val L: 1.4455, Val Acc: 0.4800, Val Bal Acc: 0.4479, Val Roc AUC: 0.5972, Val_mcc: -0.1021, Val F1: 0.3158 lr: 0.000401\n",
      " Fold 2 Epoch 5/125: Tr L: 0.2129, Tr Acc: 0.9333, Val L: 1.3062, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6528, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 2 Epoch 6/125: Tr L: 0.1520, Tr Acc: 0.9400, Val L: 1.3385, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.6944, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 2 Epoch 7/125: Tr L: 0.1647, Tr Acc: 0.9600, Val L: 1.3890, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.7431, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 2 Epoch 8/125: Tr L: 0.1034, Tr Acc: 0.9400, Val L: 1.6360, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.6806, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 2 Epoch 9/125: Tr L: 0.1574, Tr Acc: 0.9400, Val L: 1.6181, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.6806, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 2 Epoch 10/125: Tr L: 0.1925, Tr Acc: 0.9467, Val L: 1.7125, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.6806, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 2 Epoch 11/125: Tr L: 0.1875, Tr Acc: 0.9400, Val L: 1.9356, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6736, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 2 Epoch 12/125: Tr L: 0.1421, Tr Acc: 0.9333, Val L: 1.7539, Val Acc: 0.6000, Val Bal Acc: 0.5174, Val Roc AUC: 0.6736, Val_mcc: 0.0417, Val F1: 0.2857 lr: 0.000401\n",
      " Fold 2 Epoch 13/125: Tr L: 0.1654, Tr Acc: 0.9600, Val L: 1.4685, Val Acc: 0.5600, Val Bal Acc: 0.4618, Val Roc AUC: 0.6944, Val_mcc: -0.1000, Val F1: 0.1538 lr: 0.000401\n",
      " Fold 2 Epoch 14/125: Tr L: 0.0920, Tr Acc: 0.9533, Val L: 1.3503, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6944, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 2 Epoch 15/125: Tr L: 0.0993, Tr Acc: 0.9533, Val L: 0.8512, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7708, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 2 Epoch 16/125: Tr L: 0.0902, Tr Acc: 0.9600, Val L: 0.8557, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.7778, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 2 Epoch 17/125: Tr L: 0.0667, Tr Acc: 0.9800, Val L: 1.0404, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7431, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 2 Epoch 18/125: Tr L: 0.1609, Tr Acc: 0.9467, Val L: 1.3063, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.6806, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000401\n",
      " Fold 2 Epoch 19/125: Tr L: 0.1552, Tr Acc: 0.9733, Val L: 1.5886, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.5833, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000401\n",
      " Fold 2 Epoch 20/125: Tr L: 0.1836, Tr Acc: 0.9400, Val L: 1.6866, Val Acc: 0.4000, Val Bal Acc: 0.4097, Val Roc AUC: 0.4722, Val_mcc: -0.1746, Val F1: 0.3478 lr: 0.000401\n",
      " Fold 2 Epoch 21/125: Tr L: 0.1083, Tr Acc: 0.9667, Val L: 1.3344, Val Acc: 0.4800, Val Bal Acc: 0.4965, Val Roc AUC: 0.5069, Val_mcc: -0.0067, Val F1: 0.4348 lr: 0.000401\n",
      " Fold 2 Epoch 22/125: Tr L: 0.1432, Tr Acc: 0.9467, Val L: 1.1110, Val Acc: 0.4800, Val Bal Acc: 0.4722, Val Roc AUC: 0.5903, Val_mcc: -0.0534, Val F1: 0.3810 lr: 0.000401\n",
      " Fold 2 Epoch 23/125: Tr L: 0.0657, Tr Acc: 0.9800, Val L: 1.0622, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.7083, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 2 Epoch 24/125: Tr L: 0.0828, Tr Acc: 0.9733, Val L: 1.4287, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6944, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 2 Epoch 25/125: Tr L: 0.1386, Tr Acc: 0.9600, Val L: 1.8036, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6528, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 2 Epoch 26/125: Tr L: 0.1445, Tr Acc: 0.9533, Val L: 0.9662, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7708, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 2 Epoch 27/125: Tr L: 0.0872, Tr Acc: 0.9533, Val L: 0.7617, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.8264, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 2 Epoch 28/125: Tr L: 0.0841, Tr Acc: 0.9667, Val L: 0.6923, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8125, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 29/125: Tr L: 0.0442, Tr Acc: 0.9800, Val L: 0.7409, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8056, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 2 Epoch 30/125: Tr L: 0.0726, Tr Acc: 0.9667, Val L: 0.8697, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8125, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 2 Epoch 31/125: Tr L: 0.0726, Tr Acc: 0.9600, Val L: 0.8979, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8125, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 2 Epoch 32/125: Tr L: 0.0534, Tr Acc: 0.9667, Val L: 0.8205, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8056, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 2 Epoch 33/125: Tr L: 0.0441, Tr Acc: 0.9867, Val L: 0.7524, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8125, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 34/125: Tr L: 0.0429, Tr Acc: 0.9933, Val L: 0.6983, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8194, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 2 Epoch 35/125: Tr L: 0.0741, Tr Acc: 0.9600, Val L: 0.7612, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7986, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000201\n",
      " Fold 2 Epoch 36/125: Tr L: 0.0452, Tr Acc: 0.9800, Val L: 1.2964, Val Acc: 0.6000, Val Bal Acc: 0.5417, Val Roc AUC: 0.7292, Val_mcc: 0.0891, Val F1: 0.3750 lr: 0.000201\n",
      " Fold 2 Epoch 37/125: Tr L: 0.0863, Tr Acc: 0.9533, Val L: 1.7322, Val Acc: 0.6400, Val Bal Acc: 0.5486, Val Roc AUC: 0.7292, Val_mcc: 0.1273, Val F1: 0.3077 lr: 0.000201\n",
      " Fold 2 Epoch 38/125: Tr L: 0.0864, Tr Acc: 0.9600, Val L: 1.8905, Val Acc: 0.6400, Val Bal Acc: 0.5486, Val Roc AUC: 0.7569, Val_mcc: 0.1273, Val F1: 0.3077 lr: 0.000201\n",
      " Fold 2 Epoch 39/125: Tr L: 0.0644, Tr Acc: 0.9667, Val L: 1.6138, Val Acc: 0.6800, Val Bal Acc: 0.5799, Val Roc AUC: 0.7986, Val_mcc: 0.2359, Val F1: 0.3333 lr: 0.000201\n",
      " Fold 2 Epoch 40/125: Tr L: 0.0653, Tr Acc: 0.9800, Val L: 1.3183, Val Acc: 0.7200, Val Bal Acc: 0.6354, Val Roc AUC: 0.8194, Val_mcc: 0.3546, Val F1: 0.4615 lr: 0.000201\n",
      " Fold 2 Epoch 41/125: Tr L: 0.0557, Tr Acc: 0.9667, Val L: 1.1267, Val Acc: 0.6800, Val Bal Acc: 0.6042, Val Roc AUC: 0.8403, Val_mcc: 0.2500, Val F1: 0.4286 lr: 0.000201\n",
      " Fold 2 Epoch 42/125: Tr L: 0.0751, Tr Acc: 0.9733, Val L: 1.1609, Val Acc: 0.6800, Val Bal Acc: 0.6042, Val Roc AUC: 0.8194, Val_mcc: 0.2500, Val F1: 0.4286 lr: 0.000201\n",
      " Fold 2 Epoch 43/125: Tr L: 0.0693, Tr Acc: 0.9667, Val L: 0.9786, Val Acc: 0.6400, Val Bal Acc: 0.5729, Val Roc AUC: 0.7847, Val_mcc: 0.1639, Val F1: 0.4000 lr: 0.000201\n",
      " Fold 2 Epoch 44/125: Tr L: 0.1308, Tr Acc: 0.9667, Val L: 1.0108, Val Acc: 0.6400, Val Bal Acc: 0.5729, Val Roc AUC: 0.7708, Val_mcc: 0.1639, Val F1: 0.4000 lr: 0.000201\n",
      " Fold 2 Epoch 45/125: Tr L: 0.0433, Tr Acc: 0.9867, Val L: 0.9888, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7569, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000201\n",
      " Fold 2 Epoch 46/125: Tr L: 0.0537, Tr Acc: 0.9867, Val L: 0.9261, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7292, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 2 Epoch 47/125: Tr L: 0.0433, Tr Acc: 0.9867, Val L: 0.9574, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.7361, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000201\n",
      " Fold 2 Epoch 48/125: Tr L: 0.0392, Tr Acc: 0.9867, Val L: 0.9318, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7361, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 2 Epoch 49/125: Tr L: 0.0320, Tr Acc: 0.9800, Val L: 0.9270, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7639, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 2 Epoch 50/125: Tr L: 0.0362, Tr Acc: 0.9800, Val L: 0.9692, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7569, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 2 Epoch 51/125: Tr L: 0.0267, Tr Acc: 1.0000, Val L: 1.0180, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7569, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 2 Epoch 52/125: Tr L: 0.1028, Tr Acc: 0.9667, Val L: 1.2555, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7361, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 2 Epoch 53/125: Tr L: 0.0358, Tr Acc: 0.9800, Val L: 1.2228, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7431, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000201\n",
      " Fold 2 Epoch 54/125: Tr L: 0.0412, Tr Acc: 0.9867, Val L: 1.2531, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.7431, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000201\n",
      " Fold 2 Epoch 55/125: Tr L: 0.0436, Tr Acc: 0.9933, Val L: 1.2883, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.7569, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000100\n",
      " Fold 2 Epoch 56/125: Tr L: 0.0347, Tr Acc: 0.9800, Val L: 1.2127, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7569, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      " Fold 2 Epoch 57/125: Tr L: 0.0579, Tr Acc: 0.9800, Val L: 1.1887, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7500, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      " Fold 2 Epoch 58/125: Tr L: 0.0145, Tr Acc: 0.9933, Val L: 1.1580, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7431, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      " Fold 2 Epoch 59/125: Tr L: 0.0617, Tr Acc: 0.9733, Val L: 1.0739, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7292, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000100\n",
      " Fold 2 Epoch 60/125: Tr L: 0.0232, Tr Acc: 0.9933, Val L: 1.1152, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7431, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000100\n",
      " Fold 2 Epoch 61/125: Tr L: 0.0232, Tr Acc: 0.9933, Val L: 1.2224, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7153, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000100\n",
      " Fold 2 Epoch 62/125: Tr L: 0.0259, Tr Acc: 0.9867, Val L: 1.2225, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7292, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000100\n",
      " Fold 2 Epoch 63/125: Tr L: 0.0348, Tr Acc: 0.9733, Val L: 1.3299, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7153, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000100\n",
      " Fold 2 Epoch 64/125: Tr L: 0.0206, Tr Acc: 0.9933, Val L: 1.3253, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7083, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000100\n",
      " Fold 2 Epoch 65/125: Tr L: 0.0607, Tr Acc: 0.9867, Val L: 1.3492, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7292, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      " Fold 2 Epoch 66/125: Tr L: 0.0617, Tr Acc: 0.9800, Val L: 1.4286, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7361, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      " Fold 2 Epoch 67/125: Tr L: 0.0253, Tr Acc: 0.9867, Val L: 1.4756, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7292, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      " Fold 2 Epoch 68/125: Tr L: 0.0374, Tr Acc: 0.9867, Val L: 1.7606, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.7222, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000100\n",
      "Early stopping triggered at epoch 68 for fold 2\n",
      "--- Evaluating Fold 3 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 2: {0: 13, 1: 8}\n",
      "percentage of classes in test set: 0    0.619048\n",
      "1    0.380952\n",
      "Name: count, dtype: float64\n",
      " [FOLD 2 FINAL] Test Loss: 2.5880 | Test Acc: 0.2857 | test Balanced Acc: 0.2788 | test F1: 0.2105 | Test AUC: 0.2981 | Test MCC: -0.4301\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:17:17,409] A new study created in memory with name: no-name-3e739ee8-91da-4abb-b47a-094911098712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 4 / 8 =====\n",
      "Outer Train images: 142 | Outer Test images: 22\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 4 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 4.\n",
      "--- Starting Hyperparameter Tuning for Fold 4 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:17:41,356] Trial 0 finished with value: 0.6771182815233866 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6771182815233866.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:18:05,306] Trial 1 finished with value: 0.7539248168468475 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6771182815233866.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:18:29,483] Trial 2 finished with value: 0.6435288687547048 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6435288687547048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 4 with LR=0.000401 ---\n",
      "X_train_es: (117,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 117, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 3 Epoch 1/125: Tr L: 0.6534, Tr Acc: 0.5676, Val L: 0.8291, Val Acc: 0.3600, Val Bal Acc: 0.4514, Val Roc AUC: 0.4792, Val_mcc: -0.1273, Val F1: 0.4667 lr: 0.000401\n",
      " Fold 3 Epoch 2/125: Tr L: 0.4794, Tr Acc: 0.8311, Val L: 1.7380, Val Acc: 0.4000, Val Bal Acc: 0.5069, Val Roc AUC: 0.5000, Val_mcc: 0.0205, Val F1: 0.5161 lr: 0.000401\n",
      " Fold 3 Epoch 3/125: Tr L: 0.3335, Tr Acc: 0.8784, Val L: 2.0446, Val Acc: 0.5200, Val Bal Acc: 0.5764, Val Roc AUC: 0.5764, Val_mcc: 0.1572, Val F1: 0.5385 lr: 0.000401\n",
      " Fold 3 Epoch 4/125: Tr L: 0.2309, Tr Acc: 0.9054, Val L: 2.0354, Val Acc: 0.5600, Val Bal Acc: 0.6562, Val Roc AUC: 0.6250, Val_mcc: 0.3750, Val F1: 0.6207 lr: 0.000401\n",
      " Fold 3 Epoch 5/125: Tr L: 0.1955, Tr Acc: 0.9257, Val L: 2.6450, Val Acc: 0.5600, Val Bal Acc: 0.6562, Val Roc AUC: 0.6111, Val_mcc: 0.3750, Val F1: 0.6207 lr: 0.000401\n",
      " Fold 3 Epoch 6/125: Tr L: 0.1619, Tr Acc: 0.9189, Val L: 2.8312, Val Acc: 0.5600, Val Bal Acc: 0.6319, Val Roc AUC: 0.6319, Val_mcc: 0.2821, Val F1: 0.5926 lr: 0.000401\n",
      " Fold 3 Epoch 7/125: Tr L: 0.2236, Tr Acc: 0.9189, Val L: 1.7703, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6667, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 3 Epoch 8/125: Tr L: 0.1023, Tr Acc: 0.9595, Val L: 1.4500, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7431, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 9/125: Tr L: 0.0743, Tr Acc: 0.9797, Val L: 1.1480, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7431, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 10/125: Tr L: 0.1254, Tr Acc: 0.9459, Val L: 1.0603, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7361, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 11/125: Tr L: 0.0950, Tr Acc: 0.9527, Val L: 1.1316, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6667, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 3 Epoch 12/125: Tr L: 0.1497, Tr Acc: 0.9054, Val L: 1.4150, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6736, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 3 Epoch 13/125: Tr L: 0.0607, Tr Acc: 0.9797, Val L: 1.5828, Val Acc: 0.6800, Val Bal Acc: 0.5799, Val Roc AUC: 0.6806, Val_mcc: 0.2359, Val F1: 0.3333 lr: 0.000401\n",
      " Fold 3 Epoch 14/125: Tr L: 0.0694, Tr Acc: 0.9797, Val L: 1.1111, Val Acc: 0.7200, Val Bal Acc: 0.6597, Val Roc AUC: 0.7500, Val_mcc: 0.3590, Val F1: 0.5333 lr: 0.000401\n",
      " Fold 3 Epoch 15/125: Tr L: 0.1890, Tr Acc: 0.9189, Val L: 0.7011, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.7431, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 16/125: Tr L: 0.0817, Tr Acc: 0.9797, Val L: 1.1189, Val Acc: 0.6000, Val Bal Acc: 0.6875, Val Roc AUC: 0.7431, Val_mcc: 0.4215, Val F1: 0.6429 lr: 0.000401\n",
      " Fold 3 Epoch 17/125: Tr L: 0.1792, Tr Acc: 0.9392, Val L: 1.9063, Val Acc: 0.5200, Val Bal Acc: 0.6250, Val Roc AUC: 0.7014, Val_mcc: 0.3273, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 18/125: Tr L: 0.0666, Tr Acc: 0.9730, Val L: 2.5194, Val Acc: 0.5600, Val Bal Acc: 0.6562, Val Roc AUC: 0.7569, Val_mcc: 0.3750, Val F1: 0.6207 lr: 0.000401\n",
      " Fold 3 Epoch 19/125: Tr L: 0.0912, Tr Acc: 0.9595, Val L: 2.0905, Val Acc: 0.6800, Val Bal Acc: 0.7500, Val Roc AUC: 0.7778, Val_mcc: 0.5145, Val F1: 0.6923 lr: 0.000401\n",
      " Fold 3 Epoch 20/125: Tr L: 0.0896, Tr Acc: 0.9662, Val L: 1.7304, Val Acc: 0.7200, Val Bal Acc: 0.7812, Val Roc AUC: 0.7708, Val_mcc: 0.5625, Val F1: 0.7200 lr: 0.000401\n",
      " Fold 3 Epoch 21/125: Tr L: 0.0570, Tr Acc: 0.9865, Val L: 1.1336, Val Acc: 0.8000, Val Bal Acc: 0.8438, Val Roc AUC: 0.8125, Val_mcc: 0.6648, Val F1: 0.7826 lr: 0.000401\n",
      " Fold 3 Epoch 22/125: Tr L: 0.1001, Tr Acc: 0.9730, Val L: 1.0048, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.8194, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 23/125: Tr L: 0.0445, Tr Acc: 0.9797, Val L: 0.8923, Val Acc: 0.8000, Val Bal Acc: 0.8194, Val Roc AUC: 0.7917, Val_mcc: 0.6138, Val F1: 0.7619 lr: 0.000401\n",
      " Fold 3 Epoch 24/125: Tr L: 0.0659, Tr Acc: 0.9662, Val L: 0.7270, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.8333, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 25/125: Tr L: 0.0966, Tr Acc: 0.9595, Val L: 0.7693, Val Acc: 0.8000, Val Bal Acc: 0.7708, Val Roc AUC: 0.8264, Val_mcc: 0.5574, Val F1: 0.7059 lr: 0.000401\n",
      " Fold 3 Epoch 26/125: Tr L: 0.0525, Tr Acc: 0.9932, Val L: 1.0879, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7500, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 3 Epoch 27/125: Tr L: 0.0643, Tr Acc: 0.9662, Val L: 1.2190, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7639, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 3 Epoch 28/125: Tr L: 0.0752, Tr Acc: 0.9797, Val L: 1.0202, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.7569, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 29/125: Tr L: 0.0686, Tr Acc: 0.9527, Val L: 1.3269, Val Acc: 0.7600, Val Bal Acc: 0.7882, Val Roc AUC: 0.7778, Val_mcc: 0.5538, Val F1: 0.7273 lr: 0.000401\n",
      " Fold 3 Epoch 30/125: Tr L: 0.0267, Tr Acc: 0.9797, Val L: 1.1055, Val Acc: 0.8400, Val Bal Acc: 0.8750, Val Roc AUC: 0.8542, Val_mcc: 0.7206, Val F1: 0.8182 lr: 0.000401\n",
      " Fold 3 Epoch 31/125: Tr L: 0.0730, Tr Acc: 0.9730, Val L: 1.0280, Val Acc: 0.8800, Val Bal Acc: 0.9062, Val Roc AUC: 0.8750, Val_mcc: 0.7806, Val F1: 0.8571 lr: 0.000401\n",
      " Fold 3 Epoch 32/125: Tr L: 0.1101, Tr Acc: 0.9527, Val L: 3.4710, Val Acc: 0.6800, Val Bal Acc: 0.7500, Val Roc AUC: 0.8194, Val_mcc: 0.5145, Val F1: 0.6923 lr: 0.000401\n",
      " Fold 3 Epoch 33/125: Tr L: 0.0505, Tr Acc: 0.9662, Val L: 4.6392, Val Acc: 0.6000, Val Bal Acc: 0.6875, Val Roc AUC: 0.6736, Val_mcc: 0.4215, Val F1: 0.6429 lr: 0.000401\n",
      " Fold 3 Epoch 34/125: Tr L: 0.1664, Tr Acc: 0.9392, Val L: 4.2306, Val Acc: 0.5600, Val Bal Acc: 0.6562, Val Roc AUC: 0.6250, Val_mcc: 0.3750, Val F1: 0.6207 lr: 0.000401\n",
      " Fold 3 Epoch 35/125: Tr L: 0.1638, Tr Acc: 0.9324, Val L: 3.0711, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6944, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 3 Epoch 36/125: Tr L: 0.1192, Tr Acc: 0.9662, Val L: 1.6504, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6667, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 3 Epoch 37/125: Tr L: 0.0559, Tr Acc: 0.9865, Val L: 1.2630, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.7014, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 3 Epoch 38/125: Tr L: 0.0816, Tr Acc: 0.9730, Val L: 1.0971, Val Acc: 0.5600, Val Bal Acc: 0.4861, Val Roc AUC: 0.6667, Val_mcc: -0.0312, Val F1: 0.2667 lr: 0.000401\n",
      " Fold 3 Epoch 39/125: Tr L: 0.0495, Tr Acc: 0.9730, Val L: 0.8177, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.7431, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 3 Epoch 40/125: Tr L: 0.0737, Tr Acc: 0.9662, Val L: 0.8594, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7361, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 3 Epoch 41/125: Tr L: 0.0908, Tr Acc: 0.9527, Val L: 1.2518, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.6944, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 3 Epoch 42/125: Tr L: 0.0958, Tr Acc: 0.9595, Val L: 1.5513, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7222, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000201\n",
      " Fold 3 Epoch 43/125: Tr L: 0.0943, Tr Acc: 0.9662, Val L: 1.6126, Val Acc: 0.7200, Val Bal Acc: 0.7812, Val Roc AUC: 0.7500, Val_mcc: 0.5625, Val F1: 0.7200 lr: 0.000201\n",
      " Fold 3 Epoch 44/125: Tr L: 0.0490, Tr Acc: 0.9797, Val L: 1.5224, Val Acc: 0.7200, Val Bal Acc: 0.7812, Val Roc AUC: 0.8125, Val_mcc: 0.5625, Val F1: 0.7200 lr: 0.000201\n",
      " Fold 3 Epoch 45/125: Tr L: 0.0708, Tr Acc: 0.9730, Val L: 1.4939, Val Acc: 0.7600, Val Bal Acc: 0.8125, Val Roc AUC: 0.8333, Val_mcc: 0.6124, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 46/125: Tr L: 0.0235, Tr Acc: 0.9932, Val L: 1.4055, Val Acc: 0.7600, Val Bal Acc: 0.8125, Val Roc AUC: 0.8333, Val_mcc: 0.6124, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 47/125: Tr L: 0.0327, Tr Acc: 0.9797, Val L: 1.3184, Val Acc: 0.8000, Val Bal Acc: 0.8438, Val Roc AUC: 0.8472, Val_mcc: 0.6648, Val F1: 0.7826 lr: 0.000201\n",
      " Fold 3 Epoch 48/125: Tr L: 0.0783, Tr Acc: 0.9797, Val L: 1.3969, Val Acc: 0.7600, Val Bal Acc: 0.8125, Val Roc AUC: 0.8403, Val_mcc: 0.6124, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 49/125: Tr L: 0.0448, Tr Acc: 0.9797, Val L: 1.3901, Val Acc: 0.8400, Val Bal Acc: 0.8750, Val Roc AUC: 0.8611, Val_mcc: 0.7206, Val F1: 0.8182 lr: 0.000201\n",
      " Fold 3 Epoch 50/125: Tr L: 0.0772, Tr Acc: 0.9662, Val L: 1.4974, Val Acc: 0.8000, Val Bal Acc: 0.8438, Val Roc AUC: 0.8403, Val_mcc: 0.6648, Val F1: 0.7826 lr: 0.000201\n",
      " Fold 3 Epoch 51/125: Tr L: 0.0751, Tr Acc: 0.9527, Val L: 1.7919, Val Acc: 0.7600, Val Bal Acc: 0.8125, Val Roc AUC: 0.7917, Val_mcc: 0.6124, Val F1: 0.7500 lr: 0.000201\n",
      " Fold 3 Epoch 52/125: Tr L: 0.0329, Tr Acc: 0.9865, Val L: 2.1836, Val Acc: 0.7200, Val Bal Acc: 0.7812, Val Roc AUC: 0.7500, Val_mcc: 0.5625, Val F1: 0.7200 lr: 0.000201\n",
      " Fold 3 Epoch 53/125: Tr L: 0.0392, Tr Acc: 0.9865, Val L: 2.1081, Val Acc: 0.6800, Val Bal Acc: 0.7500, Val Roc AUC: 0.7361, Val_mcc: 0.5145, Val F1: 0.6923 lr: 0.000201\n",
      " Fold 3 Epoch 54/125: Tr L: 0.0512, Tr Acc: 0.9730, Val L: 1.9943, Val Acc: 0.6800, Val Bal Acc: 0.7500, Val Roc AUC: 0.7361, Val_mcc: 0.5145, Val F1: 0.6923 lr: 0.000201\n",
      " Fold 3 Epoch 55/125: Tr L: 0.0298, Tr Acc: 0.9932, Val L: 2.0303, Val Acc: 0.6800, Val Bal Acc: 0.7500, Val Roc AUC: 0.7292, Val_mcc: 0.5145, Val F1: 0.6923 lr: 0.000201\n",
      "Early stopping triggered at epoch 55 for fold 3\n",
      "--- Evaluating Fold 4 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 3: {0: 14, 1: 8}\n",
      "percentage of classes in test set: 0    0.636364\n",
      "1    0.363636\n",
      "Name: count, dtype: float64\n",
      " [FOLD 3 FINAL] Test Loss: 1.5026 | Test Acc: 0.6818 | test Balanced Acc: 0.7232 | test F1: 0.6667 | Test AUC: 0.7500 | Test MCC: 0.4368\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:23:29,095] A new study created in memory with name: no-name-b283784c-e587-4acd-9a86-60bd4734de72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 5 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 5 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 5.\n",
      "--- Starting Hyperparameter Tuning for Fold 5 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:23:52,800] Trial 0 finished with value: 0.6823943654696146 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6823943654696146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:24:16,606] Trial 1 finished with value: 0.7668376937508583 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6823943654696146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:24:39,956] Trial 2 finished with value: 0.6742387910683949 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6742387910683949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 5 with LR=0.000401 ---\n",
      "X_train_es: (119,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 119, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 4 Epoch 1/125: Tr L: 0.6721, Tr Acc: 0.5676, Val L: 0.7122, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.5069, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000401\n",
      " Fold 4 Epoch 2/125: Tr L: 0.5301, Tr Acc: 0.7770, Val L: 0.8864, Val Acc: 0.5600, Val Bal Acc: 0.6562, Val Roc AUC: 0.5278, Val_mcc: 0.3750, Val F1: 0.6207 lr: 0.000401\n",
      " Fold 4 Epoch 3/125: Tr L: 0.3641, Tr Acc: 0.8378, Val L: 0.9505, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6042, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 4 Epoch 4/125: Tr L: 0.2351, Tr Acc: 0.9324, Val L: 1.3250, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6181, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 4 Epoch 5/125: Tr L: 0.2095, Tr Acc: 0.9257, Val L: 1.7930, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6597, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 4 Epoch 6/125: Tr L: 0.2029, Tr Acc: 0.9257, Val L: 1.6629, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.6667, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000401\n",
      " Fold 4 Epoch 7/125: Tr L: 0.2690, Tr Acc: 0.9257, Val L: 1.1684, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 4 Epoch 8/125: Tr L: 0.1149, Tr Acc: 0.9662, Val L: 0.9310, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7708, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 4 Epoch 9/125: Tr L: 0.1209, Tr Acc: 0.9662, Val L: 0.9717, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7986, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 4 Epoch 10/125: Tr L: 0.0914, Tr Acc: 0.9595, Val L: 0.8984, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7917, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000401\n",
      " Fold 4 Epoch 11/125: Tr L: 0.1250, Tr Acc: 0.9459, Val L: 1.1601, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7500, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000401\n",
      " Fold 4 Epoch 12/125: Tr L: 0.1444, Tr Acc: 0.9459, Val L: 1.9252, Val Acc: 0.5600, Val Bal Acc: 0.6319, Val Roc AUC: 0.6736, Val_mcc: 0.2821, Val F1: 0.5926 lr: 0.000401\n",
      " Fold 4 Epoch 13/125: Tr L: 0.0447, Tr Acc: 0.9797, Val L: 1.9755, Val Acc: 0.5600, Val Bal Acc: 0.6319, Val Roc AUC: 0.5903, Val_mcc: 0.2821, Val F1: 0.5926 lr: 0.000401\n",
      " Fold 4 Epoch 14/125: Tr L: 0.1062, Tr Acc: 0.9257, Val L: 1.9136, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.5972, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 4 Epoch 15/125: Tr L: 0.1214, Tr Acc: 0.9459, Val L: 2.1783, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.5903, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 4 Epoch 16/125: Tr L: 0.1217, Tr Acc: 0.9459, Val L: 2.1492, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6319, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 4 Epoch 17/125: Tr L: 0.0999, Tr Acc: 0.9459, Val L: 1.6145, Val Acc: 0.6400, Val Bal Acc: 0.7188, Val Roc AUC: 0.7361, Val_mcc: 0.4677, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 4 Epoch 18/125: Tr L: 0.1099, Tr Acc: 0.9662, Val L: 0.9993, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7431, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000401\n",
      " Fold 4 Epoch 19/125: Tr L: 0.0669, Tr Acc: 0.9797, Val L: 0.7624, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7708, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 4 Epoch 20/125: Tr L: 0.3522, Tr Acc: 0.9189, Val L: 0.8479, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7569, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 4 Epoch 21/125: Tr L: 0.0625, Tr Acc: 0.9730, Val L: 1.5332, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7014, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000401\n",
      " Fold 4 Epoch 22/125: Tr L: 0.1414, Tr Acc: 0.9730, Val L: 2.4502, Val Acc: 0.6000, Val Bal Acc: 0.6875, Val Roc AUC: 0.7292, Val_mcc: 0.4215, Val F1: 0.6429 lr: 0.000401\n",
      " Fold 4 Epoch 23/125: Tr L: 0.0693, Tr Acc: 0.9595, Val L: 2.4140, Val Acc: 0.6000, Val Bal Acc: 0.6875, Val Roc AUC: 0.7569, Val_mcc: 0.4215, Val F1: 0.6429 lr: 0.000401\n",
      " Fold 4 Epoch 24/125: Tr L: 0.1352, Tr Acc: 0.9595, Val L: 2.6202, Val Acc: 0.6000, Val Bal Acc: 0.6875, Val Roc AUC: 0.7431, Val_mcc: 0.4215, Val F1: 0.6429 lr: 0.000401\n",
      " Fold 4 Epoch 25/125: Tr L: 0.0965, Tr Acc: 0.9662, Val L: 2.9851, Val Acc: 0.5200, Val Bal Acc: 0.6007, Val Roc AUC: 0.7049, Val_mcc: 0.2263, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 4 Epoch 26/125: Tr L: 0.0727, Tr Acc: 0.9730, Val L: 2.3854, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.6944, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000401\n",
      " Fold 4 Epoch 27/125: Tr L: 0.0817, Tr Acc: 0.9527, Val L: 2.0954, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7083, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 4 Epoch 28/125: Tr L: 0.0757, Tr Acc: 0.9865, Val L: 1.7063, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7222, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000201\n",
      " Fold 4 Epoch 29/125: Tr L: 0.2060, Tr Acc: 0.9595, Val L: 1.4261, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7639, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000201\n",
      " Fold 4 Epoch 30/125: Tr L: 0.0662, Tr Acc: 0.9730, Val L: 1.3837, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7847, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000201\n",
      " Fold 4 Epoch 31/125: Tr L: 0.0511, Tr Acc: 0.9797, Val L: 1.3456, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.8056, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 4 Epoch 32/125: Tr L: 0.0615, Tr Acc: 0.9595, Val L: 1.1921, Val Acc: 0.7200, Val Bal Acc: 0.7569, Val Roc AUC: 0.7917, Val_mcc: 0.4969, Val F1: 0.6957 lr: 0.000201\n",
      " Fold 4 Epoch 33/125: Tr L: 0.0622, Tr Acc: 0.9662, Val L: 1.1598, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.7847, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 4 Epoch 34/125: Tr L: 0.0749, Tr Acc: 0.9730, Val L: 1.3219, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7708, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000201\n",
      " Fold 4 Epoch 35/125: Tr L: 0.0390, Tr Acc: 0.9865, Val L: 1.4343, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7431, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000201\n",
      " Fold 4 Epoch 36/125: Tr L: 0.1101, Tr Acc: 0.9730, Val L: 1.2993, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7639, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000201\n",
      " Fold 4 Epoch 37/125: Tr L: 0.0960, Tr Acc: 0.9730, Val L: 1.2306, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7500, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000201\n",
      " Fold 4 Epoch 38/125: Tr L: 0.0425, Tr Acc: 0.9865, Val L: 1.2068, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7708, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000201\n",
      " Fold 4 Epoch 39/125: Tr L: 0.0299, Tr Acc: 0.9797, Val L: 1.1521, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.7639, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000201\n",
      " Fold 4 Epoch 40/125: Tr L: 0.0442, Tr Acc: 0.9730, Val L: 1.2429, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.7639, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000201\n",
      " Fold 4 Epoch 41/125: Tr L: 0.0544, Tr Acc: 0.9797, Val L: 1.4698, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7361, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000201\n",
      "Early stopping triggered at epoch 41 for fold 4\n",
      "--- Evaluating Fold 5 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 4: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 4 FINAL] Test Loss: 0.5857 | Test Acc: 0.8000 | test Balanced Acc: 0.7619 | test F1: 0.6667 | Test AUC: 0.9167 | Test MCC: 0.5238\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:28:24,159] A new study created in memory with name: no-name-cde06690-c1af-482d-b701-bbdc6035d5e4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 6 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 6 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 6.\n",
      "--- Starting Hyperparameter Tuning for Fold 6 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:28:47,632] Trial 0 finished with value: 0.6779592633247375 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6779592633247375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:29:11,811] Trial 1 finished with value: 0.8201061934232712 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6779592633247375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:29:35,483] Trial 2 finished with value: 0.6767223676045735 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6767223676045735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 6 with LR=0.000401 ---\n",
      "X_train_es: (119,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 119, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 5 Epoch 1/125: Tr L: 0.6655, Tr Acc: 0.6486, Val L: 0.6952, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.5069, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000401\n",
      " Fold 5 Epoch 2/125: Tr L: 0.5229, Tr Acc: 0.7973, Val L: 0.8470, Val Acc: 0.5600, Val Bal Acc: 0.6076, Val Roc AUC: 0.5972, Val_mcc: 0.2153, Val F1: 0.5600 lr: 0.000401\n",
      " Fold 5 Epoch 3/125: Tr L: 0.3131, Tr Acc: 0.8986, Val L: 0.8161, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.6528, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 5 Epoch 4/125: Tr L: 0.2533, Tr Acc: 0.8649, Val L: 1.0627, Val Acc: 0.5200, Val Bal Acc: 0.5035, Val Roc AUC: 0.5833, Val_mcc: 0.0067, Val F1: 0.4000 lr: 0.000401\n",
      " Fold 5 Epoch 5/125: Tr L: 0.1609, Tr Acc: 0.9324, Val L: 1.5955, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.5764, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000401\n",
      " Fold 5 Epoch 6/125: Tr L: 0.1500, Tr Acc: 0.9392, Val L: 2.1697, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.5139, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000401\n",
      " Fold 5 Epoch 7/125: Tr L: 0.1927, Tr Acc: 0.9324, Val L: 2.6247, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.5417, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000401\n",
      " Fold 5 Epoch 8/125: Tr L: 0.1561, Tr Acc: 0.9527, Val L: 2.3521, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.5486, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 5 Epoch 9/125: Tr L: 0.0851, Tr Acc: 0.9797, Val L: 1.8530, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.5833, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000401\n",
      " Fold 5 Epoch 10/125: Tr L: 0.0775, Tr Acc: 0.9459, Val L: 2.1281, Val Acc: 0.4800, Val Bal Acc: 0.4965, Val Roc AUC: 0.5139, Val_mcc: -0.0067, Val F1: 0.4348 lr: 0.000401\n",
      " Fold 5 Epoch 11/125: Tr L: 0.0988, Tr Acc: 0.9595, Val L: 2.6788, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.4722, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000401\n",
      " Fold 5 Epoch 12/125: Tr L: 0.1756, Tr Acc: 0.9527, Val L: 2.4012, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.5139, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000401\n",
      " Fold 5 Epoch 13/125: Tr L: 0.0475, Tr Acc: 0.9797, Val L: 1.8984, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.5833, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 14/125: Tr L: 0.1899, Tr Acc: 0.9392, Val L: 2.0238, Val Acc: 0.7600, Val Bal Acc: 0.6910, Val Roc AUC: 0.6458, Val_mcc: 0.4583, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 5 Epoch 15/125: Tr L: 0.1560, Tr Acc: 0.9527, Val L: 2.6461, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.5833, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 5 Epoch 16/125: Tr L: 0.0698, Tr Acc: 0.9730, Val L: 2.7018, Val Acc: 0.4000, Val Bal Acc: 0.4340, Val Roc AUC: 0.5625, Val_mcc: -0.1319, Val F1: 0.4000 lr: 0.000401\n",
      " Fold 5 Epoch 17/125: Tr L: 0.0887, Tr Acc: 0.9730, Val L: 1.7959, Val Acc: 0.5200, Val Bal Acc: 0.5521, Val Roc AUC: 0.6042, Val_mcc: 0.1021, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 18/125: Tr L: 0.0687, Tr Acc: 0.9730, Val L: 1.2842, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6319, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 19/125: Tr L: 0.1205, Tr Acc: 0.9527, Val L: 1.1576, Val Acc: 0.6800, Val Bal Acc: 0.6285, Val Roc AUC: 0.6389, Val_mcc: 0.2747, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 20/125: Tr L: 0.0915, Tr Acc: 0.9662, Val L: 0.8822, Val Acc: 0.5600, Val Bal Acc: 0.5347, Val Roc AUC: 0.7083, Val_mcc: 0.0680, Val F1: 0.4211 lr: 0.000401\n",
      " Fold 5 Epoch 21/125: Tr L: 0.0635, Tr Acc: 0.9797, Val L: 1.0417, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6806, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 5 Epoch 22/125: Tr L: 0.0555, Tr Acc: 0.9932, Val L: 1.2597, Val Acc: 0.4400, Val Bal Acc: 0.4653, Val Roc AUC: 0.6181, Val_mcc: -0.0680, Val F1: 0.4167 lr: 0.000401\n",
      " Fold 5 Epoch 23/125: Tr L: 0.1077, Tr Acc: 0.9730, Val L: 1.1721, Val Acc: 0.6000, Val Bal Acc: 0.5903, Val Roc AUC: 0.6389, Val_mcc: 0.1746, Val F1: 0.5000 lr: 0.000401\n",
      " Fold 5 Epoch 24/125: Tr L: 0.0783, Tr Acc: 0.9662, Val L: 1.3171, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6806, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 5 Epoch 25/125: Tr L: 0.1134, Tr Acc: 0.9595, Val L: 1.2804, Val Acc: 0.6800, Val Bal Acc: 0.6528, Val Roc AUC: 0.6944, Val_mcc: 0.3056, Val F1: 0.5556 lr: 0.000401\n",
      " Fold 5 Epoch 26/125: Tr L: 0.1608, Tr Acc: 0.9595, Val L: 1.7302, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6528, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000401\n",
      " Fold 5 Epoch 27/125: Tr L: 0.0799, Tr Acc: 0.9662, Val L: 2.0637, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.6319, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000401\n",
      " Fold 5 Epoch 28/125: Tr L: 0.0952, Tr Acc: 0.9392, Val L: 2.0494, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6528, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000201\n",
      " Fold 5 Epoch 29/125: Tr L: 0.0738, Tr Acc: 0.9595, Val L: 2.0734, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.6528, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000201\n",
      " Fold 5 Epoch 30/125: Tr L: 0.1007, Tr Acc: 0.9865, Val L: 2.1082, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6181, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000201\n",
      " Fold 5 Epoch 31/125: Tr L: 0.0533, Tr Acc: 0.9797, Val L: 1.9877, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5903, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 32/125: Tr L: 0.0474, Tr Acc: 0.9662, Val L: 1.9120, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5833, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 33/125: Tr L: 0.0422, Tr Acc: 0.9797, Val L: 2.0184, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.5764, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 34/125: Tr L: 0.0420, Tr Acc: 0.9662, Val L: 2.2950, Val Acc: 0.5200, Val Bal Acc: 0.5278, Val Roc AUC: 0.5833, Val_mcc: 0.0534, Val F1: 0.4545 lr: 0.000201\n",
      " Fold 5 Epoch 35/125: Tr L: 0.0381, Tr Acc: 0.9730, Val L: 2.3805, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6042, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000201\n",
      " Fold 5 Epoch 36/125: Tr L: 0.0802, Tr Acc: 0.9662, Val L: 2.1583, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6111, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 37/125: Tr L: 0.0382, Tr Acc: 0.9797, Val L: 2.0744, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6042, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 38/125: Tr L: 0.0769, Tr Acc: 0.9662, Val L: 2.1179, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6319, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 39/125: Tr L: 0.0556, Tr Acc: 0.9730, Val L: 2.2615, Val Acc: 0.6400, Val Bal Acc: 0.6215, Val Roc AUC: 0.6389, Val_mcc: 0.2381, Val F1: 0.5263 lr: 0.000201\n",
      " Fold 5 Epoch 40/125: Tr L: 0.0351, Tr Acc: 0.9797, Val L: 2.3095, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6389, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000201\n",
      " Fold 5 Epoch 41/125: Tr L: 0.0436, Tr Acc: 0.9932, Val L: 2.2055, Val Acc: 0.5600, Val Bal Acc: 0.5590, Val Roc AUC: 0.6458, Val_mcc: 0.1134, Val F1: 0.4762 lr: 0.000201\n",
      "Early stopping triggered at epoch 41 for fold 5\n",
      "--- Evaluating Fold 6 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 5: {0: 14, 1: 6}\n",
      "percentage of classes in test set: 0    0.7\n",
      "1    0.3\n",
      "Name: count, dtype: float64\n",
      " [FOLD 5 FINAL] Test Loss: 0.6458 | Test Acc: 0.5500 | test Balanced Acc: 0.5833 | test F1: 0.4706 | Test AUC: 0.7381 | Test MCC: 0.1535\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:33:19,229] A new study created in memory with name: no-name-ab2e99be-a010-4f7a-b6b8-445fcf107e77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 7 / 8 =====\n",
      "Outer Train images: 146 | Outer Test images: 18\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 7 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 7.\n",
      "--- Starting Hyperparameter Tuning for Fold 7 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:33:44,833] Trial 0 finished with value: 0.6801469922065735 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6801469922065735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:34:10,518] Trial 1 finished with value: 1.4976999691377084 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6801469922065735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:34:35,940] Trial 2 finished with value: 0.6882003744443258 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6801469922065735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000047\n",
      "--- Starting Final Model Training for Fold 7 with LR=0.000047 ---\n",
      "X_train_es: (121,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 121, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 6 Epoch 1/125: Tr L: 0.6880, Tr Acc: 0.5449, Val L: 0.6948, Val Acc: 0.4800, Val Bal Acc: 0.5451, Val Roc AUC: 0.6319, Val_mcc: 0.0965, Val F1: 0.5185 lr: 0.000047\n",
      " Fold 6 Epoch 2/125: Tr L: 0.6612, Tr Acc: 0.6987, Val L: 0.6861, Val Acc: 0.4800, Val Bal Acc: 0.5208, Val Roc AUC: 0.6042, Val_mcc: 0.0417, Val F1: 0.4800 lr: 0.000047\n",
      " Fold 6 Epoch 3/125: Tr L: 0.6327, Tr Acc: 0.7564, Val L: 0.6677, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.6875, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000047\n",
      " Fold 6 Epoch 4/125: Tr L: 0.6023, Tr Acc: 0.7628, Val L: 0.6480, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.7292, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 6 Epoch 5/125: Tr L: 0.5729, Tr Acc: 0.8013, Val L: 0.6277, Val Acc: 0.6000, Val Bal Acc: 0.6389, Val Roc AUC: 0.7431, Val_mcc: 0.2722, Val F1: 0.5833 lr: 0.000047\n",
      " Fold 6 Epoch 6/125: Tr L: 0.5323, Tr Acc: 0.9231, Val L: 0.6164, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7361, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 7/125: Tr L: 0.5115, Tr Acc: 0.8782, Val L: 0.6080, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7708, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 8/125: Tr L: 0.4571, Tr Acc: 0.8782, Val L: 0.5847, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7708, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 9/125: Tr L: 0.4515, Tr Acc: 0.8782, Val L: 0.5740, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7569, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 10/125: Tr L: 0.3883, Tr Acc: 0.9167, Val L: 0.5616, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7569, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 11/125: Tr L: 0.3797, Tr Acc: 0.9231, Val L: 0.5552, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7708, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 12/125: Tr L: 0.3499, Tr Acc: 0.8846, Val L: 0.5541, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7778, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 13/125: Tr L: 0.2895, Tr Acc: 0.9038, Val L: 0.5629, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7639, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 14/125: Tr L: 0.2736, Tr Acc: 0.9423, Val L: 0.5499, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7569, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 15/125: Tr L: 0.2849, Tr Acc: 0.8846, Val L: 0.5498, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7639, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 16/125: Tr L: 0.2045, Tr Acc: 0.9487, Val L: 0.5412, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7778, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 17/125: Tr L: 0.2249, Tr Acc: 0.9038, Val L: 0.5573, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7569, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 18/125: Tr L: 0.2020, Tr Acc: 0.9359, Val L: 0.5584, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7639, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 19/125: Tr L: 0.1964, Tr Acc: 0.9423, Val L: 0.5880, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7847, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 20/125: Tr L: 0.1683, Tr Acc: 0.9423, Val L: 0.5987, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7639, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 21/125: Tr L: 0.1421, Tr Acc: 0.9551, Val L: 0.5803, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7569, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 22/125: Tr L: 0.1686, Tr Acc: 0.9167, Val L: 0.5932, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7847, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 23/125: Tr L: 0.1828, Tr Acc: 0.9359, Val L: 0.6023, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7847, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 24/125: Tr L: 0.1350, Tr Acc: 0.9487, Val L: 0.5845, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7847, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 25/125: Tr L: 0.1212, Tr Acc: 0.9551, Val L: 0.6171, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7917, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 26/125: Tr L: 0.1256, Tr Acc: 0.9679, Val L: 0.5859, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.8056, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 27/125: Tr L: 0.1125, Tr Acc: 0.9615, Val L: 0.6009, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.8056, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 28/125: Tr L: 0.1007, Tr Acc: 0.9744, Val L: 0.5980, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7917, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 6 Epoch 29/125: Tr L: 0.0774, Tr Acc: 0.9615, Val L: 0.6227, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7917, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000047\n",
      " Fold 6 Epoch 30/125: Tr L: 0.0866, Tr Acc: 0.9808, Val L: 0.6414, Val Acc: 0.6800, Val Bal Acc: 0.6771, Val Roc AUC: 0.7847, Val_mcc: 0.3425, Val F1: 0.6000 lr: 0.000047\n",
      " Fold 6 Epoch 31/125: Tr L: 0.0921, Tr Acc: 0.9551, Val L: 0.6123, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7708, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 32/125: Tr L: 0.0665, Tr Acc: 0.9936, Val L: 0.6302, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7708, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 33/125: Tr L: 0.0777, Tr Acc: 0.9744, Val L: 0.6116, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7708, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 34/125: Tr L: 0.1158, Tr Acc: 0.9551, Val L: 0.5823, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7778, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 35/125: Tr L: 0.0558, Tr Acc: 0.9936, Val L: 0.5577, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7986, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000047\n",
      " Fold 6 Epoch 36/125: Tr L: 0.0817, Tr Acc: 0.9744, Val L: 0.5807, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7917, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 37/125: Tr L: 0.0671, Tr Acc: 0.9744, Val L: 0.5682, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7917, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 38/125: Tr L: 0.0486, Tr Acc: 0.9808, Val L: 0.5523, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7986, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000047\n",
      " Fold 6 Epoch 39/125: Tr L: 0.0865, Tr Acc: 0.9551, Val L: 0.5910, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.8056, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 40/125: Tr L: 0.0639, Tr Acc: 0.9679, Val L: 0.6198, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7917, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000047\n",
      " Fold 6 Epoch 41/125: Tr L: 0.0745, Tr Acc: 0.9679, Val L: 0.5818, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.8056, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000047\n",
      " Fold 6 Epoch 42/125: Tr L: 0.0601, Tr Acc: 0.9679, Val L: 0.6277, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.7986, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000047\n",
      " Fold 6 Epoch 43/125: Tr L: 0.0563, Tr Acc: 0.9679, Val L: 0.6301, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.8056, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000024\n",
      " Fold 6 Epoch 44/125: Tr L: 0.0520, Tr Acc: 0.9744, Val L: 0.6308, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.8056, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000024\n",
      " Fold 6 Epoch 45/125: Tr L: 0.0486, Tr Acc: 0.9744, Val L: 0.6351, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7917, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 6 Epoch 46/125: Tr L: 0.0506, Tr Acc: 0.9808, Val L: 0.6733, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7917, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      " Fold 6 Epoch 47/125: Tr L: 0.0520, Tr Acc: 0.9808, Val L: 0.6848, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7847, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 48/125: Tr L: 0.0677, Tr Acc: 0.9872, Val L: 0.6866, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7986, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 49/125: Tr L: 0.0884, Tr Acc: 0.9872, Val L: 0.6877, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7708, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 50/125: Tr L: 0.0500, Tr Acc: 0.9744, Val L: 0.7140, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.7778, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000024\n",
      " Fold 6 Epoch 51/125: Tr L: 0.0349, Tr Acc: 0.9872, Val L: 0.7024, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7847, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 52/125: Tr L: 0.1012, Tr Acc: 0.9744, Val L: 0.6480, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.8264, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 53/125: Tr L: 0.0833, Tr Acc: 0.9615, Val L: 0.6073, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.8264, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 54/125: Tr L: 0.0853, Tr Acc: 0.9808, Val L: 0.5982, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.8264, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 55/125: Tr L: 0.0707, Tr Acc: 0.9744, Val L: 0.6616, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.8125, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000024\n",
      " Fold 6 Epoch 56/125: Tr L: 0.0315, Tr Acc: 1.0000, Val L: 0.6575, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.8125, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000024\n",
      "Early stopping triggered at epoch 56 for fold 6\n",
      "--- Evaluating Fold 7 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 6: {0: 10, 1: 8}\n",
      "percentage of classes in test set: 0    0.555556\n",
      "1    0.444444\n",
      "Name: count, dtype: float64\n",
      " [FOLD 6 FINAL] Test Loss: 1.1864 | Test Acc: 0.4444 | test Balanced Acc: 0.4375 | test F1: 0.3750 | Test AUC: 0.3750 | Test MCC: -0.1250\n",
      "model class name: ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:40:05,106] A new study created in memory with name: no-name-53aeaac2-5bfb-45a6-9d84-ec64ca80246b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OUTER FOLD 8 / 8 =====\n",
      "Outer Train images: 144 | Outer Test images: 20\n",
      "Using pretrained model; ImageNet normalization will be applied by torchvision transforms.\n",
      "--- Generating data transforms for Fold 8 ---\n",
      "Using pretrained model: True\n",
      "Using pretrained model: True and supported by torchvision: <function is_supported_by_torchvision at 0x71124da41da0> with color transforms: False\n",
      "the model is supported by torchvision and is pretrained\n",
      "Using Imagenet/micronet pretrained model--> using torchvision transforms\n",
      "Accepts ``PIL.Image``, batched ``(B, C, H, W)`` and single ``(C, H, W)`` image ``torch.Tensor`` objects. The images are resized to ``resize_size=[232]`` using ``interpolation=InterpolationMode.BILINEAR``, followed by a central crop of ``crop_size=[224]``. Finally the values are first rescaled to ``[0.0, 1.0]`` and then normalized using ``mean=[0.485, 0.456, 0.406]`` and ``std=[0.229, 0.224, 0.225]``.\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Using pretrained model: True and supported by torchvision: True hence the resizing and scaling is handled by torchvision.Weights.Transforms\n",
      "Transforms generated for Fold 8.\n",
      "--- Starting Hyperparameter Tuning for Fold 8 ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:40:29,465] Trial 0 finished with value: 0.6773056189219158 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6773056189219158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:40:54,016] Trial 1 finished with value: 0.7478355864683788 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6773056189219158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 18:41:18,127] Trial 2 finished with value: 0.6491601467132568 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6491601467132568.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best LR from inner CV = 0.000401\n",
      "--- Starting Final Model Training for Fold 8 with LR=0.000401 ---\n",
      "X_train_es: (119,) | X_val_es: (25,)\n",
      "Early stopping split: Train images: 119, Validation images: 25\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "===========================\n",
      "Model Architecture:\n",
      "==================\n",
      "Total parameters: 23,512,130\n",
      "Trainable parameters: 19,175,170\n",
      "Non-trainable parameters: 4,336,960\n",
      "===========================\n",
      " Fold 7 Epoch 1/125: Tr L: 0.6691, Tr Acc: 0.5855, Val L: 0.6943, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.6458, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 7 Epoch 2/125: Tr L: 0.5481, Tr Acc: 0.7566, Val L: 0.6553, Val Acc: 0.6400, Val Bal Acc: 0.6701, Val Roc AUC: 0.6736, Val_mcc: 0.3290, Val F1: 0.6087 lr: 0.000401\n",
      " Fold 7 Epoch 3/125: Tr L: 0.3381, Tr Acc: 0.9013, Val L: 1.0363, Val Acc: 0.6000, Val Bal Acc: 0.6875, Val Roc AUC: 0.7569, Val_mcc: 0.4215, Val F1: 0.6429 lr: 0.000401\n",
      " Fold 7 Epoch 4/125: Tr L: 0.2180, Tr Acc: 0.9408, Val L: 1.6263, Val Acc: 0.6400, Val Bal Acc: 0.7188, Val Roc AUC: 0.7153, Val_mcc: 0.4677, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 5/125: Tr L: 0.2197, Tr Acc: 0.8947, Val L: 2.0622, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.6875, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 7 Epoch 6/125: Tr L: 0.1520, Tr Acc: 0.9474, Val L: 1.6565, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.7083, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 7 Epoch 7/125: Tr L: 0.0912, Tr Acc: 0.9671, Val L: 1.9084, Val Acc: 0.6000, Val Bal Acc: 0.6632, Val Roc AUC: 0.7986, Val_mcc: 0.3359, Val F1: 0.6154 lr: 0.000401\n",
      " Fold 7 Epoch 8/125: Tr L: 0.1654, Tr Acc: 0.9474, Val L: 2.0703, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.8056, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 7 Epoch 9/125: Tr L: 0.0735, Tr Acc: 0.9605, Val L: 2.3042, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.7917, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 10/125: Tr L: 0.0722, Tr Acc: 0.9737, Val L: 2.0000, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.8056, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 11/125: Tr L: 0.0792, Tr Acc: 0.9605, Val L: 1.2827, Val Acc: 0.6400, Val Bal Acc: 0.6944, Val Roc AUC: 0.8056, Val_mcc: 0.3889, Val F1: 0.6400 lr: 0.000401\n",
      " Fold 7 Epoch 12/125: Tr L: 0.1554, Tr Acc: 0.9408, Val L: 1.1374, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7500, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 7 Epoch 13/125: Tr L: 0.0818, Tr Acc: 0.9671, Val L: 1.2548, Val Acc: 0.7600, Val Bal Acc: 0.7153, Val Roc AUC: 0.7778, Val_mcc: 0.4603, Val F1: 0.6250 lr: 0.000401\n",
      " Fold 7 Epoch 14/125: Tr L: 0.1138, Tr Acc: 0.9276, Val L: 1.2826, Val Acc: 0.7200, Val Bal Acc: 0.6840, Val Roc AUC: 0.7708, Val_mcc: 0.3787, Val F1: 0.5882 lr: 0.000401\n",
      " Fold 7 Epoch 15/125: Tr L: 0.1409, Tr Acc: 0.9474, Val L: 1.1671, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7847, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000401\n",
      " Fold 7 Epoch 16/125: Tr L: 0.1088, Tr Acc: 0.9474, Val L: 1.0721, Val Acc: 0.6800, Val Bal Acc: 0.7014, Val Roc AUC: 0.7500, Val_mcc: 0.3870, Val F1: 0.6364 lr: 0.000401\n",
      " Fold 7 Epoch 17/125: Tr L: 0.0913, Tr Acc: 0.9474, Val L: 1.2601, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7083, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 7 Epoch 18/125: Tr L: 0.0814, Tr Acc: 0.9605, Val L: 1.4365, Val Acc: 0.6000, Val Bal Acc: 0.5660, Val Roc AUC: 0.6875, Val_mcc: 0.1319, Val F1: 0.4444 lr: 0.000401\n",
      " Fold 7 Epoch 19/125: Tr L: 0.0599, Tr Acc: 0.9737, Val L: 1.5093, Val Acc: 0.6400, Val Bal Acc: 0.5972, Val Roc AUC: 0.7014, Val_mcc: 0.2001, Val F1: 0.4706 lr: 0.000401\n",
      " Fold 7 Epoch 20/125: Tr L: 0.0791, Tr Acc: 0.9605, Val L: 1.4520, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.7569, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000401\n",
      " Fold 7 Epoch 21/125: Tr L: 0.0948, Tr Acc: 0.9671, Val L: 1.2473, Val Acc: 0.6400, Val Bal Acc: 0.6458, Val Roc AUC: 0.7569, Val_mcc: 0.2802, Val F1: 0.5714 lr: 0.000401\n",
      " Fold 7 Epoch 22/125: Tr L: 0.0517, Tr Acc: 0.9803, Val L: 1.2957, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.8194, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000401\n",
      " Fold 7 Epoch 23/125: Tr L: 0.1074, Tr Acc: 0.9539, Val L: 1.4351, Val Acc: 0.5600, Val Bal Acc: 0.5833, Val Roc AUC: 0.7986, Val_mcc: 0.1612, Val F1: 0.5217 lr: 0.000401\n",
      " Fold 7 Epoch 24/125: Tr L: 0.1331, Tr Acc: 0.9671, Val L: 1.0668, Val Acc: 0.6000, Val Bal Acc: 0.6146, Val Roc AUC: 0.7986, Val_mcc: 0.2202, Val F1: 0.5455 lr: 0.000401\n",
      " Fold 7 Epoch 25/125: Tr L: 0.1265, Tr Acc: 0.9342, Val L: 1.0821, Val Acc: 0.6800, Val Bal Acc: 0.7257, Val Roc AUC: 0.8194, Val_mcc: 0.4423, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 26/125: Tr L: 0.0577, Tr Acc: 0.9803, Val L: 1.0776, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.8472, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 27/125: Tr L: 0.1017, Tr Acc: 0.9539, Val L: 1.2014, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.8472, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 28/125: Tr L: 0.0747, Tr Acc: 0.9737, Val L: 1.0106, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.8333, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000401\n",
      " Fold 7 Epoch 29/125: Tr L: 0.0520, Tr Acc: 0.9868, Val L: 0.7923, Val Acc: 0.7200, Val Bal Acc: 0.7326, Val Roc AUC: 0.8264, Val_mcc: 0.4470, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 30/125: Tr L: 0.0661, Tr Acc: 0.9605, Val L: 0.6728, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8194, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 31/125: Tr L: 0.0971, Tr Acc: 0.9868, Val L: 0.7865, Val Acc: 0.7600, Val Bal Acc: 0.7396, Val Roc AUC: 0.8403, Val_mcc: 0.4792, Val F1: 0.6667 lr: 0.000201\n",
      " Fold 7 Epoch 32/125: Tr L: 0.0638, Tr Acc: 0.9605, Val L: 0.8201, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8333, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 33/125: Tr L: 0.0872, Tr Acc: 0.9868, Val L: 0.8620, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8542, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 34/125: Tr L: 0.0551, Tr Acc: 0.9868, Val L: 0.9463, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8750, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 35/125: Tr L: 0.0592, Tr Acc: 0.9737, Val L: 1.0379, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8681, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 36/125: Tr L: 0.0543, Tr Acc: 0.9737, Val L: 1.0737, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8472, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 37/125: Tr L: 0.0229, Tr Acc: 0.9934, Val L: 0.9901, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8333, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 38/125: Tr L: 0.0511, Tr Acc: 0.9671, Val L: 0.9546, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8264, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      " Fold 7 Epoch 39/125: Tr L: 0.0339, Tr Acc: 0.9868, Val L: 0.9661, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7986, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 7 Epoch 40/125: Tr L: 0.0496, Tr Acc: 0.9671, Val L: 0.9650, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7986, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 7 Epoch 41/125: Tr L: 0.0509, Tr Acc: 0.9737, Val L: 0.9983, Val Acc: 0.7200, Val Bal Acc: 0.7083, Val Roc AUC: 0.7986, Val_mcc: 0.4082, Val F1: 0.6316 lr: 0.000201\n",
      " Fold 7 Epoch 42/125: Tr L: 0.0437, Tr Acc: 0.9868, Val L: 0.9387, Val Acc: 0.7600, Val Bal Acc: 0.7639, Val Roc AUC: 0.8264, Val_mcc: 0.5104, Val F1: 0.7000 lr: 0.000201\n",
      "Early stopping triggered at epoch 42 for fold 7\n",
      "--- Evaluating Fold 8 on Outer Test Set ---\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Test set class counts for fold 7: {0: 12, 1: 8}\n",
      "percentage of classes in test set: 0    0.6\n",
      "1    0.4\n",
      "Name: count, dtype: float64\n",
      " [FOLD 7 FINAL] Test Loss: 0.6422 | Test Acc: 0.5500 | test Balanced Acc: 0.5625 | test F1: 0.5263 | Test AUC: 0.6458 | Test MCC: 0.1231\n",
      "model class name: ResNet\n",
      "\n",
      "-------------------------------------------------\n",
      "Cross-validation results (outer folds):\n",
      "  Fold 0: Test Loss=0.3610, Acc=0.8571, F1=0.8235, Bal Acc=0.8606, AUC=0.9423, MCC=0.7077 (Best LR=0.000401)\n",
      "  Fold 1: Test Loss=0.8902, Acc=0.7727, F1=0.7368, Bal Acc=0.7946, AUC=0.8750, MCC=0.5669 (Best LR=0.000401)\n",
      "  Fold 2: Test Loss=2.5880, Acc=0.2857, F1=0.2105, Bal Acc=0.2788, AUC=0.2981, MCC=-0.4301 (Best LR=0.000401)\n",
      "  Fold 3: Test Loss=1.5026, Acc=0.6818, F1=0.6667, Bal Acc=0.7232, AUC=0.7500, MCC=0.4368 (Best LR=0.000401)\n",
      "  Fold 4: Test Loss=0.5857, Acc=0.8000, F1=0.6667, Bal Acc=0.7619, AUC=0.9167, MCC=0.5238 (Best LR=0.000401)\n",
      "  Fold 5: Test Loss=0.6458, Acc=0.5500, F1=0.4706, Bal Acc=0.5833, AUC=0.7381, MCC=0.1535 (Best LR=0.000401)\n",
      "  Fold 6: Test Loss=1.1864, Acc=0.4444, F1=0.3750, Bal Acc=0.4375, AUC=0.3750, MCC=-0.1250 (Best LR=0.000047)\n",
      "  Fold 7: Test Loss=0.6422, Acc=0.5500, F1=0.5263, Bal Acc=0.5625, AUC=0.6458, MCC=0.1231 (Best LR=0.000401)\n",
      "\n",
      "--- Aggregate Results ---\n",
      "Avg Test Accuracy: 0.6177 +/- 0.1831\n",
      "Avg Test F1-Score: 0.5595 +/- 0.1901\n",
      "Avg Test Balanced Acc: 0.6253 +/- 0.1848\n",
      "Avg Test Precision: 0.4993 +/- 0.1812\n",
      "Avg Test Recall: 0.6510 +/- 0.2204\n",
      "Avg Test MCC: 0.2446 +/- 0.3620\n",
      "-------------------------------------------------\n",
      "Using Torchvision for model instantiation.\n",
      "pretrained_weights? imagenet pretrained? True\n",
      "Building torchvision ResNet50...\n",
      "Freezing layers up to index: 94\n",
      "Run name: Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/16 18:45:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmphdsnevh7/model/data, flavor: pytorch). Fall back to return ['torch==2.6.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/07/16 18:45:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, shape: torch.Size([25, 3, 224, 224])\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_0.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_1.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_2.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_3.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_4.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_5.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_6.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_7.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_8.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_9.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_10.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_11.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_12.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_13.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_14.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_15.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_16.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_17.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_18.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_19.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_20.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_21.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_22.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_23.png\n",
      "Saved GRADCAMPP overlay with DAPI-like channel to: /home/zano/Documents/TESI/FOLDER_CINECA/tmp_gradcam/gradcampp_outputs/Resnet50_oversamp_TL_pretrained:imagenet_freeze:94_torchvision_color_transforms:False_07-16_at:18-45-14/batch_0_img_24.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils.transformations_functions as tf\n",
    "from configs.ConfigLoader import ConfigLoader\n",
    "from classes.ModelManager import ModelManager\n",
    "import time\n",
    "# Flags ####################\n",
    "transfer_learning_flag = True\n",
    "########################################\n",
    "available_models = [\"densenet121\",\"densenet169\",\"resnet18\",\"resnet50\"]\n",
    "color_flag = False\n",
    "libraries = [\"torchvision\"]\n",
    "pretrained_weights_list = [\"imagenet\"] #!TODO use , \"imagenet-microscopynet\"\n",
    "# pretrained_weights = None #\"imagenet-microscopynet\"\n",
    "# cfg.set_batch_size(16)\n",
    "# cfg.set_freezed_layer_index(None)\n",
    "\n",
    "config_base_path = \"/home/zano/Documents/TESI/FOLDER_CINECA/configs/pretrained\" if transfer_learning_flag else \"/home/zano/Documents/TESI/FOLDER_CINECA/configs/3c\"\n",
    "for model_name in available_models:\n",
    "    for pretrained_weights in pretrained_weights_list:\n",
    "        for library in libraries:\n",
    "            # yaml_path = f\"/home/zano/Documents/TESI/FOLDER_CINECA/configs/{num_input_channels}c/{model_name}.yaml\"\n",
    "            yaml_path = f\"{config_base_path}/{model_name}.yaml\"\n",
    "            cfg = ConfigLoader(yaml_path) \n",
    "            cfg.set_transfer_learning(transfer_learning_flag)\n",
    "            transfer_learning = cfg.get_transfer_learning()\n",
    "            # if model_name == \"densenet121\":\n",
    "            #     cfg.set_freezed_layer_index(236)\n",
    "            # pretrained if needed\n",
    "            # pretrained_weights = \"imagenet\" if transfer_learning else None # 'microscopynet' or \"imagenet\"\n",
    "            # set the model library\n",
    "            # model_library = \"torchvision\" # or \"torchvision\" or \"monai\"\n",
    "            # color_transforms = False\n",
    "            # train_transforms, val_transforms, test_transforms = tf.get_transforms(cfg,color_transforms=use_color_transform)\n",
    "            num_channels       = cfg.get_model_input_channels()\n",
    "            pretrained_weights = cfg.get_pretrained_weights()\n",
    "            num_epochs         = cfg.get_num_epochs()\n",
    "            num_workers        = cfg.get_num_workers()\n",
    "            batch_size         = cfg.get_batch_size()\n",
    "            num_folds          = cfg.get_num_folds()\n",
    "            model_library      = library\n",
    "            DATA_ROOT          = get_data_directory(num_channels)\n",
    "            model_manager = ModelManager(cfg, library=library)\n",
    "            # Verify the number of unique labels in the dataset\n",
    "            num_classes = len(np.unique(train_labels_np))\n",
    "            print(f\"Number of classes in the dataset: {num_classes}\")\n",
    "            using_cosine_scheduler = False\n",
    "            train_transforms, val_transforms, test_transforms = tf.get_transforms(\n",
    "                cfg, color_transforms=False\n",
    "            )\n",
    "            # Ensure the model's output matches the number of classes\n",
    "            model, device = model_manager.setup_model(num_classes=num_classes, pretrained_weights=pretrained_weights)\n",
    "\n",
    "            # print(model)\n",
    "\n",
    "            from classes.NestedCVStratifiedByPatient import NestedCVStratifiedByPatient\n",
    "            # cfg.set_freezed_layer_index(None)\n",
    "            experiment = NestedCVStratifiedByPatient(\n",
    "                df=df,\n",
    "                cfg=cfg,\n",
    "                labels_np=labels,\n",
    "                pat_labels=pat_labels,\n",
    "                unique_pat_ids=unique_pats,\n",
    "                pretrained_weights=pretrained_weights,\n",
    "                class_names=class_names,\n",
    "                model_manager=model_manager,\n",
    "                num_folds=num_folds,\n",
    "            )\n",
    "            start_time = time.time()\n",
    "            train_metrics, test_results = experiment.run_experiment()\n",
    "\n",
    "            execution_time = time.time() - start_time\n",
    "            # hold_out_cv = True\n",
    "            # using_cosine_scheduler = False\n",
    "\n",
    "            train_counts, val_counts = experiment.get_early_stopping_split_counts()\n",
    "            test_counts = experiment.num_outer_images\n",
    "\n",
    "            from utils.mlflow_functions import log_SSL_run_to_mlflow\n",
    "\n",
    "            best_idx   = best_fold_idx(test_results)\n",
    "            best_model, _ = experiment._get_model_and_device()\n",
    "            best_model.load_state_dict(\n",
    "                torch.load(f\"best_model_fold_{best_idx}.pth\", map_location=device))\n",
    "            best_model.eval()\n",
    "\n",
    "            log_SSL_run_to_mlflow(\n",
    "                cfg=cfg,\n",
    "                model=best_model,\n",
    "                class_names=class_names,\n",
    "                fold_results=test_results,\n",
    "                per_fold_metrics=train_metrics,\n",
    "                test_transforms=val_transforms,            \n",
    "                test_images_paths_np=te_imgs,\n",
    "                test_true_labels_np=te_y,\n",
    "                yaml_path=yaml_path,\n",
    "                color_transforms=False,\n",
    "                model_library=model_library,\n",
    "                pretrained_weights=pretrained_weights,\n",
    "                execution_time=execution_time,\n",
    "                train_counts=train_counts,\n",
    "                val_counts=val_counts,\n",
    "                test_counts=test_counts,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
