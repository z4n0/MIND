{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4f8add",
   "metadata": {},
   "source": [
    "# MOCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b50098",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1245ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zano/Documents/TESI/TESI/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Documents/TESI/TESI/notebooks\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4afb9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "import re\n",
    "import tifffile\n",
    "import glob\n",
    "# import random\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils.train_functions import (\n",
    "# train_epoch,\n",
    "# val_epoch,\n",
    "# print_model_summary,\n",
    "# plot_cv_results,\n",
    "# train_epoch_mixUp,\n",
    "# print_layers,\n",
    "# oversample_minority,\n",
    "# undersample_majority,\n",
    "# freeze_layers_up_to,\n",
    "# freeze_layers_up_to_progressive_ft,\n",
    "train_epoch_vit,\n",
    "val_epoch_vit,\n",
    ")\n",
    "\n",
    "import utils.transformations_functions as tf\n",
    "# Removed redundant import: from configs.ConfigLoader import ConfigLoader\n",
    "\n",
    "from classes.ModelManager import ModelManager\n",
    "import monai\n",
    "print(monai.__version__)\n",
    "#import tifffile\n",
    "#from monai.networks.nets import DenseNet121\n",
    "# import torch.nn.functional as F\n",
    "# from monai.visualize.class_activation_maps import GradCAMpp,GradCAM  \n",
    "#kaggle = input(\"Are you on Kaggle? Enter 'T' for True or 'F' for False:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88eb2862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment settings: {'gdrive': False, 'linux': True, 'kaggle': False, 'ssl': True}\n"
     ]
    }
   ],
   "source": [
    "from utils.setup_functions import set_environment_flags\n",
    "# Example usage:\n",
    "environment_flags = set_environment_flags()\n",
    "kaggle,gdrive,linux = environment_flags[\"kaggle\"], environment_flags[\"gdrive\"], environment_flags[\"linux\"]\n",
    "from utils.reproducibility_functions import set_global_seed\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee332c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are on linux\n",
      "Linux detected, setting tracking URI\n",
      "Final Tracking URI: /home/zano/Documents/TESI/mlruns\n",
      "Does the directory exist? True\n"
     ]
    }
   ],
   "source": [
    "# start mlflow ui\n",
    "from utils.mlflow_functions import *\n",
    "from utils.directory_functions import *\n",
    "\n",
    "tracking_uri = get_tracking_uri(gdrive,kaggle,linux)\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "start_mlflow_ui(tracking_uri) # start mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7beaba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 channels input\n",
      "you are in linux\n",
      "/home/zano/Documents/TESI/3c_MIP_new\n"
     ]
    }
   ],
   "source": [
    "num_input_channels = int(input(\"Enter the number of input channels (3 or 4): \"))\n",
    "from utils.directory_functions import get_data_and_base_directory\n",
    "data_dir, base_dir = get_data_and_base_directory(environment_flags[\"kaggle\"], environment_flags[\"gdrive\"], environment_flags[\"linux\"], num_input_channels=num_input_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41c7cf",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3924a547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd954decc8746a28f6b7b40ceb3f4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Class Set:', index=1, options=('MSA vs Control', 'MSA vs PD', 'MSA-P vs MSA-C', 'MSA-P vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "CLASS_NAME_SETS = {\n",
    "    \"MSA vs Control\": [\"MSA\", \"control\"],\n",
    "    \"MSA vs PD\": [\"MSA\", \"PD\"],\n",
    "    \"MSA-P vs MSA-C\": [\"MSA-P\", \"MSA-C\"],\n",
    "    \"MSA-P vs PD\": [\"MSA-P\", \"PD\"],\n",
    "    \"PD vs MSA-P vs MSA-C\": [\"PD\", \"MSA-P\", \"MSA-C\"]\n",
    "}\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=list(CLASS_NAME_SETS.keys()),\n",
    "    value=\"MSA vs PD\",\n",
    "    description='Class Set:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def on_dropdown_change(change):\n",
    "    \"\"\"\n",
    "    Update the class_names variable when the dropdown selection changes.\n",
    "    \"\"\"\n",
    "    global class_names\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        class_names = CLASS_NAME_SETS[change['new']]\n",
    "        print(f\"class_names set to: {class_names}\")\n",
    "\n",
    "\n",
    "class_names = CLASS_NAME_SETS[dropdown.value]\n",
    "\n",
    "dropdown.observe(on_dropdown_change)\n",
    "\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7269b40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in /home/zano/Documents/TESI/3c_MIP_new/ALL: 152\n",
      "Number of images in ALL folder: 152\n"
     ]
    }
   ],
   "source": [
    "## Paths of ALL images into a numpy array without labels used for SSL\n",
    "def from_tif_folder_to_np_paths_array(folder_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load all .tif images from a folder into a numpy array.\n",
    "    \"\"\"\n",
    "    image_paths = glob.glob(os.path.join(folder_path, \"*.tif\"))\n",
    "    image_paths_np = np.array(image_paths)\n",
    "    print(f\"Number of images in {folder_path}: {len(image_paths)}\")\n",
    "    return image_paths_np\n",
    "\n",
    "all_images_folder_path = os.path.join(data_dir, \"ALL\")\n",
    "all_images_paths = from_tif_folder_to_np_paths_array(all_images_folder_path)\n",
    "print(\"Number of images in ALL folder:\", len(all_images_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61bcd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSA', 'PD']\n",
      "Number of images in /home/zano/Documents/TESI/3c_MIP_new/CONTROL: 19\n",
      "Number of images in /home/zano/Documents/TESI/3c_MIP_new/CONTROL folder: 19\n"
     ]
    }
   ],
   "source": [
    "## Paths of ALL images into a numpy array without labels used for SSL\n",
    "print(class_names)\n",
    "if class_names == ['MSA-P', 'PD']:\n",
    "    ssl_images_folder_path = os.path.join(data_dir, \"CONTROL+MSA-C\")\n",
    "else:\n",
    "    ssl_images_folder_path = os.path.join(data_dir, \"CONTROL\")\n",
    "    \n",
    "\n",
    "ssl_images_paths_np = from_tif_folder_to_np_paths_array(ssl_images_folder_path)\n",
    "print(f\"Number of images in {ssl_images_folder_path} folder:\", len(ssl_images_paths_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba51763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSA': '/home/zano/Documents/TESI/3c_MIP_new/MSA', 'PD': '/home/zano/Documents/TESI/3c_MIP_new/PD'}\n",
      "Class directories:\n",
      "{'MSA': '/home/zano/Documents/TESI/3c_MIP_new/MSA', 'PD': '/home/zano/Documents/TESI/3c_MIP_new/PD'}\n",
      "MSA images (before filtering): 'gh' count: 83, 'vaso' count: 0\n",
      "Number of glandular images before filtering: 83\n",
      "Number of glandular images after filtering: 83\n",
      "PD images (before filtering): 'gh' count: 57, 'vaso' count: 0\n",
      "Number of glandular images before filtering: 57\n",
      "Number of glandular images after filtering: 57\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking image shapes:\n",
      "MSA image: MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5435 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5435 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5463 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh 2 pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5745 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5745 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5753 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5753 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5753 gh3.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5776 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5776 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPIgrey 63x z2 gh pinhole 1 z 05.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5881 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5881 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5904 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5904 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5954 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5954 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5969 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5969 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5978 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5992 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5992 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5996 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_5996 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6046 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6046 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6053 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6053 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6060 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6085 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6085 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6179 gh.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6179 gh2.tif.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6485.lif - 6485 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6485.lif - 6485 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6491.lif - 6491 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6491.lif - 6491 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6593.lif - 6593 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6593.lif - 6593 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6599.lif - 6599 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6657.lif - 6657 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_6663.lif - 6663 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7105.lif - 7105 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7105.lif - 7105 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7120.lif - 7120 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7132.lif - 7132 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7132.lif - 7132 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7144.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7144.lif - 7144 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7179.lif - 7179 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7185.lif - 7185 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7185.lif - 7185 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7191.lif - 7191 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7191.lif - 7191 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7239.lif - 7239 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7239.lif - 7239 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7293.lif - 7293 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7343.lif - 7343 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7343.lif - 7343 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "MSA image: MAX_7579.lif - 7579 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6008.lif - 6008 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6320 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6323.lif - 6323 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6323.lif - 6323 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6337.lif - 6337 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6340.lif - 6340 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6340.lif - 6340 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6351.lif - 6351 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6363.lif - 6363 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6366.lif - 6366 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6366.lif - 6366 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6375.lif - 6375 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6383.lif - 6383 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6424.lif - 6424 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6427.lif - 6427 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6459.lif - 6459 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6571.lif - 6571 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6577.lif - 6577 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6616.lif - 6616 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6651.lif - 6651 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6651.lif - 6651 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6690.lif - 6690 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6696.lif - 6696 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6696.lif - 6696 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6749.lif - 6749 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6749.lif - 6749 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6773.lif - 6773 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh  n2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6773.lif - 6773 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_6791.lif - 6791 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7155.lif - 7155 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7155.lif - 7155 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7222.lif - 7222 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7222.lif - 7222 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7229.lif - 7229 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7229.lif - 7229 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7284.lif - 7284 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7284.lif - 7284 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7461.lif - 7461 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7544.lif - 7544 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7677.lif - 7677 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7688.lif - 7688 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "PD image: MAX_7710.lif - 7710 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif  dtype: uint8, shape: (3, 1024, 1024)\n",
      "\n",
      "Minority label for resampling purposes: 1\n",
      "\n",
      "Sample of image paths: ('/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif', '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif', '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif', '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif', '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif')\n",
      "Total images found: 140\n",
      "\n",
      "Sample of image paths (NumPy): ['/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif'\n",
      " '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif'\n",
      " '/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping each class to its directory\n",
    "class_dirs = {} # { \"class_name\": \"path/to/class_dir\", \"class_name2\": \"path/to/class_dir2\", ... }\n",
    "is_three_classes = (len(class_names) == 3)\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dirs[class_name] = os.path.join(data_dir, class_name)\n",
    "    \n",
    "print(class_dirs)\n",
    "if is_three_classes:\n",
    "    class2_name, class1_name, class0_name = class_names\n",
    "    class2_dir, class1_dir, class0_dir = class_dirs.values()\n",
    "else:\n",
    "    class1_name, class0_name = class_names\n",
    "    class1_dir, class0_dir = class_dirs.values()\n",
    "\n",
    "print(\"Class directories:\")\n",
    "print(class_dirs)\n",
    "\n",
    "# Dictionaries to store image paths and counts for each class\n",
    "images_paths_dict = {}\n",
    "counts_dict = {}\n",
    "\n",
    "# Loop over classes to process each folder\n",
    "for class_name in class_names:\n",
    "    class_dir = class_dirs[class_name]\n",
    "    image_paths = sorted(glob.glob(os.path.join(class_dir, \"*.tif\")))\n",
    "    \n",
    "    # Check if images were found; otherwise raise an error\n",
    "    if not image_paths:\n",
    "        raise FileNotFoundError(f\"No TIFF image file found in {class_dir}\")\n",
    "    \n",
    "    # Count occurrences of 'gh' and 'vaso' in the filenames (using .lower() for case insensitivity)\n",
    "    gh_count = sum('gh' in os.path.basename(path).lower() for path in image_paths)\n",
    "    vaso_count = sum('vaso' in os.path.basename(path).lower() for path in image_paths)\n",
    "    print(f\"{class_name} images (before filtering): 'gh' count: {gh_count}, 'vaso' count: {vaso_count}\")\n",
    "    \n",
    "    # Filter out images that contain 'vaso' (if needed)\n",
    "    from utils.data_extraction_functions import remove_non_gland_images\n",
    "    image_paths = remove_non_gland_images(image_paths)\n",
    "    # counts after filtering\n",
    "    gh_count_after = sum('gh' in os.path.basename(path).lower() for path in image_paths)\n",
    "    vaso_count_after = sum('vaso' in os.path.basename(path).lower() for path in image_paths)\n",
    "    # print(f\"After removing 'vaso', {class_name} images: 'gh' count: {gh_count_after}, 'vaso' count: {vaso_count_after}\")\n",
    "    \n",
    "    # Store the filtered image paths and counts for later use\n",
    "    images_paths_dict[class_name] = image_paths\n",
    "    counts_dict[class_name] = {\"gh_count\": gh_count_after, \"vaso_count\": vaso_count_after}\n",
    "\n",
    "# Visualize the number of 'gh' counts per class in a bar chart\n",
    "# def plot_counts_bar_chart(counts_dict, class_names):\n",
    "#     \"\"\"\n",
    "#     Plot a bar chart of counts for each class.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.bar(class_names, [counts_dict[cn][\"gh_count\"] for cn in class_names], color='blue')\n",
    "#     plt.xlabel(\"Class\")\n",
    "#     plt.ylabel(\"Number of 'gh' occurrences\")\n",
    "#     plt.title(\"Number of 'gh' occurrences per class\")\n",
    "#     plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of 'gh' occurrences\")\n",
    "plt.title(\"Number of 'gh' occurrences per class\")\n",
    "bar_heights = [counts_dict[cn][\"gh_count\"] for cn in class_names]\n",
    "bar_colors = ['red', 'blue', 'lightblue']\n",
    "plt.bar(class_names, bar_heights, color=bar_colors)\n",
    "plt.show()\n",
    "\n",
    "# --- Debug: Check image shapes after initial loading ---\n",
    "print(\"\\nChecking image shapes:\")\n",
    "for class_name, image_paths in images_paths_dict.items():\n",
    "    for path in image_paths:\n",
    "        img = tifffile.imread(path)  # Read image as a numpy array\n",
    "        print(f\"{class_name} image: {os.path.basename(path)}  dtype: {img.dtype}, shape: {img.shape}\")\n",
    "\n",
    "# Combine image paths and labels for the three classes; \n",
    "# the label here is simply the index of the class in class_names (0, 1, 2)\n",
    "combined = [] # List to store tuples of (image_path, label)\n",
    "for label, class_name in enumerate(class_names):\n",
    "    for path in images_paths_dict[class_name]:\n",
    "        combined.append((path, label))\n",
    "# print(\"\\nSample of combined image paths and labels:\", combined[:5])\n",
    "# random.shuffle(combined)  # Shuffle the combined list to mix classes\n",
    "\n",
    "# Optionally, determine the minority label for resampling purposes\n",
    "counts = {label: len(images_paths_dict[class_name]) for label, class_name in enumerate(class_names)}\n",
    "minority_label = min(counts.keys(), key=lambda k: counts[k])\n",
    "print(f\"\\nMinority label for resampling purposes: {minority_label}\")\n",
    "\n",
    "# Unzip the combined list back into separate tuples (if needed)\n",
    "images_paths, labels = zip(*combined)\n",
    "print(\"\\nSample of image paths:\", images_paths[:5])\n",
    "print(\"Total images found:\", len(combined))\n",
    "\n",
    "# Optionally, convert to NumPy arrays (helpful for further processing or k-fold splitting)\n",
    "images_paths_np = np.array(images_paths)\n",
    "labels_np = np.array(labels)\n",
    "print(\"\\nSample of image paths (NumPy):\", images_paths_np[:5])\n",
    "print((labels_np))\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5763ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 140\n",
      "Original label distribution: {0: 83, 1: 57}\n",
      "\n",
      "Aiming for a balanced test set with 57 samples per class.\n",
      "Total balanced test set size will be: 114\n",
      "Test set size: 114\n",
      "\n",
      "Test set distribution: {0: 57, 1: 57}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set counts and percentages:\n",
      "MSA: 57 images (50.0% of test set)\n",
      "PD: 57 images (50.0% of test set)\n"
     ]
    }
   ],
   "source": [
    "# --- Your Split Logic for 50/50 distribution in test set ---\n",
    "print(\"Original dataset size:\", len(images_paths_np))\n",
    "\n",
    "# Find unique labels and their counts in the original dataset\n",
    "unique_labels, counts = np.unique(labels_np, return_counts=True)\n",
    "original_distribution = dict(zip(unique_labels, counts))\n",
    "print(f\"Original label distribution: {original_distribution}\")\n",
    "\n",
    "# Determine the maximum possible size for a balanced test set per class\n",
    "# This is limited by the count of the smallest class\n",
    "if len(unique_labels) > 1:\n",
    "    min_class_count = min(counts)\n",
    "    # We want a balanced test set, so take 'min_class_count' samples from each class\n",
    "    test_samples_per_class = min_class_count\n",
    "    total_balanced_test_size = test_samples_per_class * len(unique_labels)\n",
    "\n",
    "    print(f\"\\nAiming for a balanced test set with {test_samples_per_class} samples per class.\")\n",
    "    print(f\"Total balanced test set size will be: {total_balanced_test_size}\")\n",
    "\n",
    "    test_indices = []\n",
    "    train_indices = []\n",
    "\n",
    "    # Iterate through each class to split\n",
    "    for label in unique_labels:\n",
    "        # Get the indices in the original array that correspond to the current class\n",
    "        # print ( labels_np == label) # returns a boolean array\n",
    "        class_indices = np.where(labels_np == label)[0]  #use the boolean array to get the indices where cond is true \n",
    "        # print(f\"\\nClass {label} indices: {class_indices}\") #retuns the indices of the class in the original array and the boolarray so we use [0] to get the indices\n",
    "\n",
    "        # Randomly select a fixed number of indices for the test set from this class\n",
    "        # Use np.random.choice with replace=False for sampling without replacement\n",
    "        # Set a random_state for reproducibility if needed\n",
    "        rng = np.random.default_rng(42) # Use new random generator recommended over np.random.seed\n",
    "        test_class_indices = rng.choice(\n",
    "            class_indices,\n",
    "            size=test_samples_per_class,\n",
    "            replace=False\n",
    "        )\n",
    "        test_indices.extend(test_class_indices)\n",
    "\n",
    "    # Convert lists of indices to NumPy arrays\n",
    "    test_indices = np.array(test_indices)\n",
    "    train_indices = np.array(train_indices)\n",
    "\n",
    "    # Shuffle the indices to mix up the classes in the final arrays (optional but good practice)\n",
    "    # rng.shuffle(test_indices)\n",
    "    # rng.shuffle(train_indices)\n",
    "\n",
    "    balanced_test_images_paths = images_paths_np[test_indices]\n",
    "    balanced_test_true_labels = labels_np[test_indices]\n",
    "    print(f\"Test set size: {len(balanced_test_images_paths)}\")\n",
    "\n",
    "    # Verify the test set distribution\n",
    "    test_unique_labels, test_counts = np.unique(balanced_test_true_labels, return_counts=True)\n",
    "    test_distribution = dict(zip(test_unique_labels, test_counts))\n",
    "    print(f\"\\nTest set distribution: {test_distribution}\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    # Use test_unique_labels and test_counts for the bar plot\n",
    "    labels_for_plot = [class_names[label] if 'class_names' in locals() else f\"Label {label}\" for label in test_unique_labels]\n",
    "    plt.bar(labels_for_plot, test_counts)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of test images\")\n",
    "    plt.title(\"Test Set Label Distribution (Balanced)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print counts and percentages for the balanced test set\n",
    "    print(\"\\nTest set counts and percentages:\")\n",
    "    for label, count in zip(test_unique_labels, test_counts):\n",
    "         class_name = class_names[label] if 'class_names' in locals() else f\"Label {label}\"\n",
    "         print(f\"{class_name}: {count} images ({count/len(balanced_test_true_labels):.1%} of test set)\")\n",
    "\n",
    "else:\n",
    "    print(\"Cannot perform a balanced split with less than two unique classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e782dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 training images\n",
      "21 test images\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 (MSA): 12 images\n",
      "Label 1 (PD): 9 images\n",
      "Label 0 (MSA) is: 0.5714285714285714\n",
      "Label 1 (PD) is: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# NB the test set must be splitted BEFORE oversampling to avoid data leakage!\n",
    "# -------------------------------------------------------------------------\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#returns numpy arrays containing the paths to images and the labels\n",
    "train_images_paths, test_images_paths, train_true_labels, test_true_labels = train_test_split(\n",
    "    images_paths_np,\n",
    "    labels_np,\n",
    "    test_size= 0.15,\n",
    "    stratify=labels,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "test_images_paths_np = np.array(test_images_paths)\n",
    "test_true_labels_np = np.array(test_true_labels)\n",
    "# print(\"train images paths:\", train_images_paths)\n",
    "# print(\"true test labels:\", test_true_labels)\n",
    "# # For the cross-validation, we'll use train_images_paths and labels_temp\n",
    "train_images_paths_np = np.array(train_images_paths) #contains the images paths\n",
    "train_labels_np = np.array(train_true_labels) #contains the labels\n",
    "print(f\"{train_images_paths_np.shape[0]} training images\")\n",
    "print(f\"{len(test_images_paths)} test images\")\n",
    "#test_images_paths = [os.path.basename(path) for path in test_images_paths]\n",
    "# print(test_images_paths)\n",
    "print(type(train_images_paths))\n",
    "\n",
    "unique_labels, counts = np.unique(test_true_labels_np, return_counts=True)\n",
    "\n",
    "\n",
    "plt.bar([class_names[label] for label in unique_labels], counts)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of test images\")\n",
    "plt.title(\"Test Set Label Distribution\")\n",
    "plt.show()\n",
    "\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label {label} ({class_names[label]}): {count} images\")\n",
    "\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label {label} ({class_names[label]}) is: {count/test_true_labels_np.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f60f714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "patient_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9a70805e-fca0-416b-954a-9706daf9fa73",
       "rows": [
        [
         "0",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "4092"
        ],
        [
         "1",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4092.lif - 4092 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "4092"
        ],
        [
         "2",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "4121"
        ],
        [
         "3",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4121.lif - 4121 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "4121"
        ],
        [
         "4",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "5358"
        ],
        [
         "5",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5358.lif - 5358 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh2.tif",
         "0",
         "5358"
        ],
        [
         "6",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5435 gh.tif.tif",
         "0",
         "5435"
        ],
        [
         "7",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5435 gh2.tif.tif",
         "0",
         "5435"
        ],
        [
         "8",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5463 gh.tif.tif",
         "0",
         "5463"
        ],
        [
         "9",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh 2 pinhole 1 z 05.tif",
         "0",
         "5717"
        ],
        [
         "10",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5717.lif - 5717 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif",
         "0",
         "5717"
        ],
        [
         "11",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5745 gh.tif.tif",
         "0",
         "5745"
        ],
        [
         "12",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5745 gh2.tif.tif",
         "0",
         "5745"
        ],
        [
         "13",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5753 gh.tif.tif",
         "0",
         "5753"
        ],
        [
         "14",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5753 gh2.tif.tif",
         "0",
         "5753"
        ],
        [
         "15",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5753 gh3.tif.tif",
         "0",
         "5753"
        ],
        [
         "16",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh pinhole 1 z 05.tif",
         "0",
         "5767"
        ],
        [
         "17",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5767.lif - 5767 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif",
         "0",
         "5767"
        ],
        [
         "18",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5776 gh.tif.tif",
         "0",
         "5776"
        ],
        [
         "19",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5776 gh2.tif.tif",
         "0",
         "5776"
        ],
        [
         "20",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPI grey 63x z2 gh2 pinhole 1 z 05.tif",
         "0",
         "5878"
        ],
        [
         "21",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5878.lif - 5878 DL VIP r TH b Sinapto gr DAPIgrey 63x z2 gh pinhole 1 z 05.tif",
         "0",
         "5878"
        ],
        [
         "22",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5881 gh.tif.tif",
         "0",
         "5881"
        ],
        [
         "23",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5881 gh2.tif.tif",
         "0",
         "5881"
        ],
        [
         "24",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5904 gh.tif.tif",
         "0",
         "5904"
        ],
        [
         "25",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5904 gh2.tif.tif",
         "0",
         "5904"
        ],
        [
         "26",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5954 gh.tif.tif",
         "0",
         "5954"
        ],
        [
         "27",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5954 gh2.tif.tif",
         "0",
         "5954"
        ],
        [
         "28",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5969 gh.tif.tif",
         "0",
         "5969"
        ],
        [
         "29",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5969 gh2.tif.tif",
         "0",
         "5969"
        ],
        [
         "30",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5978 gh.tif.tif",
         "0",
         "5978"
        ],
        [
         "31",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5992 gh.tif.tif",
         "0",
         "5992"
        ],
        [
         "32",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5992 gh2.tif.tif",
         "0",
         "5992"
        ],
        [
         "33",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5996 gh.tif.tif",
         "0",
         "5996"
        ],
        [
         "34",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5996 gh2.tif.tif",
         "0",
         "5996"
        ],
        [
         "35",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6046 gh.tif.tif",
         "0",
         "6046"
        ],
        [
         "36",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6046 gh2.tif.tif",
         "0",
         "6046"
        ],
        [
         "37",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6053 gh.tif.tif",
         "0",
         "6053"
        ],
        [
         "38",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6053 gh2.tif.tif",
         "0",
         "6053"
        ],
        [
         "39",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6060 gh.tif.tif",
         "0",
         "6060"
        ],
        [
         "40",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6085 gh.tif.tif",
         "0",
         "6085"
        ],
        [
         "41",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6085 gh2.tif.tif",
         "0",
         "6085"
        ],
        [
         "42",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6179 gh.tif.tif",
         "0",
         "6179"
        ],
        [
         "43",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6179 gh2.tif.tif",
         "0",
         "6179"
        ],
        [
         "44",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "6308"
        ],
        [
         "45",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6308.lif - 6308 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6308"
        ],
        [
         "46",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "6311"
        ],
        [
         "47",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6311.lif - 6311 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6311"
        ],
        [
         "48",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh 2.tif",
         "0",
         "6326"
        ],
        [
         "49",
         "/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_6326.lif - 6326 DL VIP red Sinapto gr TH b D grey 63x z 2 pinhole 1 z 05 gh.tif",
         "0",
         "6326"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 140
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...</td>\n",
       "      <td>0</td>\n",
       "      <td>4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...</td>\n",
       "      <td>0</td>\n",
       "      <td>4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...</td>\n",
       "      <td>0</td>\n",
       "      <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...</td>\n",
       "      <td>0</td>\n",
       "      <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5...</td>\n",
       "      <td>0</td>\n",
       "      <td>5358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/PD/MAX_74...</td>\n",
       "      <td>1</td>\n",
       "      <td>7461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/PD/MAX_75...</td>\n",
       "      <td>1</td>\n",
       "      <td>7544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/PD/MAX_76...</td>\n",
       "      <td>1</td>\n",
       "      <td>7677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/PD/MAX_76...</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>/home/zano/Documents/TESI/3c_MIP_new/PD/MAX_77...</td>\n",
       "      <td>1</td>\n",
       "      <td>7710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  label patient_id\n",
       "0    /home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...      0       4092\n",
       "1    /home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...      0       4092\n",
       "2    /home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...      0       4121\n",
       "3    /home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_4...      0       4121\n",
       "4    /home/zano/Documents/TESI/3c_MIP_new/MSA/MAX_5...      0       5358\n",
       "..                                                 ...    ...        ...\n",
       "135  /home/zano/Documents/TESI/3c_MIP_new/PD/MAX_74...      1       7461\n",
       "136  /home/zano/Documents/TESI/3c_MIP_new/PD/MAX_75...      1       7544\n",
       "137  /home/zano/Documents/TESI/3c_MIP_new/PD/MAX_76...      1       7677\n",
       "138  /home/zano/Documents/TESI/3c_MIP_new/PD/MAX_76...      1       7688\n",
       "139  /home/zano/Documents/TESI/3c_MIP_new/PD/MAX_77...      1       7710\n",
       "\n",
       "[140 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patient IDs: ['4092' '4121' '5358' '5435' '5463' '5717' '5745' '5753' '5767' '5776'\n",
      " '5878' '5881' '5904' '5954' '5969' '5978' '5992' '5996' '6008' '6046'\n",
      " '6053' '6060' '6085' '6179' '6308' '6311' '6320' '6323' '6326' '6337'\n",
      " '6340' '6351' '6363' '6366' '6375' '6383' '6424' '6427' '6459' '6485'\n",
      " '6491' '6571' '6577' '6593' '6599' '6616' '6651' '6657' '6663' '6690'\n",
      " '6696' '6749' '6773' '6791' '7105' '7120' '7132' '7144' '7155' '7179'\n",
      " '7185' '7191' '7222' '7229' '7239' '7284' '7293' '7343' '7461' '7544'\n",
      " '7579' '7677' '7688' '7710']\n",
      "Number of unique patients: 74\n",
      "Unique patient labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "patient_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b95cd6ae-da7e-4819-9968-ee4bc4f21df1",
       "rows": [
        [
         "0",
         "4092",
         "0"
        ],
        [
         "1",
         "4121",
         "0"
        ],
        [
         "2",
         "5358",
         "0"
        ],
        [
         "3",
         "5435",
         "0"
        ],
        [
         "4",
         "5463",
         "0"
        ],
        [
         "5",
         "5717",
         "0"
        ],
        [
         "6",
         "5745",
         "0"
        ],
        [
         "7",
         "5753",
         "0"
        ],
        [
         "8",
         "5767",
         "0"
        ],
        [
         "9",
         "5776",
         "0"
        ],
        [
         "10",
         "5878",
         "0"
        ],
        [
         "11",
         "5881",
         "0"
        ],
        [
         "12",
         "5904",
         "0"
        ],
        [
         "13",
         "5954",
         "0"
        ],
        [
         "14",
         "5969",
         "0"
        ],
        [
         "15",
         "5978",
         "0"
        ],
        [
         "16",
         "5992",
         "0"
        ],
        [
         "17",
         "5996",
         "0"
        ],
        [
         "18",
         "6008",
         "1"
        ],
        [
         "19",
         "6046",
         "0"
        ],
        [
         "20",
         "6053",
         "0"
        ],
        [
         "21",
         "6060",
         "0"
        ],
        [
         "22",
         "6085",
         "0"
        ],
        [
         "23",
         "6179",
         "0"
        ],
        [
         "24",
         "6308",
         "0"
        ],
        [
         "25",
         "6311",
         "0"
        ],
        [
         "26",
         "6320",
         "1"
        ],
        [
         "27",
         "6323",
         "1"
        ],
        [
         "28",
         "6326",
         "0"
        ],
        [
         "29",
         "6337",
         "1"
        ],
        [
         "30",
         "6340",
         "1"
        ],
        [
         "31",
         "6351",
         "1"
        ],
        [
         "32",
         "6363",
         "1"
        ],
        [
         "33",
         "6366",
         "1"
        ],
        [
         "34",
         "6375",
         "1"
        ],
        [
         "35",
         "6383",
         "1"
        ],
        [
         "36",
         "6424",
         "1"
        ],
        [
         "37",
         "6427",
         "1"
        ],
        [
         "38",
         "6459",
         "1"
        ],
        [
         "39",
         "6485",
         "0"
        ],
        [
         "40",
         "6491",
         "0"
        ],
        [
         "41",
         "6571",
         "1"
        ],
        [
         "42",
         "6577",
         "1"
        ],
        [
         "43",
         "6593",
         "0"
        ],
        [
         "44",
         "6599",
         "0"
        ],
        [
         "45",
         "6616",
         "1"
        ],
        [
         "46",
         "6651",
         "1"
        ],
        [
         "47",
         "6657",
         "0"
        ],
        [
         "48",
         "6663",
         "0"
        ],
        [
         "49",
         "6690",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 74
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>7544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  label\n",
       "0        4092      0\n",
       "1        4121      0\n",
       "2        5358      0\n",
       "3        5435      0\n",
       "4        5463      0\n",
       "..        ...    ...\n",
       "69       7544      1\n",
       "70       7579      0\n",
       "71       7677      1\n",
       "72       7688      1\n",
       "73       7710      1\n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_patient_id(image_path):\n",
    "    # Example: parse from the file name\n",
    "    # In real code, you might have a different pattern\n",
    "    match = re.search(r'(\\d{4})', image_path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "# Build a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"image_path\": images_paths_np,\n",
    "    \"label\": labels_np\n",
    "})\n",
    "\n",
    "df[\"patient_id\"] = df[\"image_path\"].apply(extract_patient_id)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Ensure everything is string or int\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str)\n",
    "\n",
    "# Now group by patient to get a single label per patient.\n",
    "# If every patient truly has exactly one label, we can just take .first()\n",
    "patient_label_df = df.groupby(\"patient_id\", as_index=False)[\"label\"].first()\n",
    "\n",
    "unique_pat_ids = patient_label_df[\"patient_id\"].values  # need these to stratify for patient\n",
    "print(f\"Unique patient IDs: {unique_pat_ids}\")\n",
    "print(f\"Number of unique patients: {len(unique_pat_ids)}\")\n",
    "pat_labels = patient_label_df[\"label\"].values\n",
    "print(f\"Unique patient labels: {pat_labels}\")\n",
    "\n",
    "patient_label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f489ca",
   "metadata": {},
   "source": [
    "# MOCO v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3cb7d4",
   "metadata": {},
   "source": [
    "Using fixed, hand-extracted patches as your only â€œimagesâ€ for MoCo-v2 pretraining usually isnâ€™t idealâ€”MoCo-v2 (and most SSL methods) rely on random crops of various scales so the network learns both global structure and fine details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88181035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from /home/zano/Documents/TESI/TESI/configs/3c/base.yaml\n",
      "Configuration: {'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 6}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}\n",
      "Configuration loaded from /home/zano/Documents/TESI/TESI/configs/3c/resnet18.yaml\n",
      "Configuration: {'data_splitting': {'random_seed': 42, 'val_set_size': 0.17, 'test_set_size': 0.1, 'num_folds': 6}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 16, 'num_workers': 0}, 'model': {'model_name': 'Resnet18', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1}, 'training': {'num_epochs': 200, 'early_stopping_patience': 60, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': None, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '2e-4', 'patience': 30}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None}\n",
      "Using pretrained model: False\n",
      "Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x78036012af20> with color transforms: False\n",
      "the model is not supported by torchvision or is not pretrained\n",
      "Model Resnet18 not supported using custom transforms\n",
      "No fold-specific stats provided or incomplete; proceeding without specific normalization step (only ScaleIntensityd).\n",
      "Number of classes in the dataset: 2\n"
     ]
    }
   ],
   "source": [
    "from configs.ConfigLoader import ConfigLoader\n",
    "import utils.transformations_functions as tf\n",
    "from classes.ModelManager import ModelManager\n",
    "\n",
    "yaml_path = f\"/home/zano/Documents/TESI/TESI/configs/{num_input_channels}c/resnet18.yaml\"\n",
    "cfg = ConfigLoader(yaml_path) \n",
    "cfg.set_freezed_layer_index(None)\n",
    "transfer_learning = cfg.get_transfer_learning()\n",
    "pretrained_weights = \"imagenet\" if transfer_learning else \"\" # 'microscopynet' or \"imagenet\"\n",
    "model_library = \"torchvision\" # or \"torchvision\" or \"monai\"\n",
    "color_transforms = False\n",
    "train_transforms, val_transforms, test_transforms = tf.get_transforms(cfg)\n",
    "model_manager = ModelManager(cfg, library=model_library)\n",
    "# Verify the number of unique labels in the dataset\n",
    "num_classes = len(np.unique(train_labels_np))\n",
    "print(f\"Number of classes in the dataset: {num_classes}\")\n",
    "\n",
    "# Ensure the model's output matches the number of classes\n",
    "model, device = model_manager.setup_model(num_classes=num_classes, pretrained_weights=pretrained_weights)\n",
    "\n",
    "print(model)\n",
    "print(cfg.get_model_input_channels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d21e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the code to define callbacks for pl training early stopping with knn evaluation accuracy as metric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.train_functions import make_loader\n",
    "\n",
    "# Function to evaluate k-NN accuracy\n",
    "# This function computes the k-NN accuracy of a given backbone model on a specified data loader.\n",
    "# It uses cosine similarity and temperature-scaled softmax voting to determine the accuracy.\n",
    "@torch.no_grad()\n",
    "def knn_eval(backbone, loader, k=20, temperature=0.1, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Compute k-NN top1 accuracy of `backbone` on `loader`.\n",
    "    Uses cosine similarity and temperature-scaled softmax voting.\n",
    "    \"\"\"\n",
    "    backbone.eval()\n",
    "    feats, labels = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(device, non_blocking=True)\n",
    "        y = batch[\"label\"].to(device, non_blocking=True)\n",
    "        feats.append(backbone(x).flatten(start_dim=1))\n",
    "        labels.append(y)\n",
    "    feats = torch.cat(feats)                    # [N, D]\n",
    "    labels = torch.cat(labels)                  # [N]\n",
    "    feats = F.normalize(feats, dim=1)\n",
    "\n",
    "    # cosine similarity of each sample to every other\n",
    "    sim = feats @ feats.t() / temperature       # [N, N]\n",
    "    _, idx = sim.topk(k=k + 1, largest=True)    # self in first position\n",
    "\n",
    "    # Exclude itself\n",
    "    idx = idx[:, 1:]                            # [N, k]\n",
    "\n",
    "    top1 = 0\n",
    "    for i in range(feats.size(0)):\n",
    "        neigh_labels = labels[idx[i]]           # labels of k neighbours\n",
    "        # majority vote (temperature already applied in sim)\n",
    "        pred = torch.mode(neigh_labels)[0]\n",
    "        top1 += int(pred == labels[i])\n",
    "    return top1 / feats.size(0)\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "#lightning callback to evaluate k-NN accuracy\n",
    "class KNNMonitor(pl.Callback):\n",
    "    \"\"\"\n",
    "    Compute k-NN accuracy on a fixed probe set every `frequency` epochs.\n",
    "    Logs it as 'knn_acc' so EarlyStopping can watch it.\n",
    "    \"\"\"\n",
    "    def __init__(self, probe_loader, k=20, frequency=1, temperature=0.1, device=None):\n",
    "        super().__init__()\n",
    "        self.probe_loader = probe_loader\n",
    "        self.k = k\n",
    "        self.freq = frequency\n",
    "        self.temp = temperature\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # run only every `frequency` epochs\n",
    "        if (trainer.current_epoch + 1) % self.freq != 0:\n",
    "            return\n",
    "\n",
    "        acc = knn_eval(\n",
    "            backbone=pl_module.backbone,        # online encoder\n",
    "            loader=self.probe_loader,\n",
    "            k=self.k,\n",
    "            temperature=self.temp,\n",
    "            device=self.device,\n",
    "        )\n",
    "        # log so that EarlyStopping can monitor it\n",
    "        pl_module.log(\"knn_acc\", acc, prog_bar=True, on_epoch=True, logger=True)\n",
    "        epoch = trainer.current_epoch\n",
    "        print(f\"[Epoch {epoch}]  k-NN accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# Create a new DataLoader for knn test used for early stopping\n",
    "test_images_paths_np = np.array(balanced_test_images_paths)\n",
    "test_true_labels_np = np.array(balanced_test_true_labels)\n",
    "\n",
    "knn_loader = make_loader(\n",
    "    balanced_test_images_paths,\n",
    "    test_true_labels_np,\n",
    "    transforms=val_transforms,\n",
    "    cfg=cfg,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"knn_acc\",\n",
    "    mode=\"max\",        # we want accuracy to go UP\n",
    "    patience=100,        # stop if no improvement in 5 evals\n",
    "    min_delta=0.0,\n",
    "    check_on_train_epoch_end=True,\n",
    ")\n",
    "\n",
    "knn_cb = KNNMonitor(\n",
    "    probe_loader=knn_loader,\n",
    "    k=20,\n",
    "    frequency=1,       # every epoch\n",
    ")\n",
    "\n",
    "class PrintEpochLossCallback(pl.Callback):\n",
    "    \"\"\"\n",
    "    Prints the epoch-level loss after each training epoch.\n",
    "    Assumes you log a metric called 'train_loss'.\n",
    "    \"\"\"\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # 'trainer.callback_metrics' holds the metrics you logged this epoch\n",
    "        epoch_loss = trainer.callback_metrics.get(\"train_loss\")\n",
    "        current_epoch = trainer.current_epoch\n",
    "        if epoch_loss is not None:\n",
    "            print(f\"[Epoch {current_epoch}] => train_loss: {epoch_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"[Epoch {current_epoch}] => train_loss not found!\")\n",
    "\n",
    "print_epoch_loss = PrintEpochLossCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b7c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import random\n",
    "import tifffile\n",
    "import numpy as np # Ensure numpy is imported as np\n",
    "import torch # Ensure torch is imported\n",
    "from PIL import Image # For resizing if needed, though TF.resize is used for tensors\n",
    "from utils.transformations_functions import from_GBR_to_RGB\n",
    "\n",
    "class RandomPatchDataset(Dataset):\n",
    "    def __init__(self, paths, patch_size=256, patches_per_image=8, transform=None):\n",
    "        self.paths = list(map(Path, paths))\n",
    "        self.ps = patch_size\n",
    "        self.np = patches_per_image\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # length is â€œvirtualâ€: n_images Ã— patches_per_image\n",
    "        return len(self.paths) * self.np\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx // self.np]\n",
    "        img_np = tifffile.imread(img_path) # img_np is NumPy array\n",
    "\n",
    "        # Ensure img_np is CHW (Channel, Height, Width)\n",
    "        if img_np.ndim == 2:  # Grayscale (H, W)\n",
    "            # Stack to (3, H, W) for RGB, assuming 3 channels are desired\n",
    "            img_np = np.stack((img_np,) * 3, axis=0)\n",
    "        elif img_np.ndim == 3:\n",
    "            # Check if it's HWC (e.g., H, W, C where C is 3 or 4)\n",
    "            if img_np.shape[-1] in [3, 4] and img_np.shape[0] > 4: # Heuristic: if last dim is small and first is large\n",
    "                img_np = np.transpose(img_np, (2, 0, 1))  # Convert HWC to CHW\n",
    "            elif img_np.shape[0] not in [3, 4]: # Neither CHW nor convertible HWC\n",
    "                 raise ValueError(f\"Image {img_path} has unexpected shape: {img_np.shape}. Expected CHW or HWC with 3/4 channels.\")\n",
    "            # If img_np.shape[0] is [3,4], it's already CHW, do nothing.\n",
    "        else:\n",
    "            raise ValueError(f\"Image {img_path} has unsupported dimensions: {img_np.ndim}\")\n",
    "\n",
    "        img_tensor = torch.from_numpy(img_np) # img_tensor is now CHW\n",
    "\n",
    "        # Apply GBR to RGB conversion (expects CHW tensor)\n",
    "        img_tensor_rgb = from_GBR_to_RGB(img_tensor) # Should return CHW tensor\n",
    "\n",
    "        _c, h, w = img_tensor_rgb.shape\n",
    "\n",
    "        # Handle images smaller than the patch size by resizing them (maintaining CHW)\n",
    "        if h < self.ps or w < self.ps:\n",
    "            target_h = max(h, self.ps)\n",
    "            target_w = max(w, self.ps)\n",
    "            # TF.resize expects CHW tensor and [H, W] size\n",
    "            img_tensor_rgb = TF.resize(img_tensor_rgb, [target_h, target_w], interpolation=TF.InterpolationMode.BILINEAR, antialias=True)\n",
    "            _c, h, w = img_tensor_rgb.shape # Update dimensions\n",
    "\n",
    "        # Randomly select top-left coordinates for the patch\n",
    "        y = random.randint(0, h - self.ps)\n",
    "        x = random.randint(0, w - self.ps)\n",
    "        \n",
    "        # Extract patch from CHW tensor\n",
    "        patch_tensor = img_tensor_rgb[:, y:y+self.ps, x:x+self.ps]\n",
    "\n",
    "        # Ensure the patch_tensor is in a suitable data type for to_pil_image\n",
    "        # TF.to_pil_image handles CHW float tensor in [0,1] or CHW byte tensor in [0,255].\n",
    "        if patch_tensor.dtype != torch.uint8:\n",
    "            if patch_tensor.is_floating_point():\n",
    "                if patch_tensor.min() >= 0 and patch_tensor.max() <= 1:\n",
    "                    patch_tensor = (patch_tensor * 255).type(torch.uint8)\n",
    "                else: # Attempt to normalize or just cast, may need adjustment based on data range\n",
    "                    # Forcing to uint8; consider if normalization/clipping is needed first\n",
    "                    patch_tensor = torch.clamp(patch_tensor, 0, 255).type(torch.uint8) \n",
    "            else: # Other integer types\n",
    "                patch_tensor = patch_tensor.type(torch.uint8) # Direct cast, might lose precision\n",
    "\n",
    "        patch_pil = TF.to_pil_image(patch_tensor) # Expects CHW tensor or HWC numpy\n",
    "\n",
    "        if self.transform:\n",
    "            # self.transform (MoCoV2Transform) is expected to return two views (tensors)\n",
    "            return self.transform(patch_pil)\n",
    "        else:\n",
    "            return patch_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from re import S\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# Lightly imports\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules import MoCoProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.transforms.moco_transform import MoCoV2Transform\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "\n",
    "\n",
    "class MoCo(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning module implementing MoCo v2-like training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, num_ftrs=512, out_dim=128, max_epochs=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_encoder: Which torchvision ResNet to use. e.g. 'resnet18' => 512-d final layer\n",
    "                          'resnet50' => 2048-d final layer.\n",
    "            num_ftrs: Dimension of the backbone's output before the final FC.\n",
    "                      For resnet18 => 512, for resnet50 => 2048.\n",
    "            out_dim: Dimension of the projection head output (128 typical).\n",
    "            max_epochs: For scheduling momentum with cosine_schedule.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Build a standard torchvision backbone (without the final FC)\n",
    "        # resnet = getattr(torchvision.models, base_encoder)(weights = None)\n",
    "        self.resnet = encoder\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])  # remove final FC\n",
    "\n",
    "        # Projection head for the online encoder\n",
    "        self.projection_head = MoCoProjectionHead(num_ftrs, num_ftrs, out_dim)\n",
    "\n",
    "        # Create momentum backbone and head as copies\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        # Freeze momentum backbone to avoid gradient updates\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "        # Contrastive loss with memory bank\n",
    "        # size=(memory_bank_size, out_dim), e.g. memory_bank_size=4096, out_dim=128\n",
    "        # Use NTXentLoss as recommended in lightly docs for MoCo v2\n",
    "        self.criterion = NTXentLoss(memory_bank_size=(4096,128), temperature=0.1)\n",
    "\n",
    "        # We will do a cosine schedule for momentum\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the online (query) encoder.\n",
    "        x: (B, C, H, W) => returns the projection vector of shape (B, out_dim).\n",
    "        \"\"\"\n",
    "        query = self.backbone(x).flatten(start_dim=1)    # e.g. shape (B, 512) for resnet18\n",
    "        query = self.projection_head(query)              # shape (B, out_dim)\n",
    "        return query\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the momentum (key) encoder.\n",
    "        \"\"\"\n",
    "        key = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        key = self.projection_head_momentum(key).detach()\n",
    "        return key\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if batch_idx == 0 and self.current_epoch == 0:\n",
    "            print(\"DEBUG shapes:\", len(batch), batch[0].shape, batch[1].shape)\n",
    "        queries_batch, keys_batch = batch # Or batch[0], batch[1]\n",
    "        q = self.forward(queries_batch)\n",
    "        k = self.forward_momentum(keys_batch)\n",
    "        loss = self.criterion(q, k)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    # keep the EMA update *after* optimiser step\n",
    "    def on_train_batch_end(self, *_):\n",
    "        m = cosine_schedule(self.current_epoch, self.max_epochs, 0.996, 1.0)\n",
    "        update_momentum(self.backbone,        self.backbone_momentum,        m)\n",
    "        update_momentum(self.projection_head, self.projection_head_momentum, m)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # batch_size = 32\n",
    "        opt = torch.optim.SGD(self.parameters(),\n",
    "                              lr=0.03,\n",
    "                              momentum=0.9, weight_decay=1e-4)\n",
    "    \n",
    "        return opt\n",
    "\n",
    "# 1) Create the MoCo model with a resnet18 backbone\n",
    "#    If you want resnet50 => num_ftrs=2048\n",
    "print(\"Creating MoCo model...\")\n",
    "max_epochs = 100\n",
    "model = MoCo(base_encoder=\"resnet18\", num_ftrs=512, out_dim=128, max_epochs=max_epochs)\n",
    "\n",
    "# 2) Define your transforms\n",
    "#    MoCoV2Transform returns two views: x_query, x_key\n",
    "#    input_size=256 => randomly resize/crop to 256\n",
    "transform = MoCoV2Transform(input_size=cfg.get_image_shape()[0],\n",
    "                            # cj_prob=0.5,  # color jitter probability\n",
    "                            # cj_strength=0.5,  # color jitter strength\n",
    "                            # cj_bright=0.4,  # brightness strength\n",
    "                            # cj_contrast=0.4,  # contrast strength\n",
    "                            # cj_sat=0.4,  # saturation strength\n",
    "                            # gaussian_blur=0.1,  # gaussian blur probability\n",
    "                            )\n",
    "\n",
    "# 3) Create a dataset from your unlabeled folder of images\n",
    "#    e.g., data/unlabeled/\n",
    "# dataset = LightlyDataset(f\"/home/zano/Documents/TESI/{num_input_channels}c_MIP_new/ALL/\", transform=transform)\n",
    "# print(\"Number of samples in the dataset:\", len(dataset))\n",
    "INPUT_SIZE = 64\n",
    "# 4) Create a DataLoader\n",
    "transform = MoCoV2Transform(\n",
    "    input_size=INPUT_SIZE,           # match patch dimension\n",
    "    # gaussian_blur=0.3,\n",
    "    # cj_prob=0.1,\n",
    "    # cj_strength=0.1,\n",
    "    # cj_contrast=0.1,\n",
    "    # cj_bright=0.1,\n",
    "    # cj_sat=0.1,\n",
    "    # cj_hue=0.1,\n",
    "    # sigmas=None,  # sigma range for gaussian blur\n",
    "    # normalize= None\n",
    "    \n",
    ")\n",
    "\n",
    "ds = RandomPatchDataset(all_images_paths, patch_size=INPUT_SIZE,\n",
    "                        patches_per_image=10, transform=transform)\n",
    "\n",
    "print(\"Number of samples in the dataset:\", len(ds))\n",
    "\n",
    "\n",
    "loader = DataLoader(ds, batch_size=256, shuffle=True,  # TODO: change to a much greater batch size at least 128\n",
    "                    num_workers=2, drop_last=True\n",
    "                    )\n",
    "# 5) Train with PyTorch Lightning\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gradient_clip_val=1.0,\n",
    "    max_epochs=max_epochs,\n",
    "    min_epochs=1,\n",
    "    max_steps=-1, \n",
    "    devices=1,\n",
    "    accelerator=device,\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"32-true\",  # mixed precision\n",
    "    enable_progress_bar=False,            # turn off TQDM updates\n",
    "    callbacks=[\n",
    "            print_epoch_loss,\n",
    "            knn_cb,                    \n",
    "            early_stop,\n",
    "        ]  # use our custom callback\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=loader)\n",
    "\n",
    "# 6) Save your trained model (the \"online\" part)\n",
    "#    Typically you keep the backbone for downstream tasks\n",
    "encoder_name = \"moco_backbone_es\"\n",
    "STABLE_BACKBONE_PATH = encoder_name + \".pth\"\n",
    "encoder_weights = torch.save(model.backbone.state_dict(), STABLE_BACKBONE_PATH)\n",
    "print(f\"MoCo training completed. Saved backbone to {STABLE_BACKBONE_PATH}\")\n",
    "\n",
    "# load the saved model\n",
    "moco_encoder = MoCo(base_encoder=\"resnet18\", num_ftrs=512, out_dim=128, max_epochs=10)\n",
    "moco_encoder.backbone.load_state_dict(torch.load(STABLE_BACKBONE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# tiny_moco_patches.py\n",
    "# --------------------\n",
    "# MoCo-v2 pre-training on very small datasets by turning each high-resolution\n",
    "# image into many random 256Ã—256 patches.\n",
    "\n",
    "# * 10 patches per slide  â†’  152 slides  â†’  1 520 virtual samples\n",
    "# * batch 64 with NVIDIA mixed-precision (fits 12 GB GPU)\n",
    "# * NT-Xent queue 512 (updates fully every 8 steps)\n",
    "# * momentum schedule 0.95 â†’ 0.90\n",
    "# * loss should fall from â‰ˆ5.4 to <4 within 10-15 epochs\n",
    "# \"\"\"\n",
    "\n",
    "# from pathlib import Path\n",
    "# import math, random, copy, tifffile, numpy as np\n",
    "# import torch, torchvision\n",
    "# from torch import nn\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "# from lightly.loss import NTXentLoss\n",
    "# from lightly.models.modules import MoCoProjectionHead\n",
    "# from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "# from lightly.transforms.moco_transform import MoCoV2Transform\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 1)  Random-patch dataset\n",
    "# # ------------------------------------------------------------------\n",
    "# class RandomPatchDataset(Dataset):\n",
    "#     def __init__(self, paths, patch=256, per_img=10, transform=None):\n",
    "#         self.paths, self.ps, self.per_img, self.tf = list(paths), patch, per_img, transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.paths) * self.per_img     # virtual length\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = tifffile.imread(self.paths[idx // self.per_img])\n",
    "#         if img.ndim == 3 and img.shape[0] <= 4:          # CHW â†’ HWC\n",
    "#             img = np.transpose(img, (1, 2, 0))\n",
    "#         h, w = img.shape[:2]; p = self.ps\n",
    "#         y, x = random.randint(0, h - p), random.randint(0, w - p)\n",
    "#         patch = img[y:y+p, x:x+p]\n",
    "#         patch = torchvision.transforms.functional.to_pil_image(patch)\n",
    "#         return self.tf(patch)            # MoCoV2Transform returns [view_q, view_k]\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 2)  Simple collate-fn that stacks the two views\n",
    "# # ------------------------------------------------------------------\n",
    "# def moco_collate(batch):\n",
    "#     # batch = [[v_q0, v_k0], [v_q1, v_k1], ...]\n",
    "#     x_q = torch.stack([b[0] for b in batch], 0)\n",
    "#     x_k = torch.stack([b[1] for b in batch], 0)\n",
    "#     return x_q, x_k\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 3)  MoCo model (ResNet-50 backbone)\n",
    "# # ------------------------------------------------------------------\n",
    "# class MoCo(nn.Module):\n",
    "#     def __init__(self, out_dim=128):\n",
    "#         super().__init__()\n",
    "#         resnet = torchvision.models.resnet50(weights=None)\n",
    "#         self.backbone = nn.Sequential(*list(resnet.children())[:-1])        # 2048-d\n",
    "#         self.head = MoCoProjectionHead(2048, 2048, out_dim)\n",
    "\n",
    "#         self.backbone_m = copy.deepcopy(self.backbone)\n",
    "#         self.head_m     = copy.deepcopy(self.head)\n",
    "#         deactivate_requires_grad(self.backbone_m)\n",
    "#         deactivate_requires_grad(self.head_m)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         z = self.backbone(x).flatten(1)\n",
    "#         return self.head(z)\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def forward_m(self, x):\n",
    "#         z = self.backbone_m(x).flatten(1)\n",
    "#         return self.head_m(z)\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 4)  Build data loaders\n",
    "# # ------------------------------------------------------------------  \n",
    "# img_dir = Path(ssl_images_folder_path)\n",
    "# paths   = sorted(p for p in img_dir.glob(\"*.tif*\"))        # adapt extension if PNG/JPG\n",
    "\n",
    "# transform = MoCoV2Transform(\n",
    "#     input_size=256,\n",
    "#     gaussian_blur=0.5,\n",
    "#     cj_prob=0.8,\n",
    "# )\n",
    "\n",
    "# from torchvision import transforms\n",
    "\n",
    "# # overwrite the default RandomResizedCrop with a custom one\n",
    "# transform.random_resized_crop = transforms.RandomResizedCrop(\n",
    "#     size=256,\n",
    "#     scale=(0.5, 1.0),          # â† wider scale range\n",
    "#     ratio=(3/4, 4/3),\n",
    "#     interpolation=transforms.InterpolationMode.BICUBIC,\n",
    "#     antialias=True\n",
    "# )\n",
    "\n",
    "# # from torchvision import transforms\n",
    "# # # from lightly.transforms.utils import GaussianBlur\n",
    "\n",
    "# # transform = transforms.Compose([\n",
    "# #     transform.ensure_cha\n",
    "# #     transforms.RandomResizedCrop(\n",
    "# #         256, scale=(0.5, 1.0), ratio=(3/4, 4/3),\n",
    "# #         interpolation=transforms.InterpolationMode.BICUBIC,\n",
    "# #         antialias=True),\n",
    "# #     transforms.RandomHorizontalFlip(p=0.5),\n",
    "# #     transforms.RandomApply([\n",
    "# #         transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "# #     ], p=0.8),\n",
    "# #     transforms.RandomGrayscale(p=0.2),\n",
    "# #     # GaussianBlur(0.5),                       # same as MoCoV2 default\n",
    "# #     transforms.ToTensor(),\n",
    "# #     transforms.Normalize(\n",
    "# #         mean=[0.485, 0.456, 0.406][:num_input_channels],\n",
    "# #         std =[0.229, 0.224, 0.225][:num_input_channels]),\n",
    "# # ])\n",
    "\n",
    "# dataset = RandomPatchDataset(paths, patch=256, per_img=10, transform=transform)\n",
    "# loader  = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True,\n",
    "#                      num_workers=4, collate_fn=moco_collate)\n",
    "\n",
    "# print(f\"Slides: {len(paths)}  |  virtual patches/epoch: {len(dataset)}\")\n",
    "\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 5)  Model, optimiser, loss, scaler\n",
    "# # ------------------------------------------------------------------\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model  = MoCo().to(device)\n",
    "\n",
    "# criterion = NTXentLoss(memory_bank_size=128, temperature=0.1)\n",
    "# opt = torch.optim.SGD(model.parameters(), lr=0.03 * (64/256),\n",
    "#                       momentum=0.9, weight_decay=1e-4)\n",
    "# scaler = GradScaler()\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 6)  Training\n",
    "# # ------------------------------------------------------------------\n",
    "# epochs = 100\n",
    "# for ep in range(epochs):\n",
    "#     model.train()\n",
    "#     total = 0.0\n",
    "#     m_val = 0.90 + 0.05 * (1 + math.cos(math.pi * ep / epochs)) / 2   # 0.95â†’0.90\n",
    "\n",
    "#     for x_q, x_k in loader:\n",
    "#         x_q, x_k = x_q.to(device), x_k.to(device)\n",
    "\n",
    "#         # momentum encoder update *before* forward pass (official MoCo order)\n",
    "#         update_momentum(model.backbone, model.backbone_m, m_val)\n",
    "#         update_momentum(model.head,     model.head_m,     m_val)\n",
    "\n",
    "#         with autocast():                            # mixed precision\n",
    "#             q = model(x_q)\n",
    "#             k = model.forward_m(x_k)\n",
    "#             loss = criterion(q, k)\n",
    "\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(opt)\n",
    "#         scaler.update()\n",
    "#         opt.zero_grad()\n",
    "#         total += loss.detach()\n",
    "\n",
    "#     avg = (total / len(loader)).item()\n",
    "#     print(f\"Epoch {ep:03d}  NT-Xent loss: {avg:.4f}\")\n",
    "\n",
    "# print(\"Finished.  Save backbone with:\")\n",
    "# print(\"torch.save(model.backbone.state_dict(), 'moco_backbone.pth')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c072395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ReLU(inplace=True) MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(model)\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "resnet = getattr(torchvision.models, 'resnet50')(weights = None)\n",
    "print(*list(resnet.children())[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from utils.data_visualization_functions import generate_cv_results_figure\n",
    "from utils.train_functions import train_epoch, undersample_majority, val_epoch, train_epoch_mixUp, oversample_minority\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from monai.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Example usage in a PyTorch Lightning module for supervised fine-tuning:\n",
    "class SSLClassifierModule(pl.LightningModule):\n",
    "    def __init__(self, encoder: nn.Module, num_classes: int = 2, freeze_encoder: bool = True, backbone_output_dim: int = None, lr: float = 1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"encoder\"])\n",
    "        self.classifier_model = BaseSSLClassifier(encoder, num_classes, freeze_encoder, backbone_output_dim)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier_model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self(images)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        self.log(\"test_loss\", loss, on_epoch=True)\n",
    "        self.log(\"test_acc\", acc, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd,\n",
    "    RandFlipd, RandRotate90d, Resized, ToTensord, NormalizeIntensityd\n",
    ")\n",
    "\n",
    "# Define transforms for training with data augmentation\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"], reader=\"itkreader\"),  # Load the image from disk\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),  # Convert to channel-first format\n",
    "    LambdaD(keys=[\"image\"], func=lambda x: x[:3, ...]),  # Keep only first 3 channels\n",
    "    Resized(keys=[\"image\"], spatial_size=(224, 224)),  # Resize to match model input\n",
    "    RandFlipd(keys=[\"image\"], prob=0.5),  # Random horizontal flips\n",
    "    ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0),  # Scale to [0, 1]\n",
    "    # NormalizeIntensityd(\n",
    "    #     keys=[\"image\"], \n",
    "    #     mean=[0.485, 0.456, 0.406], \n",
    "    #     std=[0.229, 0.224, 0.225]\n",
    "    # ),  # ImageNet normalization\n",
    "    ToTensord(keys=[\"image\"]),  # Convert to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Define transforms for validation/testing (no augmentations)\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"], reader=\"itkreader\"),  # Load the image from disk\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    LambdaD(keys=[\"image\"], func=lambda x: x[:3, ...]),  # Keep only first 3 channels\n",
    "    Resized(keys=[\"image\"], spatial_size=(224, 224)),\n",
    "    ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0),\n",
    "    # NormalizeIntensityd(\n",
    "    #     keys=[\"image\"], \n",
    "    #     mean=[0.485, 0.456, 0.406], \n",
    "    #     std=[0.229, 0.224, 0.225]\n",
    "    # ),\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "])\n",
    "\n",
    "test_transforms = val_transforms  # Same transforms for testing\n",
    "\n",
    "# Call the function:\n",
    "results = run_outer_cv_patient_stratified(\n",
    "    df=df,\n",
    "    unique_pat_ids=unique_pat_ids,\n",
    "    pat_labels=pat_labels,\n",
    "    cfg=cfg,\n",
    "    encoder = moco_encoder,\n",
    "    train_transforms=train_transforms,\n",
    "    val_transforms=val_transforms,\n",
    "    test_transforms=test_transforms,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
