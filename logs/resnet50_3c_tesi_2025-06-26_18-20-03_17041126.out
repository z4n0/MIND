Logging to:   /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/logs/resnet50_3c_tesi_2025-06-26_18-20-03_17041126.out
Running on:   lrdn3375.leonardo.local
CUDA visible: 0
Started at:   Thu Jun 26 18:20:03 CEST 2025
──────────────────────────────────────────────
/leonardo/prod/opt/libraries/cineca-ai/4.3.0/none/cineca-ai-env/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
2025-06-26 18:20:27.347959: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-06-26 18:20:28.142089: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-06-26 18:20:28.143262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-06-26 18:20:28.255551: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-06-26 18:20:28.532151: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-26 18:20:30.789266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Configuration loaded from /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/configs/3c/base.yaml
Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 6}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}
Configuration loaded from /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/configs/3c/resnet50.yaml
Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.17, 'test_set_size': 0.1, 'num_folds': 7}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 8, 'num_workers': 2}, 'model': {'model_name': 'Resnet50', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'torchvision', 'pretrained_weights': 'imagenet'}, 'training': {'num_epochs': 125, 'early_stopping_patience': 40, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': None, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '2e-4', 'patience': 25}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}
Using configuration: configs/3c/resnet50.yaml
Class names: ['MSA', 'PD']
Number of channels: 3
Pretrained weights: imagenet
Number of epochs: 125
Number of workers: 2
Batch size: 8
Number of folds: 7
Model library: torchvision
Data directory: /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/data/3c_MIP
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
No fold-specific stats provided or incomplete; proceeding without specific normalization step (only ScaleIntensityd).
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Detected 2 unique classes.

===== OUTER FOLD 1 / 7 =====
Outer Train images: 141 | Outer Test images: 23
--- Calculating normalization stats for Fold 1 Training Data ---
[I 2025-06-26 18:20:48,044] A new study created in memory with name: no-name-09d14e9a-d338-4624-b2db-1deec8a47bf5
Fold 1 stats: {'mean': [0.029443830251693726, 0.01055073831230402, 0.08572834730148315], 'std': [0.054127827286720276, 0.015007078647613525, 0.09222081303596497]}
--- Generating data transforms for Fold 1 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.029443830251693726, 0.01055073831230402, 0.08572834730148315], std: [0.054127827286720276, 0.015007078647613525, 0.09222081303596497]
Applying fold-specific normalization to validation data with mean: [0.029443830251693726, 0.01055073831230402, 0.08572834730148315], std: [0.054127827286720276, 0.015007078647613525, 0.09222081303596497]
Transforms generated for Fold 1.
--- Starting Hyperparameter Tuning for Fold 1 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:21:24,557] Trial 0 finished with value: 0.7026981145143509 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7026981145143509.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:21:56,458] Trial 1 finished with value: 1.277799401804805 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7026981145143509.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:22:28,453] Trial 2 finished with value: 0.7754053860902786 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7026981145143509.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 1 with LR=0.000047 ---
X_train_es: (117,) | X_val_es: (24,)
Early stopping split: Train images: 117, Validation images: 24
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 1 Epoch 1/125: Tr L: 0.7477, Tr Acc: 0.4797, Val L: 0.9480, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 2/125: Tr L: 0.6857, Tr Acc: 0.5811, Val L: 0.7938, Val Acc: 0.3750, Val F1: 0.5161 lr: 0.000047
 Fold 1 Epoch 3/125: Tr L: 0.6512, Tr Acc: 0.6351, Val L: 0.6878, Val Acc: 0.6667, Val F1: 0.4286 lr: 0.000047
 Fold 1 Epoch 4/125: Tr L: 0.6688, Tr Acc: 0.6081, Val L: 0.7397, Val Acc: 0.4167, Val F1: 0.4615 lr: 0.000047
 Fold 1 Epoch 5/125: Tr L: 0.6827, Tr Acc: 0.5811, Val L: 0.6598, Val Acc: 0.5417, Val F1: 0.4211 lr: 0.000047
 Fold 1 Epoch 6/125: Tr L: 0.6727, Tr Acc: 0.5743, Val L: 0.7151, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 1 Epoch 7/125: Tr L: 0.6354, Tr Acc: 0.6284, Val L: 1.0510, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 1 Epoch 8/125: Tr L: 0.6120, Tr Acc: 0.6757, Val L: 0.7108, Val Acc: 0.6667, Val F1: 0.3333 lr: 0.000047
 Fold 1 Epoch 9/125: Tr L: 0.6887, Tr Acc: 0.6351, Val L: 1.3090, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 10/125: Tr L: 0.5830, Tr Acc: 0.7297, Val L: 0.7656, Val Acc: 0.4583, Val F1: 0.5185 lr: 0.000047
 Fold 1 Epoch 11/125: Tr L: 0.5503, Tr Acc: 0.7365, Val L: 0.7596, Val Acc: 0.6250, Val F1: 0.4706 lr: 0.000047
 Fold 1 Epoch 12/125: Tr L: 0.5908, Tr Acc: 0.7095, Val L: 0.7614, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000047
 Fold 1 Epoch 13/125: Tr L: 0.5822, Tr Acc: 0.7432, Val L: 2.1829, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 1 Epoch 14/125: Tr L: 0.6199, Tr Acc: 0.6622, Val L: 0.7197, Val Acc: 0.5833, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 15/125: Tr L: 0.5530, Tr Acc: 0.6959, Val L: 1.2322, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 1 Epoch 16/125: Tr L: 0.4643, Tr Acc: 0.7703, Val L: 0.6769, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000047
 Fold 1 Epoch 17/125: Tr L: 0.6142, Tr Acc: 0.7365, Val L: 1.9118, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 1 Epoch 18/125: Tr L: 0.5680, Tr Acc: 0.7230, Val L: 1.4553, Val Acc: 0.6250, Val F1: 0.4000 lr: 0.000047
 Fold 1 Epoch 19/125: Tr L: 0.6747, Tr Acc: 0.7162, Val L: 2.5884, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 1 Epoch 20/125: Tr L: 0.5340, Tr Acc: 0.7230, Val L: 1.0582, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 1 Epoch 21/125: Tr L: 0.4593, Tr Acc: 0.8041, Val L: 0.8636, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 1 Epoch 22/125: Tr L: 0.4897, Tr Acc: 0.8243, Val L: 2.1676, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 1 Epoch 23/125: Tr L: 0.5032, Tr Acc: 0.7703, Val L: 1.4203, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 1 Epoch 24/125: Tr L: 0.4389, Tr Acc: 0.8108, Val L: 1.5490, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 1 Epoch 25/125: Tr L: 0.5636, Tr Acc: 0.7568, Val L: 0.8727, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 1 Epoch 26/125: Tr L: 0.4766, Tr Acc: 0.7770, Val L: 1.1891, Val Acc: 0.5000, Val F1: 0.5385 lr: 0.000047
 Fold 1 Epoch 27/125: Tr L: 0.4122, Tr Acc: 0.7905, Val L: 1.4313, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000047
 Fold 1 Epoch 28/125: Tr L: 0.4317, Tr Acc: 0.8108, Val L: 0.9538, Val Acc: 0.5417, Val F1: 0.4762 lr: 0.000047
 Fold 1 Epoch 29/125: Tr L: 0.5948, Tr Acc: 0.7027, Val L: 1.2144, Val Acc: 0.6667, Val F1: 0.6000 lr: 0.000047
 Fold 1 Epoch 30/125: Tr L: 0.4713, Tr Acc: 0.8108, Val L: 2.0589, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 1 Epoch 31/125: Tr L: 0.5082, Tr Acc: 0.8243, Val L: 1.1330, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 1 Epoch 32/125: Tr L: 0.5059, Tr Acc: 0.8378, Val L: 0.8359, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000024
 Fold 1 Epoch 33/125: Tr L: 0.4608, Tr Acc: 0.8446, Val L: 1.5428, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000024
 Fold 1 Epoch 34/125: Tr L: 0.4147, Tr Acc: 0.8581, Val L: 1.5456, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000024
 Fold 1 Epoch 35/125: Tr L: 0.4440, Tr Acc: 0.8041, Val L: 1.3797, Val Acc: 0.5833, Val F1: 0.6154 lr: 0.000024
 Fold 1 Epoch 36/125: Tr L: 0.3649, Tr Acc: 0.8784, Val L: 1.1395, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000024
 Fold 1 Epoch 37/125: Tr L: 0.3168, Tr Acc: 0.8649, Val L: 1.5943, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000024
 Fold 1 Epoch 38/125: Tr L: 0.3325, Tr Acc: 0.8851, Val L: 1.3197, Val Acc: 0.6250, Val F1: 0.4000 lr: 0.000024
 Fold 1 Epoch 39/125: Tr L: 0.4354, Tr Acc: 0.8311, Val L: 1.9831, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000024
 Fold 1 Epoch 40/125: Tr L: 0.3964, Tr Acc: 0.8446, Val L: 1.8997, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000024
 Fold 1 Epoch 41/125: Tr L: 0.2937, Tr Acc: 0.8851, Val L: 1.2037, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 42/125: Tr L: 0.2711, Tr Acc: 0.8851, Val L: 0.6797, Val Acc: 0.7917, Val F1: 0.7368 lr: 0.000024
 Fold 1 Epoch 43/125: Tr L: 0.4100, Tr Acc: 0.8311, Val L: 1.7531, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000024
 Fold 1 Epoch 44/125: Tr L: 0.3349, Tr Acc: 0.8649, Val L: 1.6408, Val Acc: 0.5833, Val F1: 0.5833 lr: 0.000024
 Fold 1 Epoch 45/125: Tr L: 0.4832, Tr Acc: 0.8311, Val L: 1.1680, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000024
Early stopping triggered at epoch 45 for fold 1
--- Evaluating Fold 1 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 1: {0: 15, 1: 8}
percentage of classes in test set: 0    0.652174
1    0.347826
Name: count, dtype: float64
 [FOLD 1 FINAL] Test Loss: 0.5055 | Test Acc: 0.6957 | test Balanced Acc: 0.6792 | test F1: 0.5882 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

===== OUTER FOLD 2 / 7 =====
Outer Train images: 140 | Outer Test images: 24
--- Calculating normalization stats for Fold 2 Training Data ---
[I 2025-06-26 18:24:43,128] A new study created in memory with name: no-name-007a64f8-bff4-46bd-85c0-7265e2efb303
Fold 2 stats: {'mean': [0.02990889921784401, 0.010732205584645271, 0.08828655630350113], 'std': [0.05641394108533859, 0.01623234897851944, 0.09562390297651291]}
--- Generating data transforms for Fold 2 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.02990889921784401, 0.010732205584645271, 0.08828655630350113], std: [0.05641394108533859, 0.01623234897851944, 0.09562390297651291]
Applying fold-specific normalization to validation data with mean: [0.02990889921784401, 0.010732205584645271, 0.08828655630350113], std: [0.05641394108533859, 0.01623234897851944, 0.09562390297651291]
Transforms generated for Fold 2.
--- Starting Hyperparameter Tuning for Fold 2 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:25:16,279] Trial 0 finished with value: 0.682438975572586 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.682438975572586.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:25:50,789] Trial 1 finished with value: 1.0487603783607482 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.682438975572586.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:26:22,369] Trial 2 finished with value: 0.723360113799572 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.682438975572586.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 2 with LR=0.000047 ---
X_train_es: (116,) | X_val_es: (24,)
Early stopping split: Train images: 116, Validation images: 24
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 2 Epoch 1/125: Tr L: 0.7434, Tr Acc: 0.5274, Val L: 0.6771, Val Acc: 0.6250, Val F1: 0.0000 lr: 0.000047
 Fold 2 Epoch 2/125: Tr L: 0.7084, Tr Acc: 0.5411, Val L: 0.6031, Val Acc: 0.7083, Val F1: 0.3636 lr: 0.000047
 Fold 2 Epoch 3/125: Tr L: 0.7149, Tr Acc: 0.5548, Val L: 0.5739, Val Acc: 0.6250, Val F1: 0.0000 lr: 0.000047
 Fold 2 Epoch 4/125: Tr L: 0.7273, Tr Acc: 0.5205, Val L: 0.5461, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000047
 Fold 2 Epoch 5/125: Tr L: 0.7754, Tr Acc: 0.5342, Val L: 1.1906, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 2 Epoch 6/125: Tr L: 0.6874, Tr Acc: 0.5959, Val L: 0.5646, Val Acc: 0.6250, Val F1: 0.0000 lr: 0.000047
 Fold 2 Epoch 7/125: Tr L: 0.7229, Tr Acc: 0.5890, Val L: 0.5346, Val Acc: 0.7500, Val F1: 0.5000 lr: 0.000047
 Fold 2 Epoch 8/125: Tr L: 0.6239, Tr Acc: 0.6918, Val L: 0.4799, Val Acc: 0.7917, Val F1: 0.7826 lr: 0.000047
 Fold 2 Epoch 9/125: Tr L: 0.6235, Tr Acc: 0.6370, Val L: 0.5526, Val Acc: 0.7500, Val F1: 0.7500 lr: 0.000047
 Fold 2 Epoch 10/125: Tr L: 0.6235, Tr Acc: 0.6438, Val L: 0.5525, Val Acc: 0.6250, Val F1: 0.0000 lr: 0.000047
 Fold 2 Epoch 11/125: Tr L: 0.5998, Tr Acc: 0.6986, Val L: 1.7709, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 2 Epoch 12/125: Tr L: 0.7138, Tr Acc: 0.6164, Val L: 0.4998, Val Acc: 0.7500, Val F1: 0.7500 lr: 0.000047
 Fold 2 Epoch 13/125: Tr L: 0.6390, Tr Acc: 0.6781, Val L: 0.5887, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000047
 Fold 2 Epoch 14/125: Tr L: 0.5963, Tr Acc: 0.6849, Val L: 0.4659, Val Acc: 0.7917, Val F1: 0.7368 lr: 0.000047
 Fold 2 Epoch 15/125: Tr L: 0.5541, Tr Acc: 0.6986, Val L: 0.4738, Val Acc: 0.7083, Val F1: 0.3636 lr: 0.000047
 Fold 2 Epoch 16/125: Tr L: 0.5824, Tr Acc: 0.6986, Val L: 0.5159, Val Acc: 0.7917, Val F1: 0.7059 lr: 0.000047
 Fold 2 Epoch 17/125: Tr L: 0.6015, Tr Acc: 0.6712, Val L: 2.2651, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 2 Epoch 18/125: Tr L: 0.5327, Tr Acc: 0.6986, Val L: 0.8463, Val Acc: 0.6250, Val F1: 0.1818 lr: 0.000047
 Fold 2 Epoch 19/125: Tr L: 0.6655, Tr Acc: 0.6712, Val L: 0.8832, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000047
 Fold 2 Epoch 20/125: Tr L: 0.5715, Tr Acc: 0.7260, Val L: 0.5559, Val Acc: 0.7500, Val F1: 0.7000 lr: 0.000047
 Fold 2 Epoch 21/125: Tr L: 0.5783, Tr Acc: 0.6712, Val L: 1.7513, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 2 Epoch 22/125: Tr L: 0.5367, Tr Acc: 0.7397, Val L: 0.6487, Val Acc: 0.7500, Val F1: 0.6250 lr: 0.000047
 Fold 2 Epoch 23/125: Tr L: 0.5190, Tr Acc: 0.7740, Val L: 0.6380, Val Acc: 0.7083, Val F1: 0.4615 lr: 0.000047
 Fold 2 Epoch 24/125: Tr L: 0.5587, Tr Acc: 0.7192, Val L: 2.2287, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 2 Epoch 25/125: Tr L: 0.4214, Tr Acc: 0.8082, Val L: 0.5325, Val Acc: 0.7917, Val F1: 0.7368 lr: 0.000047
 Fold 2 Epoch 26/125: Tr L: 0.4511, Tr Acc: 0.7945, Val L: 0.8010, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000047
 Fold 2 Epoch 27/125: Tr L: 0.5700, Tr Acc: 0.8082, Val L: 0.5602, Val Acc: 0.8750, Val F1: 0.8571 lr: 0.000047
 Fold 2 Epoch 28/125: Tr L: 0.4165, Tr Acc: 0.8151, Val L: 0.7460, Val Acc: 0.7500, Val F1: 0.7500 lr: 0.000047
 Fold 2 Epoch 29/125: Tr L: 0.5315, Tr Acc: 0.7945, Val L: 0.6254, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000047
 Fold 2 Epoch 30/125: Tr L: 0.6185, Tr Acc: 0.7329, Val L: 1.0806, Val Acc: 0.5833, Val F1: 0.5833 lr: 0.000047
 Fold 2 Epoch 31/125: Tr L: 0.7610, Tr Acc: 0.7466, Val L: 2.9527, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000047
 Fold 2 Epoch 32/125: Tr L: 0.4702, Tr Acc: 0.7877, Val L: 0.4712, Val Acc: 0.8333, Val F1: 0.7500 lr: 0.000047
 Fold 2 Epoch 33/125: Tr L: 0.5517, Tr Acc: 0.7671, Val L: 2.2210, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000047
 Fold 2 Epoch 34/125: Tr L: 0.5519, Tr Acc: 0.7671, Val L: 0.4948, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 2 Epoch 35/125: Tr L: 0.5501, Tr Acc: 0.7945, Val L: 1.1383, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000047
 Fold 2 Epoch 36/125: Tr L: 0.4620, Tr Acc: 0.8082, Val L: 0.3591, Val Acc: 0.8333, Val F1: 0.7500 lr: 0.000047
 Fold 2 Epoch 37/125: Tr L: 0.4730, Tr Acc: 0.8562, Val L: 0.4253, Val Acc: 0.7917, Val F1: 0.6667 lr: 0.000047
 Fold 2 Epoch 38/125: Tr L: 0.2770, Tr Acc: 0.8630, Val L: 1.4669, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000047
 Fold 2 Epoch 39/125: Tr L: 0.5239, Tr Acc: 0.8014, Val L: 2.8238, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 2 Epoch 40/125: Tr L: 0.4835, Tr Acc: 0.8219, Val L: 2.2372, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 2 Epoch 41/125: Tr L: 0.4476, Tr Acc: 0.8288, Val L: 0.6808, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 2 Epoch 42/125: Tr L: 0.4809, Tr Acc: 0.8630, Val L: 0.8390, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 2 Epoch 43/125: Tr L: 0.4766, Tr Acc: 0.8425, Val L: 1.8384, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 2 Epoch 44/125: Tr L: 0.5531, Tr Acc: 0.7671, Val L: 1.2297, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000047
 Fold 2 Epoch 45/125: Tr L: 0.4295, Tr Acc: 0.8082, Val L: 0.5998, Val Acc: 0.8333, Val F1: 0.7500 lr: 0.000047
 Fold 2 Epoch 46/125: Tr L: 0.4564, Tr Acc: 0.8014, Val L: 1.6605, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000047
 Fold 2 Epoch 47/125: Tr L: 0.5274, Tr Acc: 0.8219, Val L: 0.4354, Val Acc: 0.8750, Val F1: 0.8235 lr: 0.000047
 Fold 2 Epoch 48/125: Tr L: 0.4762, Tr Acc: 0.8219, Val L: 1.0028, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 2 Epoch 49/125: Tr L: 0.4748, Tr Acc: 0.8219, Val L: 0.5323, Val Acc: 0.7917, Val F1: 0.7059 lr: 0.000047
 Fold 2 Epoch 50/125: Tr L: 0.3862, Tr Acc: 0.8151, Val L: 0.6398, Val Acc: 0.7917, Val F1: 0.7059 lr: 0.000047
 Fold 2 Epoch 51/125: Tr L: 0.3669, Tr Acc: 0.8699, Val L: 3.7226, Val Acc: 0.4583, Val F1: 0.5517 lr: 0.000047
 Fold 2 Epoch 52/125: Tr L: 0.5866, Tr Acc: 0.8288, Val L: 1.4901, Val Acc: 0.7083, Val F1: 0.4615 lr: 0.000047
 Fold 2 Epoch 53/125: Tr L: 0.6771, Tr Acc: 0.8014, Val L: 2.2964, Val Acc: 0.5833, Val F1: 0.5833 lr: 0.000047
 Fold 2 Epoch 54/125: Tr L: 0.4050, Tr Acc: 0.8425, Val L: 0.7959, Val Acc: 0.7917, Val F1: 0.6154 lr: 0.000047
 Fold 2 Epoch 55/125: Tr L: 0.3024, Tr Acc: 0.8493, Val L: 0.8243, Val Acc: 0.7083, Val F1: 0.5333 lr: 0.000047
 Fold 2 Epoch 56/125: Tr L: 0.5072, Tr Acc: 0.8699, Val L: 1.2880, Val Acc: 0.6667, Val F1: 0.6000 lr: 0.000047
 Fold 2 Epoch 57/125: Tr L: 0.6233, Tr Acc: 0.8425, Val L: 1.9396, Val Acc: 0.5833, Val F1: 0.5455 lr: 0.000047
 Fold 2 Epoch 58/125: Tr L: 0.3800, Tr Acc: 0.8836, Val L: 1.0064, Val Acc: 0.7500, Val F1: 0.6667 lr: 0.000047
 Fold 2 Epoch 59/125: Tr L: 0.5860, Tr Acc: 0.8288, Val L: 1.0866, Val Acc: 0.7917, Val F1: 0.7059 lr: 0.000047
 Fold 2 Epoch 60/125: Tr L: 0.5882, Tr Acc: 0.8288, Val L: 3.0667, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 2 Epoch 61/125: Tr L: 0.5859, Tr Acc: 0.7877, Val L: 1.1971, Val Acc: 0.7500, Val F1: 0.6667 lr: 0.000047
 Fold 2 Epoch 62/125: Tr L: 0.4799, Tr Acc: 0.8493, Val L: 1.2966, Val Acc: 0.7083, Val F1: 0.6316 lr: 0.000047
 Fold 2 Epoch 63/125: Tr L: 0.3918, Tr Acc: 0.8630, Val L: 1.4453, Val Acc: 0.7917, Val F1: 0.6667 lr: 0.000024
 Fold 2 Epoch 64/125: Tr L: 0.5188, Tr Acc: 0.8219, Val L: 1.0332, Val Acc: 0.7083, Val F1: 0.5882 lr: 0.000024
 Fold 2 Epoch 65/125: Tr L: 0.4559, Tr Acc: 0.8562, Val L: 1.1011, Val Acc: 0.6250, Val F1: 0.5263 lr: 0.000024
 Fold 2 Epoch 66/125: Tr L: 0.5012, Tr Acc: 0.8288, Val L: 1.0480, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000024
 Fold 2 Epoch 67/125: Tr L: 0.3812, Tr Acc: 0.8562, Val L: 0.8759, Val Acc: 0.6667, Val F1: 0.5000 lr: 0.000024
 Fold 2 Epoch 68/125: Tr L: 0.4170, Tr Acc: 0.8493, Val L: 1.2207, Val Acc: 0.6250, Val F1: 0.5714 lr: 0.000024
 Fold 2 Epoch 69/125: Tr L: 0.3952, Tr Acc: 0.8425, Val L: 0.9941, Val Acc: 0.7083, Val F1: 0.6316 lr: 0.000024
 Fold 2 Epoch 70/125: Tr L: 0.2704, Tr Acc: 0.9110, Val L: 1.0809, Val Acc: 0.6667, Val F1: 0.6000 lr: 0.000024
 Fold 2 Epoch 71/125: Tr L: 0.1667, Tr Acc: 0.9247, Val L: 1.2700, Val Acc: 0.7083, Val F1: 0.5882 lr: 0.000024
 Fold 2 Epoch 72/125: Tr L: 0.3573, Tr Acc: 0.8904, Val L: 1.0210, Val Acc: 0.7500, Val F1: 0.6250 lr: 0.000024
 Fold 2 Epoch 73/125: Tr L: 0.4022, Tr Acc: 0.8973, Val L: 1.0488, Val Acc: 0.7083, Val F1: 0.6667 lr: 0.000024
 Fold 2 Epoch 74/125: Tr L: 0.3825, Tr Acc: 0.8973, Val L: 0.7453, Val Acc: 0.7083, Val F1: 0.6667 lr: 0.000024
 Fold 2 Epoch 75/125: Tr L: 0.5291, Tr Acc: 0.8493, Val L: 1.2579, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000024
 Fold 2 Epoch 76/125: Tr L: 0.3983, Tr Acc: 0.8904, Val L: 0.8884, Val Acc: 0.6250, Val F1: 0.5714 lr: 0.000024
Early stopping triggered at epoch 76 for fold 2
--- Evaluating Fold 2 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 2: {0: 16, 1: 8}
percentage of classes in test set: 0    0.666667
1    0.333333
Name: count, dtype: float64
 [FOLD 2 FINAL] Test Loss: 0.3159 | Test Acc: 0.8750 | test Balanced Acc: 0.8750 | test F1: 0.8235 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

===== OUTER FOLD 3 / 7 =====
Outer Train images: 141 | Outer Test images: 23
--- Calculating normalization stats for Fold 3 Training Data ---
[I 2025-06-26 18:29:38,703] A new study created in memory with name: no-name-2824fb0b-5349-4e94-ac08-b9764356de26
Fold 3 stats: {'mean': [0.029022786766290665, 0.010841076262295246, 0.08311717957258224], 'std': [0.05283747613430023, 0.01635167934000492, 0.08950860053300858]}
--- Generating data transforms for Fold 3 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.029022786766290665, 0.010841076262295246, 0.08311717957258224], std: [0.05283747613430023, 0.01635167934000492, 0.08950860053300858]
Applying fold-specific normalization to validation data with mean: [0.029022786766290665, 0.010841076262295246, 0.08311717957258224], std: [0.05283747613430023, 0.01635167934000492, 0.08950860053300858]
Transforms generated for Fold 3.
--- Starting Hyperparameter Tuning for Fold 3 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:30:11,473] Trial 0 finished with value: 0.6957860365509988 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6957860365509988.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:30:45,737] Trial 1 finished with value: 0.8842638731002808 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6957860365509988.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:31:19,238] Trial 2 finished with value: 0.6626496277749538 and parameters: {'lr': 0.0004014783718209777}. Best is trial 2 with value: 0.6626496277749538.
  Best LR from inner CV = 0.000401
--- Starting Final Model Training for Fold 3 with LR=0.000401 ---
X_train_es: (117,) | X_val_es: (24,)
Early stopping split: Train images: 117, Validation images: 24
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 3 Epoch 1/125: Tr L: 1.0568, Tr Acc: 0.5541, Val L: 1.9307, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000401
 Fold 3 Epoch 2/125: Tr L: 1.2133, Tr Acc: 0.5338, Val L: 0.9446, Val Acc: 0.4167, Val F1: 0.2222 lr: 0.000401
 Fold 3 Epoch 3/125: Tr L: 0.7469, Tr Acc: 0.6014, Val L: 0.8690, Val Acc: 0.7083, Val F1: 0.5333 lr: 0.000401
 Fold 3 Epoch 4/125: Tr L: 0.7869, Tr Acc: 0.6284, Val L: 8.0584, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000401
 Fold 3 Epoch 5/125: Tr L: 0.8476, Tr Acc: 0.6014, Val L: 0.6663, Val Acc: 0.7083, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 6/125: Tr L: 0.6955, Tr Acc: 0.6757, Val L: 1.9163, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000401
 Fold 3 Epoch 7/125: Tr L: 0.6511, Tr Acc: 0.7027, Val L: 1.0052, Val Acc: 0.7500, Val F1: 0.7500 lr: 0.000401
 Fold 3 Epoch 8/125: Tr L: 0.6935, Tr Acc: 0.7230, Val L: 0.9728, Val Acc: 0.7083, Val F1: 0.6316 lr: 0.000401
 Fold 3 Epoch 9/125: Tr L: 0.6594, Tr Acc: 0.6757, Val L: 0.4591, Val Acc: 0.6667, Val F1: 0.4286 lr: 0.000401
 Fold 3 Epoch 10/125: Tr L: 0.6064, Tr Acc: 0.7162, Val L: 1.5604, Val Acc: 0.7500, Val F1: 0.7000 lr: 0.000401
 Fold 3 Epoch 11/125: Tr L: 0.6612, Tr Acc: 0.7703, Val L: 2.4865, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000401
 Fold 3 Epoch 12/125: Tr L: 0.6278, Tr Acc: 0.7770, Val L: 0.4732, Val Acc: 0.7083, Val F1: 0.5333 lr: 0.000401
 Fold 3 Epoch 13/125: Tr L: 0.7234, Tr Acc: 0.7432, Val L: 1.0538, Val Acc: 0.5000, Val F1: 0.4000 lr: 0.000401
 Fold 3 Epoch 14/125: Tr L: 0.4946, Tr Acc: 0.7703, Val L: 1.7923, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000401
 Fold 3 Epoch 15/125: Tr L: 0.6142, Tr Acc: 0.8108, Val L: 5.3040, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000401
 Fold 3 Epoch 16/125: Tr L: 0.4928, Tr Acc: 0.8041, Val L: 0.6900, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000401
 Fold 3 Epoch 17/125: Tr L: 0.4662, Tr Acc: 0.7770, Val L: 1.1074, Val Acc: 0.7083, Val F1: 0.6316 lr: 0.000401
 Fold 3 Epoch 18/125: Tr L: 0.5720, Tr Acc: 0.7365, Val L: 1.3995, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000401
 Fold 3 Epoch 19/125: Tr L: 0.4864, Tr Acc: 0.8243, Val L: 1.1397, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000401
 Fold 3 Epoch 20/125: Tr L: 0.4355, Tr Acc: 0.8243, Val L: 1.5372, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000401
 Fold 3 Epoch 21/125: Tr L: 0.5454, Tr Acc: 0.8378, Val L: 2.2336, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 22/125: Tr L: 0.4864, Tr Acc: 0.7905, Val L: 0.7397, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000401
 Fold 3 Epoch 23/125: Tr L: 0.5799, Tr Acc: 0.7635, Val L: 1.8257, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000401
 Fold 3 Epoch 24/125: Tr L: 0.5140, Tr Acc: 0.7838, Val L: 1.0600, Val Acc: 0.7083, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 25/125: Tr L: 0.5673, Tr Acc: 0.7635, Val L: 0.4433, Val Acc: 0.8333, Val F1: 0.7778 lr: 0.000401
 Fold 3 Epoch 26/125: Tr L: 0.4124, Tr Acc: 0.8311, Val L: 1.7992, Val Acc: 0.6667, Val F1: 0.6000 lr: 0.000401
 Fold 3 Epoch 27/125: Tr L: 0.4085, Tr Acc: 0.8446, Val L: 1.7214, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 28/125: Tr L: 0.4072, Tr Acc: 0.8176, Val L: 2.4562, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000401
 Fold 3 Epoch 29/125: Tr L: 0.5979, Tr Acc: 0.7635, Val L: 1.0202, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000401
 Fold 3 Epoch 30/125: Tr L: 0.3946, Tr Acc: 0.8311, Val L: 2.7620, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000401
 Fold 3 Epoch 31/125: Tr L: 0.6003, Tr Acc: 0.7905, Val L: 1.3246, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000401
 Fold 3 Epoch 32/125: Tr L: 0.4559, Tr Acc: 0.7905, Val L: 1.9315, Val Acc: 0.8333, Val F1: 0.8182 lr: 0.000401
 Fold 3 Epoch 33/125: Tr L: 0.4662, Tr Acc: 0.8041, Val L: 1.2423, Val Acc: 0.7500, Val F1: 0.7000 lr: 0.000401
 Fold 3 Epoch 34/125: Tr L: 0.4903, Tr Acc: 0.7905, Val L: 2.9257, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000401
 Fold 3 Epoch 35/125: Tr L: 0.4291, Tr Acc: 0.8716, Val L: 0.8983, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000401
 Fold 3 Epoch 36/125: Tr L: 0.5276, Tr Acc: 0.7838, Val L: 1.3356, Val Acc: 0.4167, Val F1: 0.4615 lr: 0.000401
 Fold 3 Epoch 37/125: Tr L: 0.3735, Tr Acc: 0.8378, Val L: 5.8177, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000401
 Fold 3 Epoch 38/125: Tr L: 0.4841, Tr Acc: 0.8378, Val L: 3.5017, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000401
 Fold 3 Epoch 39/125: Tr L: 0.3479, Tr Acc: 0.8514, Val L: 1.1408, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000401
 Fold 3 Epoch 40/125: Tr L: 0.4773, Tr Acc: 0.7770, Val L: 1.1018, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000401
 Fold 3 Epoch 41/125: Tr L: 0.3994, Tr Acc: 0.8446, Val L: 0.7522, Val Acc: 0.7083, Val F1: 0.5882 lr: 0.000401
 Fold 3 Epoch 42/125: Tr L: 0.4224, Tr Acc: 0.8514, Val L: 0.7309, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000401
 Fold 3 Epoch 43/125: Tr L: 0.4070, Tr Acc: 0.8649, Val L: 0.6035, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000401
 Fold 3 Epoch 44/125: Tr L: 0.3068, Tr Acc: 0.8716, Val L: 1.7950, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000401
 Fold 3 Epoch 45/125: Tr L: 0.3416, Tr Acc: 0.8649, Val L: 0.7215, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000401
 Fold 3 Epoch 46/125: Tr L: 0.4721, Tr Acc: 0.8446, Val L: 2.5490, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 47/125: Tr L: 0.4997, Tr Acc: 0.7770, Val L: 0.8448, Val Acc: 0.7500, Val F1: 0.7273 lr: 0.000401
 Fold 3 Epoch 48/125: Tr L: 0.4052, Tr Acc: 0.8378, Val L: 1.5562, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000401
 Fold 3 Epoch 49/125: Tr L: 0.3759, Tr Acc: 0.8243, Val L: 4.1625, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 50/125: Tr L: 0.7289, Tr Acc: 0.7905, Val L: 4.7885, Val Acc: 0.7083, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 51/125: Tr L: 0.3522, Tr Acc: 0.8378, Val L: 3.6040, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000401
 Fold 3 Epoch 52/125: Tr L: 0.4687, Tr Acc: 0.8581, Val L: 1.4179, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000201
 Fold 3 Epoch 53/125: Tr L: 0.2422, Tr Acc: 0.9189, Val L: 2.0588, Val Acc: 0.5833, Val F1: 0.5833 lr: 0.000201
 Fold 3 Epoch 54/125: Tr L: 0.4412, Tr Acc: 0.8176, Val L: 1.4613, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000201
 Fold 3 Epoch 55/125: Tr L: 0.3217, Tr Acc: 0.8649, Val L: 0.9145, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000201
 Fold 3 Epoch 56/125: Tr L: 0.2527, Tr Acc: 0.8784, Val L: 1.4194, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000201
 Fold 3 Epoch 57/125: Tr L: 0.2788, Tr Acc: 0.9122, Val L: 0.9424, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000201
 Fold 3 Epoch 58/125: Tr L: 0.3045, Tr Acc: 0.8851, Val L: 3.9260, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000201
 Fold 3 Epoch 59/125: Tr L: 0.1701, Tr Acc: 0.9324, Val L: 0.9186, Val Acc: 0.7500, Val F1: 0.7273 lr: 0.000201
 Fold 3 Epoch 60/125: Tr L: 0.2879, Tr Acc: 0.9054, Val L: 1.2378, Val Acc: 0.7917, Val F1: 0.7826 lr: 0.000201
 Fold 3 Epoch 61/125: Tr L: 0.5206, Tr Acc: 0.9122, Val L: 0.9245, Val Acc: 0.7917, Val F1: 0.7619 lr: 0.000201
 Fold 3 Epoch 62/125: Tr L: 0.2855, Tr Acc: 0.8919, Val L: 0.7508, Val Acc: 0.7083, Val F1: 0.6316 lr: 0.000201
 Fold 3 Epoch 63/125: Tr L: 0.2219, Tr Acc: 0.9189, Val L: 1.2569, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000201
 Fold 3 Epoch 64/125: Tr L: 0.2659, Tr Acc: 0.9122, Val L: 1.4517, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000201
 Fold 3 Epoch 65/125: Tr L: 0.3393, Tr Acc: 0.8716, Val L: 2.2974, Val Acc: 0.6667, Val F1: 0.6000 lr: 0.000201
Early stopping triggered at epoch 65 for fold 3
--- Evaluating Fold 3 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 3: {0: 15, 1: 8}
percentage of classes in test set: 0    0.652174
1    0.347826
Name: count, dtype: float64
 [FOLD 3 FINAL] Test Loss: 1.1623 | Test Acc: 0.3478 | test Balanced Acc: 0.2958 | test F1: 0.1176 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

===== OUTER FOLD 4 / 7 =====
Outer Train images: 140 | Outer Test images: 24
--- Calculating normalization stats for Fold 4 Training Data ---
[I 2025-06-26 18:34:04,611] A new study created in memory with name: no-name-c232ff69-68a3-45c8-bdab-4677fcb5a628
Fold 4 stats: {'mean': [0.030436677858233452, 0.011141260154545307, 0.08784590661525726], 'std': [0.05676080286502838, 0.016273561865091324, 0.09347698837518692]}
--- Generating data transforms for Fold 4 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.030436677858233452, 0.011141260154545307, 0.08784590661525726], std: [0.05676080286502838, 0.016273561865091324, 0.09347698837518692]
Applying fold-specific normalization to validation data with mean: [0.030436677858233452, 0.011141260154545307, 0.08784590661525726], std: [0.05676080286502838, 0.016273561865091324, 0.09347698837518692]
Transforms generated for Fold 4.
--- Starting Hyperparameter Tuning for Fold 4 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:34:39,394] Trial 0 finished with value: 0.6907306045293808 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6907306045293808.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:35:11,980] Trial 1 finished with value: 1.0859641343355178 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6907306045293808.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:35:47,008] Trial 2 finished with value: 0.7845839455723762 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6907306045293808.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 4 with LR=0.000047 ---
X_train_es: (116,) | X_val_es: (24,)
Early stopping split: Train images: 116, Validation images: 24
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 4 Epoch 1/125: Tr L: 0.7905, Tr Acc: 0.5137, Val L: 0.7241, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 4 Epoch 2/125: Tr L: 0.7087, Tr Acc: 0.5479, Val L: 0.6649, Val Acc: 0.6250, Val F1: 0.4706 lr: 0.000047
 Fold 4 Epoch 3/125: Tr L: 0.7017, Tr Acc: 0.5890, Val L: 0.8751, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 4 Epoch 4/125: Tr L: 0.6838, Tr Acc: 0.6233, Val L: 1.0967, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 4 Epoch 5/125: Tr L: 0.6920, Tr Acc: 0.6027, Val L: 0.6320, Val Acc: 0.6667, Val F1: 0.2000 lr: 0.000047
 Fold 4 Epoch 6/125: Tr L: 0.6334, Tr Acc: 0.6164, Val L: 1.5043, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 4 Epoch 7/125: Tr L: 0.7026, Tr Acc: 0.6233, Val L: 0.6524, Val Acc: 0.6667, Val F1: 0.5000 lr: 0.000047
 Fold 4 Epoch 8/125: Tr L: 0.6565, Tr Acc: 0.6301, Val L: 0.7849, Val Acc: 0.6667, Val F1: 0.2000 lr: 0.000047
 Fold 4 Epoch 9/125: Tr L: 0.6870, Tr Acc: 0.6370, Val L: 0.5586, Val Acc: 0.7917, Val F1: 0.7619 lr: 0.000047
 Fold 4 Epoch 10/125: Tr L: 0.5849, Tr Acc: 0.6986, Val L: 1.0389, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 4 Epoch 11/125: Tr L: 0.5583, Tr Acc: 0.7397, Val L: 0.5208, Val Acc: 0.7083, Val F1: 0.6667 lr: 0.000047
 Fold 4 Epoch 12/125: Tr L: 0.5991, Tr Acc: 0.6986, Val L: 0.6500, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000047
 Fold 4 Epoch 13/125: Tr L: 0.6307, Tr Acc: 0.6781, Val L: 0.6329, Val Acc: 0.5833, Val F1: 0.6154 lr: 0.000047
 Fold 4 Epoch 14/125: Tr L: 0.5914, Tr Acc: 0.7055, Val L: 1.1044, Val Acc: 0.6667, Val F1: 0.2000 lr: 0.000047
 Fold 4 Epoch 15/125: Tr L: 0.6830, Tr Acc: 0.6301, Val L: 1.5184, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 4 Epoch 16/125: Tr L: 0.4930, Tr Acc: 0.8082, Val L: 0.6120, Val Acc: 0.7500, Val F1: 0.7500 lr: 0.000047
 Fold 4 Epoch 17/125: Tr L: 0.5843, Tr Acc: 0.7603, Val L: 1.2024, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000047
 Fold 4 Epoch 18/125: Tr L: 0.5362, Tr Acc: 0.7671, Val L: 1.2593, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000047
 Fold 4 Epoch 19/125: Tr L: 0.4538, Tr Acc: 0.8014, Val L: 0.8773, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 4 Epoch 20/125: Tr L: 0.4901, Tr Acc: 0.8082, Val L: 4.1702, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 4 Epoch 21/125: Tr L: 0.4647, Tr Acc: 0.8219, Val L: 0.5246, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000047
 Fold 4 Epoch 22/125: Tr L: 0.4240, Tr Acc: 0.8493, Val L: 0.6076, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000047
 Fold 4 Epoch 23/125: Tr L: 0.4633, Tr Acc: 0.8356, Val L: 0.8083, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000047
 Fold 4 Epoch 24/125: Tr L: 0.6167, Tr Acc: 0.7877, Val L: 1.3379, Val Acc: 0.6667, Val F1: 0.5000 lr: 0.000047
 Fold 4 Epoch 25/125: Tr L: 0.4818, Tr Acc: 0.8219, Val L: 4.2601, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 4 Epoch 26/125: Tr L: 0.5394, Tr Acc: 0.7603, Val L: 3.9374, Val Acc: 0.6667, Val F1: 0.2000 lr: 0.000047
 Fold 4 Epoch 27/125: Tr L: 0.5211, Tr Acc: 0.7671, Val L: 5.8458, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 4 Epoch 28/125: Tr L: 0.4498, Tr Acc: 0.7945, Val L: 0.6174, Val Acc: 0.7917, Val F1: 0.7368 lr: 0.000047
 Fold 4 Epoch 29/125: Tr L: 0.4717, Tr Acc: 0.8082, Val L: 0.7237, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000047
 Fold 4 Epoch 30/125: Tr L: 0.4423, Tr Acc: 0.8699, Val L: 0.6435, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000047
 Fold 4 Epoch 31/125: Tr L: 0.3461, Tr Acc: 0.8630, Val L: 3.8259, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 4 Epoch 32/125: Tr L: 0.3118, Tr Acc: 0.8973, Val L: 0.8478, Val Acc: 0.7500, Val F1: 0.5714 lr: 0.000047
 Fold 4 Epoch 33/125: Tr L: 0.5692, Tr Acc: 0.7877, Val L: 2.7361, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 4 Epoch 34/125: Tr L: 0.5322, Tr Acc: 0.8014, Val L: 0.5949, Val Acc: 0.7500, Val F1: 0.7000 lr: 0.000047
 Fold 4 Epoch 35/125: Tr L: 0.6251, Tr Acc: 0.7671, Val L: 0.9110, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000047
 Fold 4 Epoch 36/125: Tr L: 0.4499, Tr Acc: 0.8219, Val L: 0.6585, Val Acc: 0.7083, Val F1: 0.6957 lr: 0.000047
 Fold 4 Epoch 37/125: Tr L: 0.5322, Tr Acc: 0.8082, Val L: 0.6793, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000047
 Fold 4 Epoch 38/125: Tr L: 0.4484, Tr Acc: 0.8082, Val L: 0.5519, Val Acc: 0.7917, Val F1: 0.7619 lr: 0.000024
 Fold 4 Epoch 39/125: Tr L: 0.4519, Tr Acc: 0.8288, Val L: 2.4488, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000024
 Fold 4 Epoch 40/125: Tr L: 0.4664, Tr Acc: 0.8425, Val L: 1.0195, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000024
 Fold 4 Epoch 41/125: Tr L: 0.2310, Tr Acc: 0.9041, Val L: 1.0309, Val Acc: 0.7083, Val F1: 0.7200 lr: 0.000024
 Fold 4 Epoch 42/125: Tr L: 0.4036, Tr Acc: 0.8288, Val L: 2.7176, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000024
 Fold 4 Epoch 43/125: Tr L: 0.3686, Tr Acc: 0.8904, Val L: 1.8755, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000024
 Fold 4 Epoch 44/125: Tr L: 0.4099, Tr Acc: 0.9110, Val L: 0.6900, Val Acc: 0.7917, Val F1: 0.7619 lr: 0.000024
 Fold 4 Epoch 45/125: Tr L: 0.3749, Tr Acc: 0.8836, Val L: 1.3645, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000024
 Fold 4 Epoch 46/125: Tr L: 0.4855, Tr Acc: 0.8630, Val L: 1.9936, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000024
 Fold 4 Epoch 47/125: Tr L: 0.4976, Tr Acc: 0.8493, Val L: 0.6673, Val Acc: 0.7917, Val F1: 0.7368 lr: 0.000024
 Fold 4 Epoch 48/125: Tr L: 0.3749, Tr Acc: 0.8904, Val L: 1.2061, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000024
 Fold 4 Epoch 49/125: Tr L: 0.6267, Tr Acc: 0.8288, Val L: 2.3335, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000024
 Fold 4 Epoch 50/125: Tr L: 0.6170, Tr Acc: 0.8356, Val L: 0.9413, Val Acc: 0.7917, Val F1: 0.7368 lr: 0.000024
 Fold 4 Epoch 51/125: Tr L: 0.3482, Tr Acc: 0.8562, Val L: 0.9026, Val Acc: 0.7083, Val F1: 0.6316 lr: 0.000024
Early stopping triggered at epoch 51 for fold 4
--- Evaluating Fold 4 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 4: {0: 16, 1: 8}
percentage of classes in test set: 0    0.666667
1    0.333333
Name: count, dtype: float64
 [FOLD 4 FINAL] Test Loss: 0.5569 | Test Acc: 0.7917 | test Balanced Acc: 0.7812 | test F1: 0.7059 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

===== OUTER FOLD 5 / 7 =====
Outer Train images: 140 | Outer Test images: 24
--- Calculating normalization stats for Fold 5 Training Data ---
[I 2025-06-26 18:37:57,096] A new study created in memory with name: no-name-3f17ae9f-854c-465f-bd35-877313d2e6e0
Fold 5 stats: {'mean': [0.029618889093399048, 0.010843642987310886, 0.0885801613330841], 'std': [0.054024141281843185, 0.016126682981848717, 0.09403308480978012]}
--- Generating data transforms for Fold 5 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.029618889093399048, 0.010843642987310886, 0.0885801613330841], std: [0.054024141281843185, 0.016126682981848717, 0.09403308480978012]
Applying fold-specific normalization to validation data with mean: [0.029618889093399048, 0.010843642987310886, 0.0885801613330841], std: [0.054024141281843185, 0.016126682981848717, 0.09403308480978012]
Transforms generated for Fold 5.
--- Starting Hyperparameter Tuning for Fold 5 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:38:27,120] Trial 0 finished with value: 0.6721427470445633 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6721427470445633.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:38:58,966] Trial 1 finished with value: 1.3520662963390349 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6721427470445633.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:39:28,105] Trial 2 finished with value: 0.7006094574928283 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6721427470445633.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 5 with LR=0.000047 ---
X_train_es: (116,) | X_val_es: (24,)
Early stopping split: Train images: 116, Validation images: 24
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 5 Epoch 1/125: Tr L: 0.7602, Tr Acc: 0.4932, Val L: 0.8690, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 5 Epoch 2/125: Tr L: 0.6717, Tr Acc: 0.6301, Val L: 0.6166, Val Acc: 0.5000, Val F1: 0.2500 lr: 0.000047
 Fold 5 Epoch 3/125: Tr L: 0.6533, Tr Acc: 0.6164, Val L: 0.6240, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000047
 Fold 5 Epoch 4/125: Tr L: 0.6275, Tr Acc: 0.6233, Val L: 0.7240, Val Acc: 0.5417, Val F1: 0.2667 lr: 0.000047
 Fold 5 Epoch 5/125: Tr L: 0.7341, Tr Acc: 0.5890, Val L: 0.9665, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 5 Epoch 6/125: Tr L: 0.6204, Tr Acc: 0.6301, Val L: 0.5867, Val Acc: 0.6667, Val F1: 0.4286 lr: 0.000047
 Fold 5 Epoch 7/125: Tr L: 0.6092, Tr Acc: 0.6507, Val L: 0.5813, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000047
 Fold 5 Epoch 8/125: Tr L: 0.6043, Tr Acc: 0.6781, Val L: 0.5555, Val Acc: 0.5833, Val F1: 0.6154 lr: 0.000047
 Fold 5 Epoch 9/125: Tr L: 0.5324, Tr Acc: 0.7123, Val L: 0.8463, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 5 Epoch 10/125: Tr L: 0.5920, Tr Acc: 0.7192, Val L: 0.5183, Val Acc: 0.7500, Val F1: 0.7273 lr: 0.000047
 Fold 5 Epoch 11/125: Tr L: 0.4504, Tr Acc: 0.7740, Val L: 1.5212, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 5 Epoch 12/125: Tr L: 0.5395, Tr Acc: 0.7192, Val L: 0.4980, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000047
 Fold 5 Epoch 13/125: Tr L: 0.4841, Tr Acc: 0.8014, Val L: 0.8496, Val Acc: 0.6667, Val F1: 0.6923 lr: 0.000047
 Fold 5 Epoch 14/125: Tr L: 0.6017, Tr Acc: 0.6644, Val L: 1.1269, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 5 Epoch 15/125: Tr L: 0.6594, Tr Acc: 0.6712, Val L: 0.6117, Val Acc: 0.6250, Val F1: 0.5714 lr: 0.000047
 Fold 5 Epoch 16/125: Tr L: 0.4995, Tr Acc: 0.7603, Val L: 3.4009, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 5 Epoch 17/125: Tr L: 0.5262, Tr Acc: 0.7123, Val L: 0.6512, Val Acc: 0.5000, Val F1: 0.1429 lr: 0.000047
 Fold 5 Epoch 18/125: Tr L: 0.5228, Tr Acc: 0.7877, Val L: 1.4487, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 5 Epoch 19/125: Tr L: 0.6063, Tr Acc: 0.7055, Val L: 1.7025, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000047
 Fold 5 Epoch 20/125: Tr L: 0.5276, Tr Acc: 0.7877, Val L: 0.6770, Val Acc: 0.5833, Val F1: 0.4444 lr: 0.000047
 Fold 5 Epoch 21/125: Tr L: 0.6305, Tr Acc: 0.7329, Val L: 4.0519, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 5 Epoch 22/125: Tr L: 0.5623, Tr Acc: 0.7671, Val L: 1.3673, Val Acc: 0.5833, Val F1: 0.6429 lr: 0.000047
 Fold 5 Epoch 23/125: Tr L: 0.4026, Tr Acc: 0.8219, Val L: 0.7332, Val Acc: 0.4583, Val F1: 0.3158 lr: 0.000047
 Fold 5 Epoch 24/125: Tr L: 0.5452, Tr Acc: 0.7808, Val L: 2.6082, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 5 Epoch 25/125: Tr L: 0.4483, Tr Acc: 0.8493, Val L: 0.8820, Val Acc: 0.5833, Val F1: 0.5455 lr: 0.000047
 Fold 5 Epoch 26/125: Tr L: 0.4614, Tr Acc: 0.8014, Val L: 3.0819, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 5 Epoch 27/125: Tr L: 0.4343, Tr Acc: 0.8699, Val L: 0.7723, Val Acc: 0.6250, Val F1: 0.6087 lr: 0.000047
 Fold 5 Epoch 28/125: Tr L: 0.5401, Tr Acc: 0.7877, Val L: 0.7745, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000047
 Fold 5 Epoch 29/125: Tr L: 0.4804, Tr Acc: 0.8082, Val L: 2.2650, Val Acc: 0.5000, Val F1: 0.6000 lr: 0.000047
 Fold 5 Epoch 30/125: Tr L: 0.3514, Tr Acc: 0.8904, Val L: 1.4502, Val Acc: 0.6250, Val F1: 0.6667 lr: 0.000047
 Fold 5 Epoch 31/125: Tr L: 0.3799, Tr Acc: 0.8836, Val L: 0.9050, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000047
 Fold 5 Epoch 32/125: Tr L: 0.3906, Tr Acc: 0.8356, Val L: 1.2498, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000047
 Fold 5 Epoch 33/125: Tr L: 0.6448, Tr Acc: 0.7945, Val L: 2.6054, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 5 Epoch 34/125: Tr L: 0.4282, Tr Acc: 0.8493, Val L: 1.5154, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 5 Epoch 35/125: Tr L: 0.4624, Tr Acc: 0.7945, Val L: 0.5484, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000047
 Fold 5 Epoch 36/125: Tr L: 0.5639, Tr Acc: 0.8151, Val L: 0.6233, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000047
 Fold 5 Epoch 37/125: Tr L: 0.2658, Tr Acc: 0.8973, Val L: 0.9009, Val Acc: 0.6667, Val F1: 0.6667 lr: 0.000047
 Fold 5 Epoch 38/125: Tr L: 0.3946, Tr Acc: 0.8767, Val L: 1.5214, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 5 Epoch 39/125: Tr L: 0.3673, Tr Acc: 0.8630, Val L: 2.4047, Val Acc: 0.4583, Val F1: 0.5517 lr: 0.000024
 Fold 5 Epoch 40/125: Tr L: 0.3593, Tr Acc: 0.8767, Val L: 1.1875, Val Acc: 0.5000, Val F1: 0.5385 lr: 0.000024
 Fold 5 Epoch 41/125: Tr L: 0.5355, Tr Acc: 0.8425, Val L: 1.4348, Val Acc: 0.5417, Val F1: 0.4762 lr: 0.000024
 Fold 5 Epoch 42/125: Tr L: 0.2290, Tr Acc: 0.9110, Val L: 2.0695, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000024
 Fold 5 Epoch 43/125: Tr L: 0.5794, Tr Acc: 0.8219, Val L: 2.4452, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000024
 Fold 5 Epoch 44/125: Tr L: 0.6068, Tr Acc: 0.8630, Val L: 1.4241, Val Acc: 0.5417, Val F1: 0.5217 lr: 0.000024
 Fold 5 Epoch 45/125: Tr L: 0.3397, Tr Acc: 0.9178, Val L: 2.6176, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000024
 Fold 5 Epoch 46/125: Tr L: 0.6039, Tr Acc: 0.8630, Val L: 1.0293, Val Acc: 0.6667, Val F1: 0.6364 lr: 0.000024
 Fold 5 Epoch 47/125: Tr L: 0.4284, Tr Acc: 0.8699, Val L: 1.1457, Val Acc: 0.5833, Val F1: 0.5833 lr: 0.000024
 Fold 5 Epoch 48/125: Tr L: 0.4911, Tr Acc: 0.8767, Val L: 2.4351, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000024
 Fold 5 Epoch 49/125: Tr L: 0.3715, Tr Acc: 0.8767, Val L: 2.0544, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000024
 Fold 5 Epoch 50/125: Tr L: 0.4853, Tr Acc: 0.8767, Val L: 1.5892, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000024
 Fold 5 Epoch 51/125: Tr L: 0.4016, Tr Acc: 0.9041, Val L: 1.4204, Val Acc: 0.5833, Val F1: 0.5000 lr: 0.000024
 Fold 5 Epoch 52/125: Tr L: 0.5896, Tr Acc: 0.8630, Val L: 3.5110, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000024
Early stopping triggered at epoch 52 for fold 5
--- Evaluating Fold 5 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 5: {0: 16, 1: 8}
percentage of classes in test set: 0    0.666667
1    0.333333
Name: count, dtype: float64
 [FOLD 5 FINAL] Test Loss: 0.9113 | Test Acc: 0.5417 | test Balanced Acc: 0.5000 | test F1: 0.3529 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

===== OUTER FOLD 6 / 7 =====
Outer Train images: 142 | Outer Test images: 22
--- Calculating normalization stats for Fold 6 Training Data ---
[I 2025-06-26 18:41:58,124] A new study created in memory with name: no-name-53e00b9f-28be-440f-afa6-c5c1f468b82a
Fold 6 stats: {'mean': [0.02973039634525776, 0.011006001383066177, 0.08780225366353989], 'std': [0.054660338908433914, 0.016186637803912163, 0.09488232433795929]}
--- Generating data transforms for Fold 6 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.02973039634525776, 0.011006001383066177, 0.08780225366353989], std: [0.054660338908433914, 0.016186637803912163, 0.09488232433795929]
Applying fold-specific normalization to validation data with mean: [0.02973039634525776, 0.011006001383066177, 0.08780225366353989], std: [0.054660338908433914, 0.016186637803912163, 0.09488232433795929]
Transforms generated for Fold 6.
--- Starting Hyperparameter Tuning for Fold 6 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:42:30,853] Trial 0 finished with value: 0.6748304784297944 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.6748304784297944.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:43:04,683] Trial 1 finished with value: 1.8458276189863683 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.6748304784297944.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:43:39,300] Trial 2 finished with value: 0.842999367415905 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.6748304784297944.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 6 with LR=0.000047 ---
X_train_es: (117,) | X_val_es: (25,)
Early stopping split: Train images: 117, Validation images: 25
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 6 Epoch 1/125: Tr L: 0.7359, Tr Acc: 0.4737, Val L: 0.6564, Val Acc: 0.6400, Val F1: 0.0000 lr: 0.000047
 Fold 6 Epoch 2/125: Tr L: 0.7274, Tr Acc: 0.4276, Val L: 0.5507, Val Acc: 0.6400, Val F1: 0.0000 lr: 0.000047
 Fold 6 Epoch 3/125: Tr L: 0.6971, Tr Acc: 0.5592, Val L: 1.4844, Val Acc: 0.3600, Val F1: 0.5294 lr: 0.000047
 Fold 6 Epoch 4/125: Tr L: 0.6747, Tr Acc: 0.6053, Val L: 0.4763, Val Acc: 0.7600, Val F1: 0.5000 lr: 0.000047
 Fold 6 Epoch 5/125: Tr L: 0.6726, Tr Acc: 0.6382, Val L: 0.4874, Val Acc: 0.6400, Val F1: 0.0000 lr: 0.000047
 Fold 6 Epoch 6/125: Tr L: 0.6836, Tr Acc: 0.5789, Val L: 1.0643, Val Acc: 0.5600, Val F1: 0.6207 lr: 0.000047
 Fold 6 Epoch 7/125: Tr L: 0.6812, Tr Acc: 0.5921, Val L: 0.7091, Val Acc: 0.7200, Val F1: 0.6957 lr: 0.000047
 Fold 6 Epoch 8/125: Tr L: 0.6602, Tr Acc: 0.6447, Val L: 0.4628, Val Acc: 0.7200, Val F1: 0.5882 lr: 0.000047
 Fold 6 Epoch 9/125: Tr L: 0.6414, Tr Acc: 0.6118, Val L: 0.7395, Val Acc: 0.6400, Val F1: 0.5714 lr: 0.000047
 Fold 6 Epoch 10/125: Tr L: 0.6472, Tr Acc: 0.6382, Val L: 2.2104, Val Acc: 0.4800, Val F1: 0.5806 lr: 0.000047
 Fold 6 Epoch 11/125: Tr L: 0.6977, Tr Acc: 0.6053, Val L: 0.4795, Val Acc: 0.8400, Val F1: 0.8000 lr: 0.000047
 Fold 6 Epoch 12/125: Tr L: 0.6025, Tr Acc: 0.6645, Val L: 0.3981, Val Acc: 0.7200, Val F1: 0.5333 lr: 0.000047
 Fold 6 Epoch 13/125: Tr L: 0.5449, Tr Acc: 0.7697, Val L: 1.8569, Val Acc: 0.4800, Val F1: 0.5806 lr: 0.000047
 Fold 6 Epoch 14/125: Tr L: 0.5272, Tr Acc: 0.7500, Val L: 0.4019, Val Acc: 0.6400, Val F1: 0.3077 lr: 0.000047
 Fold 6 Epoch 15/125: Tr L: 0.6061, Tr Acc: 0.7171, Val L: 2.5751, Val Acc: 0.5200, Val F1: 0.6000 lr: 0.000047
 Fold 6 Epoch 16/125: Tr L: 0.7037, Tr Acc: 0.6645, Val L: 0.5541, Val Acc: 0.7600, Val F1: 0.6250 lr: 0.000047
 Fold 6 Epoch 17/125: Tr L: 0.5523, Tr Acc: 0.7303, Val L: 0.7505, Val Acc: 0.8000, Val F1: 0.7368 lr: 0.000047
 Fold 6 Epoch 18/125: Tr L: 0.6197, Tr Acc: 0.7171, Val L: 0.3952, Val Acc: 0.8800, Val F1: 0.8235 lr: 0.000047
 Fold 6 Epoch 19/125: Tr L: 0.5502, Tr Acc: 0.7171, Val L: 2.1526, Val Acc: 0.5200, Val F1: 0.6000 lr: 0.000047
 Fold 6 Epoch 20/125: Tr L: 0.4713, Tr Acc: 0.7763, Val L: 0.6102, Val Acc: 0.8800, Val F1: 0.8235 lr: 0.000047
 Fold 6 Epoch 21/125: Tr L: 0.4388, Tr Acc: 0.7763, Val L: 1.2711, Val Acc: 0.7600, Val F1: 0.7273 lr: 0.000047
 Fold 6 Epoch 22/125: Tr L: 0.5653, Tr Acc: 0.7632, Val L: 0.2535, Val Acc: 0.8000, Val F1: 0.6667 lr: 0.000047
 Fold 6 Epoch 23/125: Tr L: 0.6251, Tr Acc: 0.7566, Val L: 0.7742, Val Acc: 0.8000, Val F1: 0.7368 lr: 0.000047
 Fold 6 Epoch 24/125: Tr L: 0.5160, Tr Acc: 0.7368, Val L: 0.7642, Val Acc: 0.8000, Val F1: 0.7059 lr: 0.000047
 Fold 6 Epoch 25/125: Tr L: 0.5107, Tr Acc: 0.7763, Val L: 0.5476, Val Acc: 0.8400, Val F1: 0.7778 lr: 0.000047
 Fold 6 Epoch 26/125: Tr L: 0.4565, Tr Acc: 0.7697, Val L: 1.5519, Val Acc: 0.5200, Val F1: 0.5714 lr: 0.000047
 Fold 6 Epoch 27/125: Tr L: 0.5017, Tr Acc: 0.7697, Val L: 0.9613, Val Acc: 0.7600, Val F1: 0.7273 lr: 0.000047
 Fold 6 Epoch 28/125: Tr L: 0.4856, Tr Acc: 0.7368, Val L: 1.8027, Val Acc: 0.4800, Val F1: 0.5806 lr: 0.000047
 Fold 6 Epoch 29/125: Tr L: 0.5090, Tr Acc: 0.8092, Val L: 0.5945, Val Acc: 0.7200, Val F1: 0.3636 lr: 0.000047
 Fold 6 Epoch 30/125: Tr L: 0.4234, Tr Acc: 0.8421, Val L: 0.6682, Val Acc: 0.8400, Val F1: 0.7500 lr: 0.000047
 Fold 6 Epoch 31/125: Tr L: 0.4215, Tr Acc: 0.8487, Val L: 1.4620, Val Acc: 0.7200, Val F1: 0.6667 lr: 0.000047
 Fold 6 Epoch 32/125: Tr L: 0.4792, Tr Acc: 0.7829, Val L: 0.6430, Val Acc: 0.8800, Val F1: 0.8235 lr: 0.000047
 Fold 6 Epoch 33/125: Tr L: 0.5043, Tr Acc: 0.8092, Val L: 2.2321, Val Acc: 0.7200, Val F1: 0.6957 lr: 0.000047
 Fold 6 Epoch 34/125: Tr L: 0.6784, Tr Acc: 0.7895, Val L: 0.4011, Val Acc: 0.7200, Val F1: 0.3636 lr: 0.000047
 Fold 6 Epoch 35/125: Tr L: 0.6410, Tr Acc: 0.7697, Val L: 1.9301, Val Acc: 0.4800, Val F1: 0.5517 lr: 0.000047
 Fold 6 Epoch 36/125: Tr L: 0.4873, Tr Acc: 0.7697, Val L: 0.3732, Val Acc: 0.7600, Val F1: 0.5000 lr: 0.000047
 Fold 6 Epoch 37/125: Tr L: 0.3911, Tr Acc: 0.8355, Val L: 1.3793, Val Acc: 0.6400, Val F1: 0.6400 lr: 0.000047
 Fold 6 Epoch 38/125: Tr L: 0.4338, Tr Acc: 0.8158, Val L: 0.3233, Val Acc: 0.7600, Val F1: 0.6250 lr: 0.000047
 Fold 6 Epoch 39/125: Tr L: 0.3572, Tr Acc: 0.8355, Val L: 1.4577, Val Acc: 0.7600, Val F1: 0.7273 lr: 0.000047
 Fold 6 Epoch 40/125: Tr L: 0.4083, Tr Acc: 0.8224, Val L: 0.9344, Val Acc: 0.6800, Val F1: 0.3333 lr: 0.000047
 Fold 6 Epoch 41/125: Tr L: 0.4172, Tr Acc: 0.8684, Val L: 3.0682, Val Acc: 0.5200, Val F1: 0.6000 lr: 0.000047
 Fold 6 Epoch 42/125: Tr L: 0.3801, Tr Acc: 0.8355, Val L: 0.4012, Val Acc: 0.8000, Val F1: 0.6154 lr: 0.000047
 Fold 6 Epoch 43/125: Tr L: 0.3689, Tr Acc: 0.8421, Val L: 0.8301, Val Acc: 0.7600, Val F1: 0.6667 lr: 0.000047
 Fold 6 Epoch 44/125: Tr L: 0.4578, Tr Acc: 0.8750, Val L: 2.9707, Val Acc: 0.5600, Val F1: 0.6207 lr: 0.000047
 Fold 6 Epoch 45/125: Tr L: 0.5309, Tr Acc: 0.8092, Val L: 0.6524, Val Acc: 0.7200, Val F1: 0.6957 lr: 0.000047
 Fold 6 Epoch 46/125: Tr L: 0.4272, Tr Acc: 0.8487, Val L: 0.2925, Val Acc: 0.8800, Val F1: 0.8235 lr: 0.000047
 Fold 6 Epoch 47/125: Tr L: 0.5729, Tr Acc: 0.8224, Val L: 0.5160, Val Acc: 0.8800, Val F1: 0.8000 lr: 0.000047
 Fold 6 Epoch 48/125: Tr L: 0.4536, Tr Acc: 0.8092, Val L: 4.8016, Val Acc: 0.4800, Val F1: 0.5806 lr: 0.000047
 Fold 6 Epoch 49/125: Tr L: 0.3196, Tr Acc: 0.8816, Val L: 0.6033, Val Acc: 0.6800, Val F1: 0.6667 lr: 0.000024
 Fold 6 Epoch 50/125: Tr L: 0.3400, Tr Acc: 0.8882, Val L: 0.9198, Val Acc: 0.6000, Val F1: 0.6429 lr: 0.000024
 Fold 6 Epoch 51/125: Tr L: 0.3565, Tr Acc: 0.8553, Val L: 0.4849, Val Acc: 0.7200, Val F1: 0.6667 lr: 0.000024
 Fold 6 Epoch 52/125: Tr L: 0.4031, Tr Acc: 0.8684, Val L: 0.4390, Val Acc: 0.7600, Val F1: 0.7000 lr: 0.000024
 Fold 6 Epoch 53/125: Tr L: 0.5250, Tr Acc: 0.8684, Val L: 0.3455, Val Acc: 0.8000, Val F1: 0.7368 lr: 0.000024
 Fold 6 Epoch 54/125: Tr L: 0.4988, Tr Acc: 0.8421, Val L: 1.1183, Val Acc: 0.6800, Val F1: 0.6667 lr: 0.000024
 Fold 6 Epoch 55/125: Tr L: 0.3456, Tr Acc: 0.9079, Val L: 1.0738, Val Acc: 0.6800, Val F1: 0.6923 lr: 0.000024
 Fold 6 Epoch 56/125: Tr L: 0.4661, Tr Acc: 0.8618, Val L: 0.6294, Val Acc: 0.7600, Val F1: 0.7000 lr: 0.000024
 Fold 6 Epoch 57/125: Tr L: 0.3146, Tr Acc: 0.9013, Val L: 0.2972, Val Acc: 0.8400, Val F1: 0.7778 lr: 0.000024
 Fold 6 Epoch 58/125: Tr L: 0.4488, Tr Acc: 0.8487, Val L: 0.3410, Val Acc: 0.7600, Val F1: 0.7273 lr: 0.000024
 Fold 6 Epoch 59/125: Tr L: 0.3966, Tr Acc: 0.8421, Val L: 2.1538, Val Acc: 0.5200, Val F1: 0.6000 lr: 0.000024
 Fold 6 Epoch 60/125: Tr L: 0.4557, Tr Acc: 0.8684, Val L: 0.7838, Val Acc: 0.8400, Val F1: 0.7778 lr: 0.000024
 Fold 6 Epoch 61/125: Tr L: 0.5654, Tr Acc: 0.8421, Val L: 0.8735, Val Acc: 0.7200, Val F1: 0.6957 lr: 0.000024
 Fold 6 Epoch 62/125: Tr L: 0.3477, Tr Acc: 0.8947, Val L: 1.3153, Val Acc: 0.5600, Val F1: 0.5926 lr: 0.000024
Early stopping triggered at epoch 62 for fold 6
--- Evaluating Fold 6 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 6: {0: 12, 1: 10}
percentage of classes in test set: 0    0.545455
1    0.454545
Name: count, dtype: float64
 [FOLD 6 FINAL] Test Loss: 0.9861 | Test Acc: 0.6818 | test Balanced Acc: 0.6667 | test F1: 0.5882 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

===== OUTER FOLD 7 / 7 =====
Outer Train images: 140 | Outer Test images: 24
--- Calculating normalization stats for Fold 7 Training Data ---
[I 2025-06-26 18:46:29,300] A new study created in memory with name: no-name-c6daddae-2db5-423a-b9bc-d162dd103d0b
Fold 7 stats: {'mean': [0.03051312454044819, 0.011291892267763615, 0.08618436753749847], 'std': [0.0551801398396492, 0.016380367800593376, 0.09129982441663742]}
--- Generating data transforms for Fold 7 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x14776bf1d8a0> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Resnet50 not supported using custom transforms
Applying fold-specific normalization with mean: [0.03051312454044819, 0.011291892267763615, 0.08618436753749847], std: [0.0551801398396492, 0.016380367800593376, 0.09129982441663742]
Applying fold-specific normalization to validation data with mean: [0.03051312454044819, 0.011291892267763615, 0.08618436753749847], std: [0.0551801398396492, 0.016380367800593376, 0.09129982441663742]
Transforms generated for Fold 7.
--- Starting Hyperparameter Tuning for Fold 7 ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:47:00,186] Trial 0 finished with value: 0.7057985201478003 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.7057985201478003.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:47:30,837] Trial 1 finished with value: 1.082804837822914 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.7057985201478003.
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
[I 2025-06-26 18:48:02,227] Trial 2 finished with value: 0.7282083995640278 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.7057985201478003.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 7 with LR=0.000047 ---
X_train_es: (116,) | X_val_es: (24,)
Early stopping split: Train images: 116, Validation images: 24
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
===========================
Model Architecture:
==================
Total parameters: 23,512,130
Trainable parameters: 23,512,130
Non-trainable parameters: 0
===========================
 Fold 7 Epoch 1/125: Tr L: 0.6742, Tr Acc: 0.5667, Val L: 1.0333, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 7 Epoch 2/125: Tr L: 0.6461, Tr Acc: 0.6133, Val L: 0.8266, Val Acc: 0.3750, Val F1: 0.4444 lr: 0.000047
 Fold 7 Epoch 3/125: Tr L: 0.6945, Tr Acc: 0.5533, Val L: 1.2463, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 7 Epoch 4/125: Tr L: 0.6959, Tr Acc: 0.5800, Val L: 1.1975, Val Acc: 0.3750, Val F1: 0.1176 lr: 0.000047
 Fold 7 Epoch 5/125: Tr L: 0.6789, Tr Acc: 0.6600, Val L: 1.2738, Val Acc: 0.5000, Val F1: 0.1429 lr: 0.000047
 Fold 7 Epoch 6/125: Tr L: 0.6325, Tr Acc: 0.6133, Val L: 1.0518, Val Acc: 0.3750, Val F1: 0.5455 lr: 0.000047
 Fold 7 Epoch 7/125: Tr L: 0.5846, Tr Acc: 0.6933, Val L: 0.9837, Val Acc: 0.4583, Val F1: 0.4348 lr: 0.000047
 Fold 7 Epoch 8/125: Tr L: 0.6058, Tr Acc: 0.7133, Val L: 0.9517, Val Acc: 0.5000, Val F1: 0.1429 lr: 0.000047
 Fold 7 Epoch 9/125: Tr L: 0.5145, Tr Acc: 0.7800, Val L: 0.9830, Val Acc: 0.6250, Val F1: 0.4000 lr: 0.000047
 Fold 7 Epoch 10/125: Tr L: 0.5718, Tr Acc: 0.6733, Val L: 1.2869, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 7 Epoch 11/125: Tr L: 0.6132, Tr Acc: 0.6733, Val L: 1.5790, Val Acc: 0.5833, Val F1: 0.1667 lr: 0.000047
 Fold 7 Epoch 12/125: Tr L: 0.5439, Tr Acc: 0.7133, Val L: 2.6404, Val Acc: 0.4167, Val F1: 0.5625 lr: 0.000047
 Fold 7 Epoch 13/125: Tr L: 0.6302, Tr Acc: 0.7400, Val L: 2.3330, Val Acc: 0.5833, Val F1: 0.1667 lr: 0.000047
 Fold 7 Epoch 14/125: Tr L: 0.5649, Tr Acc: 0.7333, Val L: 2.9479, Val Acc: 0.4583, Val F1: 0.5806 lr: 0.000047
 Fold 7 Epoch 15/125: Tr L: 0.5900, Tr Acc: 0.7200, Val L: 1.4197, Val Acc: 0.5000, Val F1: 0.5385 lr: 0.000047
 Fold 7 Epoch 16/125: Tr L: 0.4476, Tr Acc: 0.7933, Val L: 1.0074, Val Acc: 0.5000, Val F1: 0.4545 lr: 0.000047
 Fold 7 Epoch 17/125: Tr L: 0.4651, Tr Acc: 0.7933, Val L: 2.7910, Val Acc: 0.5000, Val F1: 0.5714 lr: 0.000047
 Fold 7 Epoch 18/125: Tr L: 0.4821, Tr Acc: 0.8133, Val L: 2.3487, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 7 Epoch 19/125: Tr L: 0.4734, Tr Acc: 0.8000, Val L: 1.8811, Val Acc: 0.5000, Val F1: 0.5385 lr: 0.000047
 Fold 7 Epoch 20/125: Tr L: 0.4236, Tr Acc: 0.8133, Val L: 2.9430, Val Acc: 0.5417, Val F1: 0.1538 lr: 0.000047
 Fold 7 Epoch 21/125: Tr L: 0.4488, Tr Acc: 0.8200, Val L: 2.5289, Val Acc: 0.4167, Val F1: 0.4615 lr: 0.000047
 Fold 7 Epoch 22/125: Tr L: 0.4081, Tr Acc: 0.8267, Val L: 4.0733, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000047
 Fold 7 Epoch 23/125: Tr L: 0.5378, Tr Acc: 0.8000, Val L: 2.0505, Val Acc: 0.5833, Val F1: 0.5833 lr: 0.000047
 Fold 7 Epoch 24/125: Tr L: 0.3874, Tr Acc: 0.8200, Val L: 2.0050, Val Acc: 0.3750, Val F1: 0.4000 lr: 0.000047
 Fold 7 Epoch 25/125: Tr L: 0.5312, Tr Acc: 0.8000, Val L: 3.6017, Val Acc: 0.4583, Val F1: 0.5517 lr: 0.000047
 Fold 7 Epoch 26/125: Tr L: 0.4206, Tr Acc: 0.8267, Val L: 2.0432, Val Acc: 0.5417, Val F1: 0.4762 lr: 0.000047
 Fold 7 Epoch 27/125: Tr L: 0.4911, Tr Acc: 0.8333, Val L: 2.0120, Val Acc: 0.5833, Val F1: 0.3750 lr: 0.000047
 Fold 7 Epoch 28/125: Tr L: 0.4320, Tr Acc: 0.8267, Val L: 4.1598, Val Acc: 0.5417, Val F1: 0.6207 lr: 0.000047
 Fold 7 Epoch 29/125: Tr L: 0.3943, Tr Acc: 0.8267, Val L: 1.5498, Val Acc: 0.5833, Val F1: 0.5000 lr: 0.000024
 Fold 7 Epoch 30/125: Tr L: 0.4427, Tr Acc: 0.8333, Val L: 1.6865, Val Acc: 0.5000, Val F1: 0.5000 lr: 0.000024
 Fold 7 Epoch 31/125: Tr L: 0.4415, Tr Acc: 0.8400, Val L: 1.8095, Val Acc: 0.5417, Val F1: 0.4762 lr: 0.000024
 Fold 7 Epoch 32/125: Tr L: 0.4460, Tr Acc: 0.8533, Val L: 3.2009, Val Acc: 0.6250, Val F1: 0.6400 lr: 0.000024
 Fold 7 Epoch 33/125: Tr L: 0.5054, Tr Acc: 0.7733, Val L: 1.8478, Val Acc: 0.5833, Val F1: 0.2857 lr: 0.000024
 Fold 7 Epoch 34/125: Tr L: 0.2609, Tr Acc: 0.8733, Val L: 1.8097, Val Acc: 0.6250, Val F1: 0.5263 lr: 0.000024
 Fold 7 Epoch 35/125: Tr L: 0.2973, Tr Acc: 0.9067, Val L: 1.8956, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000024
 Fold 7 Epoch 36/125: Tr L: 0.3145, Tr Acc: 0.8800, Val L: 2.4763, Val Acc: 0.5417, Val F1: 0.5217 lr: 0.000024
 Fold 7 Epoch 37/125: Tr L: 0.3400, Tr Acc: 0.9133, Val L: 2.6796, Val Acc: 0.5417, Val F1: 0.4762 lr: 0.000024
 Fold 7 Epoch 38/125: Tr L: 0.3993, Tr Acc: 0.8667, Val L: 3.2934, Val Acc: 0.5417, Val F1: 0.5600 lr: 0.000024
 Fold 7 Epoch 39/125: Tr L: 0.3869, Tr Acc: 0.8667, Val L: 3.3093, Val Acc: 0.5833, Val F1: 0.6154 lr: 0.000024
 Fold 7 Epoch 40/125: Tr L: 0.2709, Tr Acc: 0.8867, Val L: 2.0663, Val Acc: 0.6667, Val F1: 0.5556 lr: 0.000024
 Fold 7 Epoch 41/125: Tr L: 0.3701, Tr Acc: 0.8533, Val L: 4.0654, Val Acc: 0.5417, Val F1: 0.5926 lr: 0.000024
 Fold 7 Epoch 42/125: Tr L: 0.4860, Tr Acc: 0.8667, Val L: 1.7244, Val Acc: 0.5417, Val F1: 0.4762 lr: 0.000024
Early stopping triggered at epoch 42 for fold 7
--- Evaluating Fold 7 on Outer Test Set ---
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
Test set class counts for fold 7: {0: 14, 1: 10}
percentage of classes in test set: 0    0.583333
1    0.416667
Name: count, dtype: float64
 [FOLD 7 FINAL] Test Loss: 0.7497 | Test Acc: 0.5000 | test Balanced Acc: 0.5429 | test F1: 0.5714 | Test AUC: 1.0000
model class name: ResNet
model class name: ResNet
model class name: ResNet

-------------------------------------------------
Cross-validation results (outer folds):
  Fold 1: Test Loss=0.5055, Acc=0.6957, F1=0.5882, Bal Acc=0.6792, AUC=1.0000 (Best LR=0.000047)
  Fold 2: Test Loss=0.3159, Acc=0.8750, F1=0.8235, Bal Acc=0.8750, AUC=1.0000 (Best LR=0.000047)
  Fold 3: Test Loss=1.1623, Acc=0.3478, F1=0.1176, Bal Acc=0.2958, AUC=1.0000 (Best LR=0.000401)
  Fold 4: Test Loss=0.5569, Acc=0.7917, F1=0.7059, Bal Acc=0.7812, AUC=1.0000 (Best LR=0.000047)
  Fold 5: Test Loss=0.9113, Acc=0.5417, F1=0.3529, Bal Acc=0.5000, AUC=1.0000 (Best LR=0.000047)
  Fold 6: Test Loss=0.9861, Acc=0.6818, F1=0.5882, Bal Acc=0.6667, AUC=1.0000 (Best LR=0.000047)
  Fold 7: Test Loss=0.7497, Acc=0.5000, F1=0.5714, Bal Acc=0.5429, AUC=1.0000 (Best LR=0.000047)

--- Aggregate Results ---
Avg Test Accuracy: 0.6334 +/- 0.1679
Avg Test F1-Score: 0.5354 +/- 0.2161
Avg Test Balanced Acc: 0.6201 +/- 0.1781
Avg Test Precision: 0.5147 +/- 0.2186
Avg Test Recall: 0.5786 +/- 0.2455
-------------------------------------------------
Using Torchvision for model instantiation.
pretrained_weights? imagenet pretrained? False
Building torchvision ResNet50...
MLFLOW_TRACKING_URI = file:/leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/mlruns
Run name: Resnet50_oversamp_torchvision_color_transforms:False_06-26_at:18-50-04
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_1/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_2/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_3/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_4/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_5/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_6/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_7/train_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_1/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_2/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_3/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_4/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_5/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_6/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_7/val_loss
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_1/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_2/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_3/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_4/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_5/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_6/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_7/train_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_1/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_2/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_3/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_4/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_5/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_6/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_7/val_accuracy
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_1/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_2/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_3/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_4/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_5/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_6/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_7/val_f1
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_1/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_2/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_3/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_4/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_5/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_6/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_7/val_balanced_accuracy
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_1/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_2/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_3/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_4/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_5/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_6/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_7/val_precision
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_1/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_2/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_3/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_4/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_5/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_6/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_7/val_recall
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_1/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_2/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_3/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
2025/06/26 18:50:15 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.0a0+git6c8c5ad) contains a local version label (+git6c8c5ad). MLflow logged a pip requirement for this package as 'torch==2.2.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.
[31m2025/06/26 18:50:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_4/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_5/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_6/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Logging val_fold_7/val_auc
Grad-CAM skipped: cannot access local variable 'make_loader' where it is not associated with a value
