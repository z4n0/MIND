Logging to:   /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/logs/densenet169_3c_tesi_2025-06-26_21-59-40_17046175.out
Running on:   lrdn3076.leonardo.local
CUDA visible: 0
Started at:   Thu Jun 26 21:59:40 CEST 2025
──────────────────────────────────────────────
/leonardo/prod/opt/libraries/cineca-ai/4.3.0/none/cineca-ai-env/lib/python3.11/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
2025-06-26 22:00:03.398972: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-06-26 22:00:04.083201: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-06-26 22:00:04.084362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-06-26 22:00:04.184992: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-06-26 22:00:04.432189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-06-26 22:00:06.593121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Configuration loaded from /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/configs/3c/base.yaml
Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.2, 'test_set_size': 0.1, 'num_folds': 6}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1}, 'data_loading': {'batch_size': 8, 'num_workers': 0}, 'model': {'model_name': 'base', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai'}, 'training': {'num_epochs': 50, 'early_stopping_patience': 17, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': True, 'freezed_layerIndex': None}, 'optimizer': {'learning_rate': '1e-4', 'optimizer_name': 'Adam', 'weight_decay': '2e-5'}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}}
Configuration loaded from /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/configs/3c/densenet169.yaml
Configuration: {'dataset': {'class_names': ['MSA', 'PD']}, 'class_names': None, 'data_splitting': {'random_seed': 42, 'val_set_size': 0.15, 'test_set_size': 0.1, 'num_folds': 7}, 'data_augmentation': {'resize_spatial_size': [256, 256], 'rand_flip_prob': 0.3, 'rand_flip_spatial_axes': [0, 1], 'rand_rotate90_prob': 0.3, 'rand_rotate90_max_k': 3, 'rand_gaussian_noise_prob': 0.4, 'rand_gaussian_noise_mean': 0.0, 'rand_gaussian_noise_std': 0.1, 'use_color_transforms': False}, 'data_loading': {'batch_size': 32, 'num_workers': 2}, 'model': {'model_name': 'Densenet169', 'spatial_dims': 2, 'in_channels': 3, 'out_channels': 2, 'dropout_prob': 0.1, 'library': 'monai', 'pretrained_weights': 'imagenet'}, 'training': {'num_epochs': 125, 'early_stopping_patience': 40, 'mixup_alpha': 0, 'oversample': True, 'undersample': False, 'weighted_loss': False, 'fine_tuning': False, 'transfer_learning': False, 'freezed_layerIndex': None, 'pretrained': True}, 'optimizer': {'learning_rate': '2e-4', 'optimizer_name': 'AdamW', 'weight_decay': '1e-4', 'patience': 25}, 'scheduler': {'scheduler_name': 'ReduceLROnPlateau', 'factor': 0.5, 'scheduler_patience': 9, 'threshold': '1e-4', 'min_lr': '1e-8'}, 'num_epochs': None, 'freeze_layers': None, 'pretrained_weights': None}
Using configuration: configs/3c/densenet169.yaml
Class names: ['MSA', 'PD']
Number of channels: 3
Pretrained weights: imagenet
Number of epochs: 125
Number of workers: 2
Batch size: 32
Number of folds: 7
Model library: monai
Data directory: /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/data/3c_MIP
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x1482f1271800> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Densenet169 not supported using custom transforms
No fold-specific stats provided or incomplete; proceeding without specific normalization step (only ScaleIntensityd).
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Detected 2 unique classes.

===== OUTER FOLD 1 / 7 =====
Outer Train images: 141 | Outer Test images: 23
--- Calculating normalization stats for Fold 1 Training Data ---
[I 2025-06-26 22:00:21,702] A new study created in memory with name: no-name-733d55ed-0e2d-4b37-8727-c40c03e3f638
Fold 1 stats: {'mean': [0.02977055311203003, 0.010488065890967846, 0.08571473509073257], 'std': [0.05622174218297005, 0.014948060736060143, 0.09586147218942642]}
--- Generating data transforms for Fold 1 ---
Using pretrained model: False
Using pretrained model: False and supported by torchvision: <function is_supported_by_torchvision at 0x1482f1271800> with color transforms: False
the model is not supported by torchvision or is not pretrained
Model Densenet169 not supported using custom transforms
Applying fold-specific normalization with mean: [0.02977055311203003, 0.010488065890967846, 0.08571473509073257], std: [0.05622174218297005, 0.014948060736060143, 0.09586147218942642]
Applying fold-specific normalization to validation data with mean: [0.02977055311203003, 0.010488065890967846, 0.08571473509073257], std: [0.05622174218297005, 0.014948060736060143, 0.09586147218942642]
Transforms generated for Fold 1.
--- Starting Hyperparameter Tuning for Fold 1 ---
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
[I 2025-06-26 22:00:59,645] Trial 0 finished with value: 0.605070173740387 and parameters: {'lr': 4.715696678089837e-05}. Best is trial 0 with value: 0.605070173740387.
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
[I 2025-06-26 22:01:34,863] Trial 1 finished with value: 14.644241202622027 and parameters: {'lr': 0.0014886262201211794}. Best is trial 0 with value: 0.605070173740387.
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
[I 2025-06-26 22:02:08,858] Trial 2 finished with value: 0.7181979715824127 and parameters: {'lr': 0.0004014783718209777}. Best is trial 0 with value: 0.605070173740387.
  Best LR from inner CV = 0.000047
--- Starting Final Model Training for Fold 1 with LR=0.000047 ---
X_train_es: (119,) | X_val_es: (22,)
Early stopping split: Train images: 119, Validation images: 22
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
===========================
Model Architecture:
==================
Total parameters: 12,487,810
Trainable parameters: 12,487,810
Non-trainable parameters: 0
===========================
 Fold 1 Epoch 1/125: Tr L: 0.6753, Tr Acc: 0.5400, Val L: 0.6862, Val Acc: 0.5909, Val F1: 0.0000 lr: 0.000047
 Fold 1 Epoch 2/125: Tr L: 0.5991, Tr Acc: 0.7200, Val L: 0.7120, Val Acc: 0.5000, Val F1: 0.1538 lr: 0.000047
 Fold 1 Epoch 3/125: Tr L: 0.5561, Tr Acc: 0.7333, Val L: 0.7907, Val Acc: 0.4545, Val F1: 0.4000 lr: 0.000047
 Fold 1 Epoch 4/125: Tr L: 0.5113, Tr Acc: 0.7267, Val L: 0.8668, Val Acc: 0.5000, Val F1: 0.5600 lr: 0.000047
 Fold 1 Epoch 5/125: Tr L: 0.4915, Tr Acc: 0.8133, Val L: 0.8524, Val Acc: 0.5000, Val F1: 0.5600 lr: 0.000047
 Fold 1 Epoch 6/125: Tr L: 0.4346, Tr Acc: 0.8133, Val L: 0.8536, Val Acc: 0.5455, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 7/125: Tr L: 0.4019, Tr Acc: 0.8200, Val L: 0.8843, Val Acc: 0.5455, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 8/125: Tr L: 0.3561, Tr Acc: 0.8400, Val L: 0.8189, Val Acc: 0.5455, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 9/125: Tr L: 0.3341, Tr Acc: 0.9000, Val L: 0.7621, Val Acc: 0.5455, Val F1: 0.5000 lr: 0.000047
 Fold 1 Epoch 10/125: Tr L: 0.4328, Tr Acc: 0.8333, Val L: 0.8170, Val Acc: 0.6364, Val F1: 0.6364 lr: 0.000047
 Fold 1 Epoch 11/125: Tr L: 0.3033, Tr Acc: 0.8533, Val L: 0.8850, Val Acc: 0.5455, Val F1: 0.5833 lr: 0.000047
 Fold 1 Epoch 12/125: Tr L: 0.3472, Tr Acc: 0.8733, Val L: 0.8819, Val Acc: 0.5455, Val F1: 0.5833 lr: 0.000047
 Fold 1 Epoch 13/125: Tr L: 0.3144, Tr Acc: 0.8733, Val L: 0.8241, Val Acc: 0.6364, Val F1: 0.6364 lr: 0.000047
 Fold 1 Epoch 14/125: Tr L: 0.2732, Tr Acc: 0.9133, Val L: 0.8361, Val Acc: 0.6364, Val F1: 0.6000 lr: 0.000047
 Fold 1 Epoch 15/125: Tr L: 0.2957, Tr Acc: 0.8867, Val L: 0.9388, Val Acc: 0.5455, Val F1: 0.5455 lr: 0.000047
 Fold 1 Epoch 16/125: Tr L: 0.2045, Tr Acc: 0.9200, Val L: 1.1342, Val Acc: 0.5909, Val F1: 0.6087 lr: 0.000047
 Fold 1 Epoch 17/125: Tr L: 0.2275, Tr Acc: 0.9067, Val L: 1.1699, Val Acc: 0.5909, Val F1: 0.6087 lr: 0.000047
 Fold 1 Epoch 18/125: Tr L: 0.2138, Tr Acc: 0.9067, Val L: 1.0556, Val Acc: 0.6818, Val F1: 0.6667 lr: 0.000047
 Fold 1 Epoch 19/125: Tr L: 0.1930, Tr Acc: 0.9533, Val L: 0.9736, Val Acc: 0.6818, Val F1: 0.6316 lr: 0.000047
 Fold 1 Epoch 20/125: Tr L: 0.2797, Tr Acc: 0.9133, Val L: 1.0003, Val Acc: 0.6364, Val F1: 0.5000 lr: 0.000047
 Fold 1 Epoch 21/125: Tr L: 0.2677, Tr Acc: 0.8933, Val L: 1.0617, Val Acc: 0.6818, Val F1: 0.5882 lr: 0.000047
 Fold 1 Epoch 22/125: Tr L: 0.1826, Tr Acc: 0.9333, Val L: 0.9353, Val Acc: 0.7273, Val F1: 0.7000 lr: 0.000047
 Fold 1 Epoch 23/125: Tr L: 0.1717, Tr Acc: 0.9467, Val L: 0.8219, Val Acc: 0.7727, Val F1: 0.7368 lr: 0.000047
 Fold 1 Epoch 24/125: Tr L: 0.1485, Tr Acc: 0.9733, Val L: 0.6968, Val Acc: 0.7727, Val F1: 0.7368 lr: 0.000047
 Fold 1 Epoch 25/125: Tr L: 0.1567, Tr Acc: 0.9400, Val L: 0.6908, Val Acc: 0.6818, Val F1: 0.5333 lr: 0.000047
 Fold 1 Epoch 26/125: Tr L: 0.1841, Tr Acc: 0.9133, Val L: 1.0340, Val Acc: 0.7727, Val F1: 0.7368 lr: 0.000047
 Fold 1 Epoch 27/125: Tr L: 0.1315, Tr Acc: 0.9800, Val L: 1.1338, Val Acc: 0.6818, Val F1: 0.6667 lr: 0.000047
 Fold 1 Epoch 28/125: Tr L: 0.2216, Tr Acc: 0.9267, Val L: 1.1528, Val Acc: 0.7273, Val F1: 0.7000 lr: 0.000024
 Fold 1 Epoch 29/125: Tr L: 0.1120, Tr Acc: 0.9733, Val L: 0.9594, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 30/125: Tr L: 0.0983, Tr Acc: 0.9667, Val L: 0.9267, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 31/125: Tr L: 0.1416, Tr Acc: 0.9467, Val L: 0.9654, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 32/125: Tr L: 0.1121, Tr Acc: 0.9600, Val L: 0.9374, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 33/125: Tr L: 0.1317, Tr Acc: 0.9733, Val L: 0.9368, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 34/125: Tr L: 0.1221, Tr Acc: 0.9667, Val L: 0.8706, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 35/125: Tr L: 0.1285, Tr Acc: 0.9400, Val L: 0.8001, Val Acc: 0.7273, Val F1: 0.6250 lr: 0.000024
 Fold 1 Epoch 36/125: Tr L: 0.1377, Tr Acc: 0.9533, Val L: 0.8820, Val Acc: 0.7273, Val F1: 0.6250 lr: 0.000024
 Fold 1 Epoch 37/125: Tr L: 0.1307, Tr Acc: 0.9600, Val L: 1.0427, Val Acc: 0.6818, Val F1: 0.5882 lr: 0.000024
 Fold 1 Epoch 38/125: Tr L: 0.1075, Tr Acc: 0.9667, Val L: 1.0994, Val Acc: 0.6818, Val F1: 0.5882 lr: 0.000024
 Fold 1 Epoch 39/125: Tr L: 0.1436, Tr Acc: 0.9467, Val L: 1.0685, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 40/125: Tr L: 0.0616, Tr Acc: 0.9867, Val L: 1.0724, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
 Fold 1 Epoch 41/125: Tr L: 0.0587, Tr Acc: 0.9867, Val L: 1.0930, Val Acc: 0.7273, Val F1: 0.6667 lr: 0.000024
Early stopping triggered at epoch 41 for fold 1
--- Evaluating Fold 1 on Outer Test Set ---
Using MONAI for model instantiation.
Building MONAI DenseNet169 with 3-channel input...
Traceback (most recent call last):
  File "/leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/train.py", line 213, in <module>
    main()
  File "/leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/train.py", line 183, in main
    train_metrics, test_results = experiment.run_experiment()
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/classes/NestedCVStratifiedByPatient.py", line 484, in run_experiment
    self._evaluate_fold_on_test_set(fold_display_idx, best_model_path, loss_func_for_eval, X_test_outer, y_test_outer, best_lr)
  File "/leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/classes/NestedCVStratifiedByPatient.py", line 379, in _evaluate_fold_on_test_set
    model.load_state_dict(torch.load(model_path))
  File "/leonardo/prod/opt/libraries/cineca-ai/4.3.0/none/cineca-ai-env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2153, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for DenseNet169:
	Missing key(s) in state_dict: "features.denseblock3.denselayer25.layers.norm1.weight", "features.denseblock3.denselayer25.layers.norm1.bias", "features.denseblock3.denselayer25.layers.norm1.running_mean", "features.denseblock3.denselayer25.layers.norm1.running_var", "features.denseblock3.denselayer25.layers.conv1.weight", "features.denseblock3.denselayer25.layers.norm2.weight", "features.denseblock3.denselayer25.layers.norm2.bias", "features.denseblock3.denselayer25.layers.norm2.running_mean", "features.denseblock3.denselayer25.layers.norm2.running_var", "features.denseblock3.denselayer25.layers.conv2.weight", "features.denseblock3.denselayer26.layers.norm1.weight", "features.denseblock3.denselayer26.layers.norm1.bias", "features.denseblock3.denselayer26.layers.norm1.running_mean", "features.denseblock3.denselayer26.layers.norm1.running_var", "features.denseblock3.denselayer26.layers.conv1.weight", "features.denseblock3.denselayer26.layers.norm2.weight", "features.denseblock3.denselayer26.layers.norm2.bias", "features.denseblock3.denselayer26.layers.norm2.running_mean", "features.denseblock3.denselayer26.layers.norm2.running_var", "features.denseblock3.denselayer26.layers.conv2.weight", "features.denseblock3.denselayer27.layers.norm1.weight", "features.denseblock3.denselayer27.layers.norm1.bias", "features.denseblock3.denselayer27.layers.norm1.running_mean", "features.denseblock3.denselayer27.layers.norm1.running_var", "features.denseblock3.denselayer27.layers.conv1.weight", "features.denseblock3.denselayer27.layers.norm2.weight", "features.denseblock3.denselayer27.layers.norm2.bias", "features.denseblock3.denselayer27.layers.norm2.running_mean", "features.denseblock3.denselayer27.layers.norm2.running_var", "features.denseblock3.denselayer27.layers.conv2.weight", "features.denseblock3.denselayer28.layers.norm1.weight", "features.denseblock3.denselayer28.layers.norm1.bias", "features.denseblock3.denselayer28.layers.norm1.running_mean", "features.denseblock3.denselayer28.layers.norm1.running_var", "features.denseblock3.denselayer28.layers.conv1.weight", "features.denseblock3.denselayer28.layers.norm2.weight", "features.denseblock3.denselayer28.layers.norm2.bias", "features.denseblock3.denselayer28.layers.norm2.running_mean", "features.denseblock3.denselayer28.layers.norm2.running_var", "features.denseblock3.denselayer28.layers.conv2.weight", "features.denseblock3.denselayer29.layers.norm1.weight", "features.denseblock3.denselayer29.layers.norm1.bias", "features.denseblock3.denselayer29.layers.norm1.running_mean", "features.denseblock3.denselayer29.layers.norm1.running_var", "features.denseblock3.denselayer29.layers.conv1.weight", "features.denseblock3.denselayer29.layers.norm2.weight", "features.denseblock3.denselayer29.layers.norm2.bias", "features.denseblock3.denselayer29.layers.norm2.running_mean", "features.denseblock3.denselayer29.layers.norm2.running_var", "features.denseblock3.denselayer29.layers.conv2.weight", "features.denseblock3.denselayer30.layers.norm1.weight", "features.denseblock3.denselayer30.layers.norm1.bias", "features.denseblock3.denselayer30.layers.norm1.running_mean", "features.denseblock3.denselayer30.layers.norm1.running_var", "features.denseblock3.denselayer30.layers.conv1.weight", "features.denseblock3.denselayer30.layers.norm2.weight", "features.denseblock3.denselayer30.layers.norm2.bias", "features.denseblock3.denselayer30.layers.norm2.running_mean", "features.denseblock3.denselayer30.layers.norm2.running_var", "features.denseblock3.denselayer30.layers.conv2.weight", "features.denseblock3.denselayer31.layers.norm1.weight", "features.denseblock3.denselayer31.layers.norm1.bias", "features.denseblock3.denselayer31.layers.norm1.running_mean", "features.denseblock3.denselayer31.layers.norm1.running_var", "features.denseblock3.denselayer31.layers.conv1.weight", "features.denseblock3.denselayer31.layers.norm2.weight", "features.denseblock3.denselayer31.layers.norm2.bias", "features.denseblock3.denselayer31.layers.norm2.running_mean", "features.denseblock3.denselayer31.layers.norm2.running_var", "features.denseblock3.denselayer31.layers.conv2.weight", "features.denseblock3.denselayer32.layers.norm1.weight", "features.denseblock3.denselayer32.layers.norm1.bias", "features.denseblock3.denselayer32.layers.norm1.running_mean", "features.denseblock3.denselayer32.layers.norm1.running_var", "features.denseblock3.denselayer32.layers.conv1.weight", "features.denseblock3.denselayer32.layers.norm2.weight", "features.denseblock3.denselayer32.layers.norm2.bias", "features.denseblock3.denselayer32.layers.norm2.running_mean", "features.denseblock3.denselayer32.layers.norm2.running_var", "features.denseblock3.denselayer32.layers.conv2.weight", "features.denseblock4.denselayer17.layers.norm1.weight", "features.denseblock4.denselayer17.layers.norm1.bias", "features.denseblock4.denselayer17.layers.norm1.running_mean", "features.denseblock4.denselayer17.layers.norm1.running_var", "features.denseblock4.denselayer17.layers.conv1.weight", "features.denseblock4.denselayer17.layers.norm2.weight", "features.denseblock4.denselayer17.layers.norm2.bias", "features.denseblock4.denselayer17.layers.norm2.running_mean", "features.denseblock4.denselayer17.layers.norm2.running_var", "features.denseblock4.denselayer17.layers.conv2.weight", "features.denseblock4.denselayer18.layers.norm1.weight", "features.denseblock4.denselayer18.layers.norm1.bias", "features.denseblock4.denselayer18.layers.norm1.running_mean", "features.denseblock4.denselayer18.layers.norm1.running_var", "features.denseblock4.denselayer18.layers.conv1.weight", "features.denseblock4.denselayer18.layers.norm2.weight", "features.denseblock4.denselayer18.layers.norm2.bias", "features.denseblock4.denselayer18.layers.norm2.running_mean", "features.denseblock4.denselayer18.layers.norm2.running_var", "features.denseblock4.denselayer18.layers.conv2.weight", "features.denseblock4.denselayer19.layers.norm1.weight", "features.denseblock4.denselayer19.layers.norm1.bias", "features.denseblock4.denselayer19.layers.norm1.running_mean", "features.denseblock4.denselayer19.layers.norm1.running_var", "features.denseblock4.denselayer19.layers.conv1.weight", "features.denseblock4.denselayer19.layers.norm2.weight", "features.denseblock4.denselayer19.layers.norm2.bias", "features.denseblock4.denselayer19.layers.norm2.running_mean", "features.denseblock4.denselayer19.layers.norm2.running_var", "features.denseblock4.denselayer19.layers.conv2.weight", "features.denseblock4.denselayer20.layers.norm1.weight", "features.denseblock4.denselayer20.layers.norm1.bias", "features.denseblock4.denselayer20.layers.norm1.running_mean", "features.denseblock4.denselayer20.layers.norm1.running_var", "features.denseblock4.denselayer20.layers.conv1.weight", "features.denseblock4.denselayer20.layers.norm2.weight", "features.denseblock4.denselayer20.layers.norm2.bias", "features.denseblock4.denselayer20.layers.norm2.running_mean", "features.denseblock4.denselayer20.layers.norm2.running_var", "features.denseblock4.denselayer20.layers.conv2.weight", "features.denseblock4.denselayer21.layers.norm1.weight", "features.denseblock4.denselayer21.layers.norm1.bias", "features.denseblock4.denselayer21.layers.norm1.running_mean", "features.denseblock4.denselayer21.layers.norm1.running_var", "features.denseblock4.denselayer21.layers.conv1.weight", "features.denseblock4.denselayer21.layers.norm2.weight", "features.denseblock4.denselayer21.layers.norm2.bias", "features.denseblock4.denselayer21.layers.norm2.running_mean", "features.denseblock4.denselayer21.layers.norm2.running_var", "features.denseblock4.denselayer21.layers.conv2.weight", "features.denseblock4.denselayer22.layers.norm1.weight", "features.denseblock4.denselayer22.layers.norm1.bias", "features.denseblock4.denselayer22.layers.norm1.running_mean", "features.denseblock4.denselayer22.layers.norm1.running_var", "features.denseblock4.denselayer22.layers.conv1.weight", "features.denseblock4.denselayer22.layers.norm2.weight", "features.denseblock4.denselayer22.layers.norm2.bias", "features.denseblock4.denselayer22.layers.norm2.running_mean", "features.denseblock4.denselayer22.layers.norm2.running_var", "features.denseblock4.denselayer22.layers.conv2.weight", "features.denseblock4.denselayer23.layers.norm1.weight", "features.denseblock4.denselayer23.layers.norm1.bias", "features.denseblock4.denselayer23.layers.norm1.running_mean", "features.denseblock4.denselayer23.layers.norm1.running_var", "features.denseblock4.denselayer23.layers.conv1.weight", "features.denseblock4.denselayer23.layers.norm2.weight", "features.denseblock4.denselayer23.layers.norm2.bias", "features.denseblock4.denselayer23.layers.norm2.running_mean", "features.denseblock4.denselayer23.layers.norm2.running_var", "features.denseblock4.denselayer23.layers.conv2.weight", "features.denseblock4.denselayer24.layers.norm1.weight", "features.denseblock4.denselayer24.layers.norm1.bias", "features.denseblock4.denselayer24.layers.norm1.running_mean", "features.denseblock4.denselayer24.layers.norm1.running_var", "features.denseblock4.denselayer24.layers.conv1.weight", "features.denseblock4.denselayer24.layers.norm2.weight", "features.denseblock4.denselayer24.layers.norm2.bias", "features.denseblock4.denselayer24.layers.norm2.running_mean", "features.denseblock4.denselayer24.layers.norm2.running_var", "features.denseblock4.denselayer24.layers.conv2.weight", "features.denseblock4.denselayer25.layers.norm1.weight", "features.denseblock4.denselayer25.layers.norm1.bias", "features.denseblock4.denselayer25.layers.norm1.running_mean", "features.denseblock4.denselayer25.layers.norm1.running_var", "features.denseblock4.denselayer25.layers.conv1.weight", "features.denseblock4.denselayer25.layers.norm2.weight", "features.denseblock4.denselayer25.layers.norm2.bias", "features.denseblock4.denselayer25.layers.norm2.running_mean", "features.denseblock4.denselayer25.layers.norm2.running_var", "features.denseblock4.denselayer25.layers.conv2.weight", "features.denseblock4.denselayer26.layers.norm1.weight", "features.denseblock4.denselayer26.layers.norm1.bias", "features.denseblock4.denselayer26.layers.norm1.running_mean", "features.denseblock4.denselayer26.layers.norm1.running_var", "features.denseblock4.denselayer26.layers.conv1.weight", "features.denseblock4.denselayer26.layers.norm2.weight", "features.denseblock4.denselayer26.layers.norm2.bias", "features.denseblock4.denselayer26.layers.norm2.running_mean", "features.denseblock4.denselayer26.layers.norm2.running_var", "features.denseblock4.denselayer26.layers.conv2.weight", "features.denseblock4.denselayer27.layers.norm1.weight", "features.denseblock4.denselayer27.layers.norm1.bias", "features.denseblock4.denselayer27.layers.norm1.running_mean", "features.denseblock4.denselayer27.layers.norm1.running_var", "features.denseblock4.denselayer27.layers.conv1.weight", "features.denseblock4.denselayer27.layers.norm2.weight", "features.denseblock4.denselayer27.layers.norm2.bias", "features.denseblock4.denselayer27.layers.norm2.running_mean", "features.denseblock4.denselayer27.layers.norm2.running_var", "features.denseblock4.denselayer27.layers.conv2.weight", "features.denseblock4.denselayer28.layers.norm1.weight", "features.denseblock4.denselayer28.layers.norm1.bias", "features.denseblock4.denselayer28.layers.norm1.running_mean", "features.denseblock4.denselayer28.layers.norm1.running_var", "features.denseblock4.denselayer28.layers.conv1.weight", "features.denseblock4.denselayer28.layers.norm2.weight", "features.denseblock4.denselayer28.layers.norm2.bias", "features.denseblock4.denselayer28.layers.norm2.running_mean", "features.denseblock4.denselayer28.layers.norm2.running_var", "features.denseblock4.denselayer28.layers.conv2.weight", "features.denseblock4.denselayer29.layers.norm1.weight", "features.denseblock4.denselayer29.layers.norm1.bias", "features.denseblock4.denselayer29.layers.norm1.running_mean", "features.denseblock4.denselayer29.layers.norm1.running_var", "features.denseblock4.denselayer29.layers.conv1.weight", "features.denseblock4.denselayer29.layers.norm2.weight", "features.denseblock4.denselayer29.layers.norm2.bias", "features.denseblock4.denselayer29.layers.norm2.running_mean", "features.denseblock4.denselayer29.layers.norm2.running_var", "features.denseblock4.denselayer29.layers.conv2.weight", "features.denseblock4.denselayer30.layers.norm1.weight", "features.denseblock4.denselayer30.layers.norm1.bias", "features.denseblock4.denselayer30.layers.norm1.running_mean", "features.denseblock4.denselayer30.layers.norm1.running_var", "features.denseblock4.denselayer30.layers.conv1.weight", "features.denseblock4.denselayer30.layers.norm2.weight", "features.denseblock4.denselayer30.layers.norm2.bias", "features.denseblock4.denselayer30.layers.norm2.running_mean", "features.denseblock4.denselayer30.layers.norm2.running_var", "features.denseblock4.denselayer30.layers.conv2.weight", "features.denseblock4.denselayer31.layers.norm1.weight", "features.denseblock4.denselayer31.layers.norm1.bias", "features.denseblock4.denselayer31.layers.norm1.running_mean", "features.denseblock4.denselayer31.layers.norm1.running_var", "features.denseblock4.denselayer31.layers.conv1.weight", "features.denseblock4.denselayer31.layers.norm2.weight", "features.denseblock4.denselayer31.layers.norm2.bias", "features.denseblock4.denselayer31.layers.norm2.running_mean", "features.denseblock4.denselayer31.layers.norm2.running_var", "features.denseblock4.denselayer31.layers.conv2.weight", "features.denseblock4.denselayer32.layers.norm1.weight", "features.denseblock4.denselayer32.layers.norm1.bias", "features.denseblock4.denselayer32.layers.norm1.running_mean", "features.denseblock4.denselayer32.layers.norm1.running_var", "features.denseblock4.denselayer32.layers.conv1.weight", "features.denseblock4.denselayer32.layers.norm2.weight", "features.denseblock4.denselayer32.layers.norm2.bias", "features.denseblock4.denselayer32.layers.norm2.running_mean", "features.denseblock4.denselayer32.layers.norm2.running_var", "features.denseblock4.denselayer32.layers.conv2.weight". 
	size mismatch for features.transition3.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for features.transition3.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for features.transition3.norm.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for features.transition3.norm.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1280]).
	size mismatch for features.transition3.conv.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([640, 1280, 1, 1]).
	size mismatch for features.denseblock4.denselayer1.layers.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([640]).
	size mismatch for features.denseblock4.denselayer1.layers.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([640]).
	size mismatch for features.denseblock4.denselayer1.layers.norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([640]).
	size mismatch for features.denseblock4.denselayer1.layers.norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([640]).
	size mismatch for features.denseblock4.denselayer1.layers.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 640, 1, 1]).
	size mismatch for features.denseblock4.denselayer2.layers.norm1.weight: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([672]).
	size mismatch for features.denseblock4.denselayer2.layers.norm1.bias: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([672]).
	size mismatch for features.denseblock4.denselayer2.layers.norm1.running_mean: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([672]).
	size mismatch for features.denseblock4.denselayer2.layers.norm1.running_var: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([672]).
	size mismatch for features.denseblock4.denselayer2.layers.conv1.weight: copying a param with shape torch.Size([128, 544, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 672, 1, 1]).
	size mismatch for features.denseblock4.denselayer3.layers.norm1.weight: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([704]).
	size mismatch for features.denseblock4.denselayer3.layers.norm1.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([704]).
	size mismatch for features.denseblock4.denselayer3.layers.norm1.running_mean: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([704]).
	size mismatch for features.denseblock4.denselayer3.layers.norm1.running_var: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([704]).
	size mismatch for features.denseblock4.denselayer3.layers.conv1.weight: copying a param with shape torch.Size([128, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 704, 1, 1]).
	size mismatch for features.denseblock4.denselayer4.layers.norm1.weight: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([736]).
	size mismatch for features.denseblock4.denselayer4.layers.norm1.bias: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([736]).
	size mismatch for features.denseblock4.denselayer4.layers.norm1.running_mean: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([736]).
	size mismatch for features.denseblock4.denselayer4.layers.norm1.running_var: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([736]).
	size mismatch for features.denseblock4.denselayer4.layers.conv1.weight: copying a param with shape torch.Size([128, 608, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 736, 1, 1]).
	size mismatch for features.denseblock4.denselayer5.layers.norm1.weight: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for features.denseblock4.denselayer5.layers.norm1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for features.denseblock4.denselayer5.layers.norm1.running_mean: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for features.denseblock4.denselayer5.layers.norm1.running_var: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for features.denseblock4.denselayer5.layers.conv1.weight: copying a param with shape torch.Size([128, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 768, 1, 1]).
	size mismatch for features.denseblock4.denselayer6.layers.norm1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([800]).
	size mismatch for features.denseblock4.denselayer6.layers.norm1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([800]).
	size mismatch for features.denseblock4.denselayer6.layers.norm1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([800]).
	size mismatch for features.denseblock4.denselayer6.layers.norm1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([800]).
	size mismatch for features.denseblock4.denselayer6.layers.conv1.weight: copying a param with shape torch.Size([128, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 800, 1, 1]).
	size mismatch for features.denseblock4.denselayer7.layers.norm1.weight: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([832]).
	size mismatch for features.denseblock4.denselayer7.layers.norm1.bias: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([832]).
	size mismatch for features.denseblock4.denselayer7.layers.norm1.running_mean: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([832]).
	size mismatch for features.denseblock4.denselayer7.layers.norm1.running_var: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([832]).
	size mismatch for features.denseblock4.denselayer7.layers.conv1.weight: copying a param with shape torch.Size([128, 704, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 832, 1, 1]).
	size mismatch for features.denseblock4.denselayer8.layers.norm1.weight: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([864]).
	size mismatch for features.denseblock4.denselayer8.layers.norm1.bias: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([864]).
	size mismatch for features.denseblock4.denselayer8.layers.norm1.running_mean: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([864]).
	size mismatch for features.denseblock4.denselayer8.layers.norm1.running_var: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([864]).
	size mismatch for features.denseblock4.denselayer8.layers.conv1.weight: copying a param with shape torch.Size([128, 736, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 864, 1, 1]).
	size mismatch for features.denseblock4.denselayer9.layers.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([896]).
	size mismatch for features.denseblock4.denselayer9.layers.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([896]).
	size mismatch for features.denseblock4.denselayer9.layers.norm1.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([896]).
	size mismatch for features.denseblock4.denselayer9.layers.norm1.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([896]).
	size mismatch for features.denseblock4.denselayer9.layers.conv1.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 896, 1, 1]).
	size mismatch for features.denseblock4.denselayer10.layers.norm1.weight: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([928]).
	size mismatch for features.denseblock4.denselayer10.layers.norm1.bias: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([928]).
	size mismatch for features.denseblock4.denselayer10.layers.norm1.running_mean: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([928]).
	size mismatch for features.denseblock4.denselayer10.layers.norm1.running_var: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([928]).
	size mismatch for features.denseblock4.denselayer10.layers.conv1.weight: copying a param with shape torch.Size([128, 800, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 928, 1, 1]).
	size mismatch for features.denseblock4.denselayer11.layers.norm1.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for features.denseblock4.denselayer11.layers.norm1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for features.denseblock4.denselayer11.layers.norm1.running_mean: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for features.denseblock4.denselayer11.layers.norm1.running_var: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([960]).
	size mismatch for features.denseblock4.denselayer11.layers.conv1.weight: copying a param with shape torch.Size([128, 832, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 960, 1, 1]).
	size mismatch for features.denseblock4.denselayer12.layers.norm1.weight: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([992]).
	size mismatch for features.denseblock4.denselayer12.layers.norm1.bias: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([992]).
	size mismatch for features.denseblock4.denselayer12.layers.norm1.running_mean: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([992]).
	size mismatch for features.denseblock4.denselayer12.layers.norm1.running_var: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([992]).
	size mismatch for features.denseblock4.denselayer12.layers.conv1.weight: copying a param with shape torch.Size([128, 864, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 992, 1, 1]).
	size mismatch for features.denseblock4.denselayer13.layers.norm1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for features.denseblock4.denselayer13.layers.norm1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for features.denseblock4.denselayer13.layers.norm1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for features.denseblock4.denselayer13.layers.norm1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for features.denseblock4.denselayer13.layers.conv1.weight: copying a param with shape torch.Size([128, 896, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 1024, 1, 1]).
	size mismatch for features.denseblock4.denselayer14.layers.norm1.weight: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([1056]).
	size mismatch for features.denseblock4.denselayer14.layers.norm1.bias: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([1056]).
	size mismatch for features.denseblock4.denselayer14.layers.norm1.running_mean: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([1056]).
	size mismatch for features.denseblock4.denselayer14.layers.norm1.running_var: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([1056]).
	size mismatch for features.denseblock4.denselayer14.layers.conv1.weight: copying a param with shape torch.Size([128, 928, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 1056, 1, 1]).
	size mismatch for features.denseblock4.denselayer15.layers.norm1.weight: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([1088]).
	size mismatch for features.denseblock4.denselayer15.layers.norm1.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([1088]).
	size mismatch for features.denseblock4.denselayer15.layers.norm1.running_mean: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([1088]).
	size mismatch for features.denseblock4.denselayer15.layers.norm1.running_var: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([1088]).
	size mismatch for features.denseblock4.denselayer15.layers.conv1.weight: copying a param with shape torch.Size([128, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 1088, 1, 1]).
	size mismatch for features.denseblock4.denselayer16.layers.norm1.weight: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([1120]).
	size mismatch for features.denseblock4.denselayer16.layers.norm1.bias: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([1120]).
	size mismatch for features.denseblock4.denselayer16.layers.norm1.running_mean: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([1120]).
	size mismatch for features.denseblock4.denselayer16.layers.norm1.running_var: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([1120]).
	size mismatch for features.denseblock4.denselayer16.layers.conv1.weight: copying a param with shape torch.Size([128, 992, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 1120, 1, 1]).
	size mismatch for features.norm5.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1664]).
	size mismatch for features.norm5.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1664]).
	size mismatch for features.norm5.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1664]).
	size mismatch for features.norm5.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([1664]).
	size mismatch for class_layers.out.weight: copying a param with shape torch.Size([2, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1664]).
srun: error: lrdn3076: task 0: Exited with exit code 1
