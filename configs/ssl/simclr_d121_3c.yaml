# configs/simclr_d121_3c.yaml
dataset:
  unlabeled_subdir: PRETRAINING_MSA_VS_PD   # relative to $DATA_ROOT

model:
  backbone_library: torchvision             # or "monai"
  in_channels: 3
  input_size: 256                           # image crop/resize used in SimCLRTransform
  proj_hidden_dim: 512                      # hidden dim of the projection MLP
  proj_output_dim: 128                      # output dim of the projection MLP


# Data Loading
data_loading:
  batch_size: 256  # Custom batch size for DenseNet
  num_workers: 2  # Number of data loading workers


data_augmentation:
  resize_spatial_size: [256, 256]           # [height, width] for input images
  rotation_range: 15                        # degrees
  brightness: 0.2                           # brightness jitter
  contrast: 0.2                             # contrast jitter
  saturation: 0.2                           # saturation jitter
  hue: 0.1                                  # hue jitter
  gaussian_blur_prob: 0.5                   # probability of applying Gaussian blur
  gaussian_blur_kernel_size: 23             # kernel size for Gaussian blur
  gaussian_blur_sigma: [0.1, 2.0]          # sigma range for Gaussian blur


training:
  batch_size: 256
  num_workers: 4
  num_epochs: 120
  lr: 3e-4
  temperature: 0.07

output:
  weights_path: /leonardo_work/pMI24_EleBr_1/lzanotto/FOLDER_CINECA/pretrained_encoders/simclr_d121_3c.pth