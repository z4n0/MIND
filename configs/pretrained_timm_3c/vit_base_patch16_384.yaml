_base_: base.yaml

model:
  model_name: "vit_base_patch16_384"
  library: "timm"
  in_channels: 3
  out_channels: 2
  pretrained_weights: "imagenet"
  
  # Optional timm-specific parameters
  global_pool: "avg"
  drop_rate: 0.0
  drop_path_rate: 0.0

data_augmentation:
  resize_spatial_size: [384, 384]  # Larger input size for this variant
  crop_size: [384, 384]

data_loading:
  batch_size: 8  # Smaller batch due to larger input (384x384)

training:
  num_epochs: 450
  transfer_learning: true
  early_stopping_patience: 50
  oversample: true
  undersample: false
  weighted_loss: false
  mixup_alpha: 0

optimizer:
  learning_rate: 1e-4
  optimizer_name: "AdamW"
  weight_decay: 1e-5

scheduler:
  scheduler_name: "ReduceLROnPlateau"
  factor: 0.5
  scheduler_patience: 25
  threshold: 1e-4
  min_lr: 1e-8

